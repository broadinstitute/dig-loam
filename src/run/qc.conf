// Loam Pipeline Configuration File
//  Description: This file is the user configuration file. Use it to define your data, pipeline inputs/settings, and pipeline architecture.

// Reference files and settings
// regionsExclude [string]: path to file containing regions to exclude from qc dataset (each line should be a range of genome, eg. chr1:12345-67899)
// kgPurcellVcf [string]: 1000 genomes vcf containing purcell 5k ancestry informative variants
// kgSample [string]: 1000 genomes sample file
// kgSampleId [string]: column name for sample id in 1000 genomes sample file
// kgSamplePop [string]: column name for population in 1000 genomes sample file
// kgSampleGroup [string]: column name for group in 1000 genomes sample file
regionsExclude = .../regions.GRCh38.exclude
kgPurcellVcf = .../ALL.purcell5k.shapeit2_integrated_snvindels_v2a_27022019.GRCh38.phased.vcf.bgz
kgSample = .../1000GP_Phase3/1000GP_Phase3.sample
kgSampleId = ID
kgSamplePop = POP
kgSampleGroup = GROUP

// Reference files split by chromosome
// note: use wildcard [CHROMOSOME] to indicate 1-26/X/Y/MT. It will be replaced with the appropriate chromosome ID at run-time
// kgVcf [string]: 1000 genomes vcf files
// kgIds [string]: files containing list of variant id's in 1000 genomes vcf files
// humanReferenceWild [string]: human reference assembly files
// dbSNPht [string]: dbSNP release hail table
kgVcf = ".../ALL.chr[CHROMOSOME].shapeit2_integrated_snvindels_v2a_27022019.GRCh38.phased.vcf.gz"
kgIds = ".../ALL.chr[CHROMOSOME].shapeit2_integrated_snvindels_v2a_27022019.GRCh38.phased.vcf.ids"
humanReferenceWild = ".../[CHROMOSOME].txt"
dbSNPht = .../00-All.GRCh38.ht

// Annotation settings
// fasta [string]: dna primary assembly fasta file
// vepCacheDir [string]: path to ensembl vep cache directory
// vepPluginsDir [string]: path to ensembl vep plugins directory
// dbNSFP [string]: prepared dbNSFP release file
// gnomad [string]: gnomad release file
fasta = .../Homo_sapiens.GRCh38.dna.primary_assembly.fa.bgz
vepCacheDir = .../ensembl_vep/cache
dbNSFP = .../ensembl_vep/dbnsfp/v3.5a/dbNSFP3.5a_GRCh38.gz
vepPluginsDir = .../ensembl_vep/VEP_plugins
vepConservation = .../ensembl_vep/r110/phylocsf/GRCh37/phylocsf_gerp.sql | .../ensembl_vep/r110/phylocsf/GRCh38/loftee.sql
vepGerpBW = .../ensembl_vep/r110/gerp/gerp_conservation_scores.homo_sapiens.GRCh38.bw
gnomad = .../gnomad.exomes.r2.0.1.sites.GRCh38.noVEP.vcf.gz

// Global pipeline settings
// projectId [string]: can be any alphanumeric string and may include underscores
// hailCloud [boolean]: run hail jobs in google cloud, true or false
// tmpDir [string]: a path to use for temporary directory
// cloudShare [optional[string]]: URI of shared pipeline data on google cloud (only needed in hailCloud == true)
// cloudHome [optional[string]]: URI indicating path to output of this pipeline on google cloud (only needed in hailCloud == true)
// referenceGenome [string]: either GRCh38 or GRCh37
// nAncestryInferenceFeatures [integer]: number of PCs to include during ancestry inference
projectId = ID
hailCloud = false
cloudShare = "gs://.../shared"
cloudHome = "gs://.../ID"
referenceGenome = GRCh38
nAncestryInferenceFeatures = 3

// Report Settings
// authors [list[string]]: authors to include in qc report
// email [string]: contact email address to include in qc report
// organization [string]: organization supporting analysis
// acknowledgements [optional[list[string]]]: names of people to include in acknowledgements section of qc report
authors = [Author1,Author2]
email = "contact1@institute.org"
organization = "Institute"
acknowledgements = [Acknowledgement1,Acknowledgement2,Acknowledgement3]    // optional

// Phenotype file settings
// sampleFile [string]: 1000 genomes sample file
// sampleFileId [string]: sample id column name in 1000 genomes sample file
// sampleFileSrSex [optional[string]]: self reported sex column name in 1000 genomes sample file
// sampleFileMaleCode [optional[string]]: value indicating male in 1000 genomes sample file self reported sex column
// sampleFileFemaleCode [optional[string]]: value indicating female in 1000 genomes sample file self reported sex column
// sampleFileSrRace [optional[string]]: self reported race/ethnicity column name in 1000 genomes sample file
// sampleFileAFRCodes [optional[list[string]]]: values in self reported race/ethnicity column that can be combined with 1000 genomes AFR group
// sampleFileAMRCodes [optional[list[string]]]: values in self reported race/ethnicity column that can be combined with 1000 genomes AMR group
// sampleFileEURCodes [optional[list[string]]]: values in self reported race/ethnicity column that can be combined with 1000 genomes EUR group
// sampleFileEASCodes [optional[list[string]]]: values in self reported race/ethnicity column that can be combined with 1000 genomes EAS group
// sampleFileSASCodes [optional[list[string]]]: values in self reported race/ethnicity column that can be combined with 1000 genomes SAS group
sampleFile = .../1kg_phenotypes.tsv
sampleFileId = Sample
sampleFileSrSex = isFemale
sampleFileMaleCode = 0
sampleFileFemaleCode = 1
sampleFileSrRace = SuperPopulation
sampleFileAFRCodes = [AFR]
sampleFileAMRCodes = [AMR]
sampleFileEURCodes = [EUR]
sampleFileEASCodes = [EAS]
sampleFileSASCodes = [SAS]

// Pipeline architecture settings

// optional list of numeric filters for variants
// id [string]: can be any alphanumeric string and may include underscores
// field [string]: must start with full column name from variant stats file ('variant_qc_raw' and 'variant_qc') followed by '.' or start with 'annotation.' to use VEP column names
// range [string]: mathematical notation for variants to include in filtered variants
numericVariantFilters = [
  {
    id = rawcr98
    field = variant_qc_raw.call_rate
    range = "[0.98,)"
  }
]

// optional list of boolean filters for variants
// id [string]: can be any alphanumeric string and may include underscores
// field [string]: must start with full column name from variant stats file ('variant_qc_raw' and 'variant_qc') followed by '.' or start with 'annotation.' to use VEP column names
// value [boolean]: include variants where either true or false
booleanVariantFilters = []

// optional list of categorical filters for variants
// id [string]: can be any alphanumeric string and may include underscores
// field [string]: must start with full column name from variant stats file ('variant_qc_raw' and 'variant_qc') followed by '.' or start with 'annotation.' to use VEP column names
// incl [list[string]]: list of values from column to include in filtered variants
// excl [list[string]]: list of values from column to exclude in filtered variants
// substrings [boolean]: either true or false to indicate if string can be a substring of column value
categoricalVariantFilters = []

// optional list of categorical filters for variants
// id [string]: can be any alphanumeric string and may include underscores
// filter [string]: mathematical notation combining only existing filter id's from above
compoundVariantFilters = []

// optional list of numeric filters for samples (required attributes analogous to variant filters above)
numericSampleFilters = [
  {
    id = cr95
    field = sample_qc.call_rate
    range = "[0.95,)"
  }

// optional list of boolean filters for samples (required attributes analogous to variant filters above)]
booleanSampleFilters = []

// optional list of categorical filters for samples (required attributes analogous to variant filters above)
categoricalSampleFilters = []

// optional list of compound filters for samples (required attributes analogous to variant filters above)
compoundSampleFilters = []

// list of individual genotyping arrays and/or sequence data to include in analysis
// id [string]: can be any alphanumeric string and may include underscores
// filename [string]: file name of input data
// format [string]: either plink (ie. bed/bim/fam), vcf, or mt (ie. a hail matrix table)
// technology [string]: either gwas (this would include illumina genotyping arrays and exome chip arrays), wgs (ie. whole genome sequencing), or wes (ie. whole exome sequencing)
// description [string]: a description of the dataset
// keepIndels [boolean]: keep insertion/deletion variant, either true or false
// minPartitions [integer]: the minimum number of hail matrix table partitions to use (default = 1, but hail will partition to maintain a certain maximum size for each part)
// liftOver [optional[string]]: a liftover chain file to trigger a desired update in coordinates
// sampleQcMetrics [optional[list[string]]]: list of sample qc metrics from one of two lists
//   options for gwas technology: [n_non_ref,n_het,n_called,call_rate,r_ti_tv,het,het_low,het_high,n_hom_var,r_het_hom_var]
//   options for wgs or wes technology: [n_non_ref,n_het,n_called,call_rate,r_ti_tv,het,het_low,het_high,n_hom_var,r_het_hom_var,n_singleton,avg_ab,avg_ab50]
// nSampleMetricPcs [integer]: number of PCs to include when calculating adjusted residuals of sample metrics
// sampleMetricCovars [optional[list[string]]]: covariates to include when calculating adjusted residuals of sample metrics
// chrs [list[string]]: list of chromosomes to include in analysis (can use 1-22 or equivalent to indicate range of autosomal chromosomes and must follow reference genome nomenclature)
// gqThreshold [optional[integer]]: threshold under which GT and NALT entries are set to missing during calculation
// ancestryOutliersKeep [optional[string]]: a file containing a list of sample individual id's to keep during ancestry outlier identification
// duplicatesKeep [optional[string]]: a file containing a list of sample individual id's to keep during duplicate identification
// famsizeKeep [optional[string]]: a file containing a list of sample individual id's to keep during fam size filtering
// sampleqcKeep [optional[string]]: a file containing a list of sample individual id's to keep during sample quality control
// sexcheckKeep [optional[string]]: a file containing a list of sample individual id's to keep during sex check
// qcVariantFilters [optional[list[string]]]: list of variant filter ids from above to use for sample quality control
// qcVariantSampleN [optional[integer]]: the number of desired variants in the final QC data set (will be ignored if remaining variant count is less than this number: default: 1000)
// qcVariantSampleSeed [optional[integer]]: a seed number to allow for reproducibility in sampling variants (default: 1)
// postQcSampleFilters [optional[list[string]]]: list of sample filter ids from above to use during final sample qc
// postQcVariantFilters [optional[list[string]]]: list of variant filter ids from above to use during final variant qc
// exportCleanBgen [boolean]: write a clean bgen format file in addition to vcf
arrays = [
  {
    id = S1
    filename = .../1kg.set1.GRCh38.with_rsids
    format = plink
    technology = gwas
    description = "1000 Genomes GWAS"
    keepIndels = true
    chrs = ["1-22",X]
    ancestryOutliersKeep = []
    duplicatesKeep = []
    famsizeKeep = []
    sampleqcKeep = []
    sexcheckKeep = []
    gqThreshold = 20
    nSampleMetricPcs = 3
    sampleMetricCovars = ["[isFemale]"]
    qcVariantFilters = [rawcr98,rawaf19,rawhwe1e6]
    qcVariantSampleN = 7500
    qcVariantSampleSeed = 1
    postQcSampleFilters = [cr95]
    postQcVariantFilters = [cr3,het1]
    exportCleanBgen = true
  }
]

// Cluster resources

// Hail matrix table cluster config
mtCluster: {
  zone: "us-central1-a",
  properties: "spark:spark.driver.extraJavaOptions=-Xss4M,spark:spark.executor.extraJavaOptions=-Xss4M,spark:spark.driver.memory=16g,spark:spark.driver.maxResultSize=0,spark:spark.task.maxFailures=20,spark:spark.kryoserializer.buffer.max=1g,hdfs:dfs.replication=1",
  masterMachineType: "n1-highmem-2",
  masterBootDiskSize: 64,
  workerMachineType: "n1-standard-2",
  workerBootDiskSize: 30,
  numWorkers: 2,
  numPreemptibleWorkers: 0,
  preemptibleWorkerBootDiskSize: 30,
  maxClusterIdleTime: "10m"
}

// Variant hail table cluster config
variantHtCluster: {
  zone: "us-central1-a",
  properties: "spark:spark.driver.extraJavaOptions=-Xss4M,spark:spark.executor.extraJavaOptions=-Xss4M,spark:spark.driver.memory=16g,spark:spark.driver.maxResultSize=0,spark:spark.task.maxFailures=20,spark:spark.kryoserializer.buffer.max=1g,hdfs:dfs.replication=1",
  masterMachineType: "n1-highmem-2",
  masterBootDiskSize: 64,
  workerMachineType: "n1-standard-2",
  workerBootDiskSize: 30,
  numWorkers: 2,
  numPreemptibleWorkers: 0,
  preemptibleWorkerBootDiskSize: 30,
  maxClusterIdleTime: "10m"
}

// Local machine resources
// cpus [integer]: number of cpus to allocate
// mem [integer]: number of gigabytes to allocate for each cpu
// maxRunTime [integer]: number of hours to allocate

// Hail matrix table
matrixTableHail: { cpus: 8, mem: 4, maxRunTime: 2}

// Hail table
tableHail: { cpus: 4, mem: 4, maxRunTime: 2}

// Plink
standardPlink: { cpus: 1, mem: 3, maxRunTime: 2}
highMemPlink: { cpus: 1, mem: 8, maxRunTime: 2}
standardPlinkMultiCpu: { cpus: 2, mem: 4, maxRunTime: 4 }

// R
standardR: { cpus: 1, mem: 2, maxRunTime: 2}
highMemR: { cpus: 1, mem: 8, maxRunTime: 2}

// flashPca
flashPca: { cpus: 1, mem: 8, maxRunTime: 2}

// liftOver
liftOver: { cpus: 1, mem: 3, maxRunTime: 2}

// Genotype Harmonizer
genotypeHarmonizer: { cpus: 1, mem: 3, maxRunTime: 2}

// Python
standardPython: { cpus: 1, mem: 3, maxRunTime: 2}

// VEP
vep: { cpus: 2, mem: 4, maxRunTime: 6}

// King
king: { cpus: 1, mem: 3, maxRunTime: 2}

// Klustakwik
klustakwik: { cpus: 1, mem: 3, maxRunTime: 2}

// Tabix
tabix: { cpus: 2, mem: 4, maxRunTime: 2}

// Bgenix
bgenix: { cpus: 1, mem: 3, maxRunTime: 48 }
