import binaries._
import cloud_helpers._
import config._
import scripts._
import store_helpers._

import loamstream.conf.DataConfig
import loamstream.googlecloud.HailSupport._
import loamstream.model.Store
import loamstream.util.Files

val nChr = endChr - startChr + 1
val kgSampleId = dataConfig.getStr("kgSampleId")
val kgSamplePop = dataConfig.getStr("kgSamplePop")
val kgSampleGroup = dataConfig.getStr("kgSampleGroup")
val kgVcfBaseWild = dataConfig.getStr("kgVcfBaseWild")
val kgLegendWild = dataConfig.getStr("kgLegendWild")
val humanReferenceWild = dataConfig.getStr("humanReferenceWild")
val phenoFile = dataConfig.getStr("pheno")
val phenoId = dataConfig.getStr("phenoId")
val phenoSrSex = dataConfig.getStr("phenoSrSex")
val phenoSrRace = dataConfig.getStr("phenoSrRace")
val phenoStatus = dataConfig.getStr("phenoStatus")
val nArrays = dataConfig.getObjList("arrays").size
val nMetrics = sampleQcMetrics.size

// generate list of tuples that define each association test
var assocSeq: Seq[(String, String, String, String, String)] = Seq()

for { assoc <- dataConfig.getObjList("assocs") } 
  {
    for { test <- assoc.getStrList("tests") }
      {
	    for { covars <- assoc.getStrList("covars") }
	      {
	    	assocSeq = assocSeq :+ (
	    	  (assoc.getStr("pheno"),
	    		test,
	    		covars,
	    		assoc.getStr("trans"),
	    		assoc.getStr("strat"))
	    	  )  
	      }
      }
  }

object Input {

  object Local {
    val kgSample = store[TXT].at(path(dataConfig.getStr("kgSample"))).asInput
    val pheno = store[TXT].at(path(phenoFile)).asInput
  }

  object Google {
    val kgPurcellVcf = store[VCF].at(uri(dataConfig.getStr("kgPurcellVcfGoogle"))).asInput
    val kgSample = store[TXT].at(uri(dataConfig.getStr("kgSampleGoogle"))).asInput
    val regionsExclude = store[TXT].at(uri(dataConfig.getStr("regionsExcludeGoogle"))).asInput
    val pheno = store[TXT].at(googleOutDir / s"${phenoFile}".split("/").last)
  }

}

object Params {

  final case class Chr(
    rawChrName: Path,
    rawChr: Seq[Store[TXT]],
    harmKgChrName: Path,
    harmKgHuRefChrName: Path,
    harmKgChr: Seq[Store[TXT]],
    harmKgHuRefChr: Seq[Store[TXT]],
    kgVcfChr: Store[VCF],
    kgLegendChr: Store[TXT],
    humanReference: Store[TXT],
    harmKgChrRemove: Store[TXT],
    harmKgChrNonKgFlip: Store[TXT],
    harmKgChrForceA1: Store[TXT],
    harmKgChrVarIdUpdate: Store[TXT],
    harmKgChrVarSnpLog: Store[TXT],
    harmMergeLine: String)

  final case class Metric(
    sampleqcStatsAdjIndMetric: String,
    sampleqcStatsAdjIndClusterName: Path,
    sampleqcStatsAdjIndClusterFet: Store[TXT],
    sampleqcStatsAdjIndClusterClu: Store[TXT],
    sampleqcStatsAdjIndClusterKlg: Store[TXT],
    sampleqcStatsAdjIndClusterKlustakwikLog: Store[TXT])

  final case class Assoc(
    assocPheno: String,
    assocTest: String,
    assocCovars: String,
    assocTrans: String,
    assocStrat: String,
    assocPhenoPrelimFile: Store[TXT],
    assocPhenoPrelimFileCloud: Store[TXT],
    assocSamplesInclude: Store[TXT],
    assocSamplesIncludeCloud: Store[TXT],
    assocPhenoFileLog: Store[TXT],
    assocPhenoFile: Store[TXT],
    assocPcsFile: Store[TXT],
    assocPhenoFileCloud: Store[TXT],
    assocPcsFileCloud: Store[TXT],
    assocResults: Store[TXT],
    assocResultsTbi: Store[TXT],
    assocResultsCloud: Store[TXT])

  final case class Result(
    resultPheno: String,
    resultTest: String,
    resultCovars: String,
    resultTrans: String,
    resultStrat: String,
    resultFinal: Store[TXT],
    resultFinalTbi: Store[TXT],
    resultFinalCloud: Store[TXT],
    resultFinalQqPlot: Store[TXT],
    resultFinalMhtPlot: Store[TXT],
    resultFinalSigRegions: Store[TXT],
    resultFinalRegplotName: String)

  final case class Arr(
    arrayId: String,
    harmName: Path,
    harm: Seq[Store[TXT]],
    harmRefName: Path,
    harmRefVcf: Store[VCF],
    harmRefVcfCloud: Store[VCF],
    harmRefVcfTbi: Store[TXT],
    harmRefVcfTbiCloud: Store[VCF],
    harmRefVdsCloud: Store[VCF],
    harmRefFiltNameCloud: URI,
    harmRefFiltCloud: Seq[Store[TXT]],
    harmRefFiltVdsCloud: Store[VCF],
    harmRefFiltVariantQcCloud: Store[TXT],
    harmRefFiltVariantsPrunedInCloud: Store[TXT],
    harmRefFiltPrunedName: Path,
    harmRefFiltPruned: Seq[Store[TXT]],
    harmRefFiltPrunedNameCloud: URI,
    harmRefFiltPrunedCloud: Seq[Store[TXT]],
    harmRefFiltPrunedVdsCloud: Store[VCF],
    paramsByArrByChr: Seq[(Int, Chr)],
    paramsByArrByAssoc: Seq[(Int, Assoc)],
    paramsByArrByMetric: Seq[(Int, Metric)],
    paramsByArrByChrSorted: Seq[Chr],
    paramsByArrByAssocSorted: Seq[Assoc],
    paramsByArrByMetricSorted: Seq[Metric],
    harmMergeLines: Seq[String],
    harmMergeList: Store[TXT],
    sampleqcStatsAdjIndClusterCluList: Seq[String],
    harmForceA2: Store[TXT],
    kinName: Path,
    kinLog: Store[TXT],
    kinTmpDat: Store[TXT],
    kinTmpPed: Store[TXT],
    kinKin: Store[TXT],
    kinKin0: Store[TXT],
    kinKin0Related: Store[TXT],
    kinFamsizes: Store[TXT],
    ancestryPcaName: Path,
    harmRef1kgName: Path,
    harmRef1kg: Seq[Store[TXT]],
    harmRef1kgGds: Store[TXT],
    ancestryPcaLog: Store[TXT],
    ancestryPcaScores: Store[TXT],
    ancestryPcaScoresPlots: Store[TXT],
    harmRef1kgNameCloud: URI,
    harmRef1kgCloud: Seq[Store[TXT]],
    ancestryClusterName: Path,
    ancestryClusterLog: Store[TXT],
    ancestryClusterFet: Store[TXT],
    ancestryClusterClu: Store[TXT],
    ancestryClusterKlg: Store[TXT],
    ancestryClusterPlots: Store[TXT],
    ancestryClusterPlotsCenters: Store[TXT],
    ancestryClusterPlotsNo1kg: Store[TXT],
    ancestryClusterXtabs: Store[TXT],
    ancestryClusterGroups: Store[TXT],
    ancestryInferred: Store[TXT],
    harmRefFiltPrunedPcaGds: Store[TXT],
    pcaLog: Store[TXT],
    pcaScores: Store[TXT],
    sampleqcStats: Store[TXT],
    sampleqcStatsAdj: Store[TXT],
    sampleqcStatsAdjCorrPlots: Store[TXT],
    sampleqcStatsAdjPcaLoadings: Store[TXT],
    sampleqcStatsAdjPcaScoresPlots: Store[TXT],
    sampleqcStatsAdjPcaScores: Store[TXT],
	sampleqcSexcheck: Store[TXT],
    sampleqcSexcheckProblems: Store[TXT],
    sampleqcSexcheckCloud: Store[TXT],
    sampleqcSexcheckProblemsCloud: Store[TXT],
    sampleqcStatsCloud: Store[TXT],
    sampleqcStatsAdjClusterFet: Store[TXT],
    sampleqcStatsAdjClusterClu: Store[TXT],
    sampleqcStatsAdjClusterKlg: Store[TXT],
    sampleqcStatsAdjClusterKlustakwikLog: Store[TXT],
    sampleqcStatsAdjClusterOutliers: Store[TXT],
    sampleqcStatsAdjClusterPlots: Store[TXT],
    sampleqcStatsAdjClusterXtabs: Store[TXT],
    sampleqcStatsAdjClusterName: Path,
    sampleqcStatsAdjIndBoxplots: Store[TXT],
    sampleqcStatsAdjIndDiscreteness: Store[TXT],
    sampleqcStatsAdjOutliersTable: Store[TXT],
    sampleqcStatsAdjStripchart: Store[TXT],
    finalSampleExclusions: Store[TXT],
    finalSampleExclusionsCloud: Store[TXT],
    variantqcStats: Store[TXT],
    variantqcStatsCloud: Store[TXT],
    finalVariantExclusions: Store[TXT],
    finalVariantExclusionsCloud: Store[TXT],
    clean: Seq[Store[TXT]],
    cleanNameCloud: URI,
    cleanCloud: Seq[Store[TXT]],
    cleanVcf: Store[VCF],
    cleanVcfCloud: Store[VCF],
    cleanVcfTbi: Store[TXT],
    cleanVdsCloud: Store[VCF])

  val paramsByResult: Seq[(Int, Result)] = (0 until assocSeq.size).map { result =>

    val resultPheno = assocSeq(result)._1
    val resultTest = assocSeq(result)._2
    val resultCovars = assocSeq(result)._3
    val resultTrans = assocSeq(result)._4
    val resultStrat = assocSeq(result)._5

    val covarsString = resultCovars.replace("+","_")

    result -> Result(
      resultPheno = resultPheno,
      resultTest = resultTest,
      resultCovars = resultCovars,
      resultTrans = resultTrans,
      resultStrat = resultStrat,
      resultFinal = store[TXT].at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.tsv.gz"),
      resultFinalTbi = store[TXT].at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.tsv.gz.tbi"),
      resultFinalCloud = store[TXT].at(googleOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.results.tsv.gz"),
      resultFinalQqPlot = store[TXT].at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.qq.png"),
      resultFinalMhtPlot = store[TXT].at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.mht.png"),
      resultFinalSigRegions = store[TXT].at(localOutDir / s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.sigregions.tsv"),
      resultFinalRegplotName = s"${projectId}.assoc.$resultPheno.$resultTrans.$covarsString.$resultTest.regplot")

  }

  val paramsByArr: Seq[(Int, Arr)] = (0 until nArrays).map { arr =>

    val arrayId = dataConfig.getObjList("arrays")(arr).getStr("arrayId")

    val paramsByArrByChr = (startChr to endChr).map { chr =>

      val rawChrBase = s"${projectId}.${arrayId}.chr$chr"
      val harmKgChrBase = s"${rawChrBase}.harmkg"
      val harmKgChrName = localOutDir / harmKgChrBase
      val harmKgHuRefChrName = localOutDir / s"${harmKgChrBase}.huref"
      val rawChrName = localOutDir / rawChrBase
      val kgVcfChr = store[VCF].at(
          kgVcfBaseWild
            .replace("[CHROMOSOME]", s"$chr")
            .replace("23.phase3_shapeit2_mvncall_integrated_v5a",
                     "X.phase3_shapeit2_mvncall_integrated_v1b") + ".vcf.gz").asInput
      val kgLegendChr = store[TXT].at(
          kgLegendWild
            .replace("[CHROMOSOME]", s"$chr")
            .replace("23",
                     "X")).asInput
      val humanReference = store[TXT].at(
          humanReferenceWild
            .replace("[CHROMOSOME]", s"$chr")
            .replace("23",
                     "X")).asInput

      chr -> Chr(
        rawChrName = rawChrName,
        rawChr = bedBimFam(rawChrName),
        harmKgChrName = harmKgChrName,
        harmKgHuRefChrName = harmKgHuRefChrName,
        harmKgChr = bedBimFam(harmKgChrName),
        harmKgHuRefChr = bedBimFam(harmKgHuRefChrName),
        kgVcfChr = kgVcfChr,
        kgLegendChr = kgLegendChr,
        humanReference = humanReference,
        harmKgChrRemove = store[TXT].at(localOutDir / s"${harmKgChrBase}.remove"),
        harmKgChrNonKgFlip = store[TXT].at(localOutDir / s"${harmKgChrBase}.nonkg.flip"),
        harmKgChrForceA1 = store[TXT].at(localOutDir / s"${harmKgChrBase}.force_a1"),
        harmKgChrVarIdUpdate = store[TXT].at(localOutDir / s"${harmKgChrBase}_idUpdates.txt"),
        harmKgChrVarSnpLog = store[TXT].at(localOutDir / s"${harmKgChrBase}_snpLog.log"),
        harmMergeLine = s"${localOutDir}/${harmKgChrBase}")
    }

    val paramsByArrByAssoc = (0 until assocSeq.size).map { assoc =>

      val assocPheno = assocSeq(assoc)._1
      val assocTest = assocSeq(assoc)._2
      val assocCovars = assocSeq(assoc)._3
      val assocTrans = assocSeq(assoc)._4
      val assocStrat = assocSeq(assoc)._5

      val covarsString = assocCovars.replace("+","_")

      assoc -> Assoc(
        assocPheno = assocPheno,
        assocTest = assocTest,
        assocCovars = assocCovars,
        assocTrans = assocTrans,
        assocStrat = assocStrat,
        assocPhenoPrelimFile = store[TXT].at(localOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.prelim_pheno.tsv"),
        assocPhenoPrelimFileCloud = store[TXT].at(googleOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.prelim_pheno.tsv"),
        assocSamplesInclude = store[TXT].at(localOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.samples.include"),
        assocSamplesIncludeCloud = store[TXT].at(googleOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.samples.include"),
        assocPhenoFileLog = store[TXT].at(localOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.pheno.log"),
        assocPhenoFile = store[TXT].at(localOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.pheno.tsv"),
        assocPcsFile = store[TXT].at(localOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.pcs.include"),
        assocPhenoFileCloud = store[TXT].at(googleOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.pheno.tsv"),
        assocPcsFileCloud = store[TXT].at(googleOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.pcs.include"),
        assocResults = store[TXT].at(localOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.results.tsv.gz"),
        assocResultsTbi = store[TXT].at(localOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.results.tsv.gz.tbi"),
        assocResultsCloud = store[TXT].at(googleOutDir / s"${projectId}.${arrayId}.assoc.$assocPheno.$assocTrans.$covarsString.$assocTest.results.tsv.gz"))

    }

    val sampleqcBase = s"${projectId}.${arrayId}.sampleqc"
    val sampleqcStatsAdjBase = s"${sampleqcBase}.stats.adj"

    val paramsByArrByMetric = (0 until nMetrics).map { metricIdx =>

      val sampleqcStatsAdjIndMetric = sampleQcMetrics(metricIdx)
      val sampleqcStatsAdjIndClusterBase = s"${sampleqcStatsAdjBase}.${sampleqcStatsAdjIndMetric}"

      metricIdx -> Metric(
        sampleqcStatsAdjIndMetric = sampleqcStatsAdjIndMetric,
        sampleqcStatsAdjIndClusterName = localOutDir / sampleqcStatsAdjIndClusterBase,
        sampleqcStatsAdjIndClusterFet = store[TXT].at(localOutDir / s"${sampleqcStatsAdjIndClusterBase}.fet.1"),
        sampleqcStatsAdjIndClusterClu = store[TXT].at(localOutDir / s"${sampleqcStatsAdjIndClusterBase}.clu.1"),
        sampleqcStatsAdjIndClusterKlg = store[TXT].at(localOutDir / s"${sampleqcStatsAdjIndClusterBase}.klg.1"),
        sampleqcStatsAdjIndClusterKlustakwikLog = store[TXT].at(localOutDir / s"${sampleqcStatsAdjIndClusterBase}.klustakwik.log"))
    }

    val harmBase = s"${projectId}.${arrayId}.harm"
    val harmName = localOutDir / harmBase
    val harmRefBase = s"${harmBase}.ref"
    val harmRefFiltBase = s"${harmRefBase}.filt"
    val harmRefFiltPrunedBase = s"${harmRefFiltBase}.pruned"
    val harmRefFiltPrunedName = localOutDir / harmRefFiltPrunedBase
    val harmRefFiltPrunedNameCloud = googleOutDir / s"${harmRefFiltBase}.pruned"
    val harmRefFiltName = localOutDir / harmRefFiltBase
    val kinBase = s"${projectId}.${arrayId}.kinship"
    val harmRef1kgBase = s"${projectId}.${arrayId}.harm.ref.1kg"
    val harmRef1kgName = localOutDir / harmRef1kgBase
    val harmRef1kgNameCloud = googleOutDir / harmRef1kgBase
    val pcaBase = s"${projectId}.${arrayId}.pca"
    val ancestryBase = s"${projectId}.${arrayId}.ancestry"
    val ancestryPcaBase = s"${ancestryBase}.pca"
    val ancestryClusterBase = s"${projectId}.${arrayId}.ancestry.cluster"
    val sampleqcSexcheckBase = s"${projectId}.${arrayId}.sampleqc.sexcheck"
    val sampleqcStatsAdjOutliersTableBase = s"${sampleqcBase}.outliers.tsv"
    val finalBase = s"${projectId}.${arrayId}.final"
    val cleanBase = s"${projectId}.${arrayId}.clean"
    val cleanName = localOutDir / cleanBase
    val cleanNameCloud = googleOutDir / cleanBase
    val sampleqcStatsAdjClusterBase = s"${sampleqcBase}.stats.adj.cluster"
    val sampleqcStatsAdjClusterName = localOutDir / sampleqcStatsAdjClusterBase
    val variantqcBase = s"${projectId}.${arrayId}.variantqc"

    val (_, paramsByArrByChrSorted) = paramsByArrByChr.unzip
    val harmMergeLines = paramsByArrByChrSorted.map(_.harmKgHuRefChrName.toString)
	val (_, paramsByArrByAssocSorted) = paramsByArrByAssoc.unzip
    val (_, paramsByArrByMetricSorted) = paramsByArrByMetric.unzip
    val sampleqcStatsAdjIndClusterCluList = paramsByArrByMetricSorted.map(_.sampleqcStatsAdjIndClusterClu.toString)

    arr -> Arr(
    arrayId = arrayId,
    paramsByArrByChr = paramsByArrByChr,
    paramsByArrByAssoc = paramsByArrByAssoc,
    paramsByArrByMetric = paramsByArrByMetric,
    harmName = harmName,
    harm = bedBimFam(harmName),
    harmRefName = localOutDir / harmRefBase,
    harmRefVcf = store[VCF].at(localOutDir / s"${harmRefBase}.vcf.gz"),
    harmRefVcfCloud = store[VCF].at(googleOutDir / s"${harmRefBase}.vcf.gz"),
    harmRefVcfTbi = store[TXT].at(localOutDir / s"${harmRefBase}.vcf.gz.tbi"),
    harmRefVcfTbiCloud = store[VCF].at(googleOutDir / s"${harmRefBase}.vcf.gz.tbi"),
    harmRefVdsCloud = store[VCF].at(googleOutDir / s"${harmRefBase}.vds"),
    paramsByArrByChrSorted = paramsByArrByChrSorted,
    paramsByArrByAssocSorted = paramsByArrByAssocSorted,
    paramsByArrByMetricSorted = paramsByArrByMetricSorted,
    harmMergeLines = harmMergeLines,
    sampleqcStatsAdjIndClusterCluList = sampleqcStatsAdjIndClusterCluList,
    harmMergeList = store[TXT].at(localOutDir / s"${harmBase}.merge.txt"),
    harmForceA2 = store[TXT].at(localOutDir / s"${harmBase}.force_a2.txt"),
    harmRefFiltNameCloud = googleOutDir / harmRefFiltBase,
    harmRefFiltCloud = bedBimFam(googleOutDir / harmRefFiltBase),
    harmRefFiltVdsCloud = store[VCF].at(googleOutDir / s"${harmRefFiltBase}.vds"),
    harmRefFiltVariantQcCloud = store[TXT].at(googleOutDir / s"${harmRefFiltBase}.variantqc.tsv"),
    harmRefFiltVariantsPrunedInCloud = store[TXT].at(googleOutDir / s"${harmRefFiltPrunedBase}.in"),
    harmRefFiltPrunedName = harmRefFiltPrunedName,
    harmRefFiltPruned = bedBimFam(harmRefFiltPrunedName),
    harmRefFiltPrunedNameCloud = harmRefFiltPrunedNameCloud,
    harmRefFiltPrunedCloud = bedBimFam(harmRefFiltPrunedNameCloud),
    harmRefFiltPrunedVdsCloud = store[VCF].at(googleOutDir / s"${harmRefFiltPrunedBase}.vds"),
    kinName = localOutDir / kinBase,
    kinLog = store[TXT].at(localOutDir / s"${kinBase}.log"),
    kinTmpDat = store[TXT].at(localOutDir / s"${kinBase}TMP.dat"),
    kinTmpPed = store[TXT].at(localOutDir / s"${kinBase}TMP.ped"),
    kinKin = store[TXT].at(localOutDir / s"${kinBase}.kin"),
    kinKin0 = store[TXT].at(localOutDir / s"${kinBase}.kin0"),
    kinKin0Related = store[TXT].at(localOutDir / s"${kinBase}.kin0.related"),
    kinFamsizes = store[TXT].at(localOutDir / s"${kinBase}.famsizes.tsv"),
    ancestryPcaName = localOutDir / ancestryPcaBase,
    harmRef1kgName = harmRef1kgName,
    harmRef1kg = bedBimFam(harmRef1kgName),
    harmRef1kgGds = store[TXT].at(localOutDir / s"${harmRef1kgBase}.gds"),
    ancestryPcaLog = store[TXT].at(localOutDir / s"${ancestryPcaBase}.log"),
    ancestryPcaScores = store[TXT].at(localOutDir / s"${ancestryPcaBase}.scores.tsv"),
    ancestryPcaScoresPlots = store[TXT].at(localOutDir / s"${ancestryPcaBase}.scores.plots.pdf"),
    harmRef1kgNameCloud = harmRef1kgNameCloud,
    harmRef1kgCloud = bedBimFam(harmRef1kgNameCloud),
    ancestryClusterName = localOutDir / ancestryClusterBase,
    ancestryClusterLog = store[TXT].at(localOutDir / s"${ancestryClusterBase}.log"),
    ancestryClusterFet = store[TXT].at(localOutDir / s"${ancestryClusterBase}.fet.1"),
    ancestryClusterClu = store[TXT].at(localOutDir / s"${ancestryClusterBase}.clu.1"),
    ancestryClusterKlg = store[TXT].at(localOutDir / s"${ancestryClusterBase}.klg.1"),
    ancestryClusterPlots = store[TXT].at(localOutDir / s"${ancestryClusterBase}.plots.pdf"),
    ancestryClusterPlotsCenters = store[TXT].at(localOutDir / s"${ancestryClusterBase}.plots.centers.pdf"),
    ancestryClusterPlotsNo1kg = store[TXT].at(localOutDir / s"${ancestryClusterBase}.plots.no_1kg.pdf"),
    ancestryClusterXtabs = store[TXT].at(localOutDir / s"${ancestryClusterBase}.xtabs"),
    ancestryClusterGroups = store[TXT].at(localOutDir / s"${ancestryClusterBase}.groups.tsv"),
    ancestryInferred = store[TXT].at(localOutDir / s"${ancestryBase}.inferred.tsv"),
    harmRefFiltPrunedPcaGds = store[TXT].at(localOutDir / s"${harmRefFiltPrunedBase}.pca.gds"),
    pcaLog = store[TXT].at(localOutDir / s"${pcaBase}.log"),
    pcaScores = store[TXT].at(localOutDir / s"${pcaBase}.scores.tsv"),
    sampleqcStats = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.tsv"),
    sampleqcStatsAdj = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.adj.tsv"),
    sampleqcStatsAdjCorrPlots = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.adj.corr.pdf"),
    sampleqcStatsAdjPcaLoadings = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.adj.pca.loadings.tsv"),
    sampleqcStatsAdjPcaScoresPlots = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.adj.pca.plots.pdf"),
    sampleqcStatsAdjPcaScores = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.adj.pca.scores.tsv"),
	sampleqcSexcheck = store[TXT].at(localOutDir / s"${sampleqcSexcheckBase}.tsv"),
    sampleqcSexcheckProblems = store[TXT].at(localOutDir / s"${sampleqcSexcheckBase}.problems.tsv"),
    sampleqcSexcheckCloud = store[TXT].at(googleOutDir / s"${sampleqcSexcheckBase}.tsv"),
    sampleqcSexcheckProblemsCloud = store[TXT].at(googleOutDir / s"${sampleqcSexcheckBase}.problems.tsv"),
    sampleqcStatsCloud = store[TXT].at(googleOutDir / s"${sampleqcBase}.stats.tsv"),
    sampleqcStatsAdjClusterName = sampleqcStatsAdjClusterName,
    sampleqcStatsAdjClusterFet = store[TXT].at(localOutDir / s"${sampleqcStatsAdjClusterBase}.fet.1"),
    sampleqcStatsAdjClusterClu = store[TXT].at(localOutDir / s"${sampleqcStatsAdjClusterBase}.clu.1"),
    sampleqcStatsAdjClusterKlg = store[TXT].at(localOutDir / s"${sampleqcStatsAdjClusterBase}.klg.1"),
    sampleqcStatsAdjClusterKlustakwikLog = store[TXT].at(localOutDir / s"${sampleqcStatsAdjClusterBase}.klustakwik.log"),
    sampleqcStatsAdjClusterOutliers = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.adj.cluster.outliers"),
    sampleqcStatsAdjClusterPlots = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.adj.cluster.plots.pdf"),
    sampleqcStatsAdjClusterXtabs = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.adj.cluster.xtabs"),
    sampleqcStatsAdjIndBoxplots = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.adj.ind.boxplots.pdf"),
    sampleqcStatsAdjIndDiscreteness = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.adj.ind.discreteness"),
    sampleqcStatsAdjOutliersTable = store[TXT].at(localOutDir / sampleqcStatsAdjOutliersTableBase),
    sampleqcStatsAdjStripchart = store[TXT].at(localOutDir / s"${sampleqcBase}.stats.adj.stripchart.pdf"),
    finalSampleExclusions = store[TXT].at(localOutDir / s"${finalBase}.sample.exclusions"),
    finalSampleExclusionsCloud = store[TXT].at(googleOutDir / s"${finalBase}.sample.exclusions"),
    variantqcStats = store[TXT].at(localOutDir / s"${variantqcBase}.stats.tsv"),
    variantqcStatsCloud = store[TXT].at(googleOutDir / s"${variantqcBase}.stats.tsv"),
	finalVariantExclusions = store[TXT].at(localOutDir / s"${finalBase}.variant.exclusions"),
	finalVariantExclusionsCloud = store[TXT].at(googleOutDir / s"${finalBase}.variant.exclusions"),
    clean = bedBimFam(cleanName),
    cleanNameCloud = cleanNameCloud,
    cleanCloud = bedBimFam(cleanNameCloud),
    cleanVcf = store[VCF].at(localOutDir / s"${cleanBase}.vcf.bgz"),
    cleanVcfTbi = store[TXT].at(localOutDir / s"${cleanBase}.vcf.bgz.tbi"),
    cleanVcfCloud = store[VCF].at(googleOutDir / s"${cleanBase}.vcf.bgz"),
    cleanVdsCloud = store[VCF].at(googleOutDir / s"${cleanBase}.vds"))
    }

}

// Perform qc1
val ancestryInferredStores: Seq[Store[TXT]] = {
  for {
    i <- 0 until nArrays
  } yield { 
    qc1(i)
  }
}

// Reconcile inferred ancestry step
val ancestryInferredPathList = ancestryInferredStores.map(_.path).mkString(",")
val ancestryInferredMerged = store[TXT].at(localOutDir / s"${projectId}.ancestry.inferred.merged.tsv")
val ancestryInferredMergedCloud = store[TXT].at(googleOutDir / s"${projectId}.ancestry.inferred.merged.tsv")
val ancestryInferredMergedOutliers = store[TXT].at(localOutDir / s"${projectId}.ancestry.inferred.merged.outliers.tsv")

local {
  cmd"""$binRscript --vanilla --verbose
    $rAncestryClusterMerge
    --ancestry-in $ancestryInferredPathList
    --out-table ${ancestryInferredMerged}
    --out-outliers ${ancestryInferredMergedOutliers}""".in(ancestryInferredStores).out(ancestryInferredMerged, ancestryInferredMergedOutliers).using("R-3.4")
}

// Perform qc2, adding relevent (inter-array) stores to the map
val resultsStoresMapsList: Seq[Map[(String, String, String, String, String), Store[TXT]]] = {
  for {
    i <- 0 until nArrays
  } yield { 
    qc2(i)
  }
}

// Combine results step
for {
  i <- 0 until assocSeq.size
} {
  finalizeResults(i)
}

def qc1(i: Int): Store[TXT] = {

  // Global parameters
  val dataPath = dataConfig.getObjList("arrays")(i).getStr("dataPath")
  val dataType = dataConfig.getObjList("arrays")(i).getStr("dataType")

  // Input Stores
  val data = {
    if (dataType == "vcf") { store[VCF].at(path(dataPath)).asInput }
    else { store[TXT].at(path(s"${dataPath}.bed")).asInput }
  }

  val (_, paramsArr) = Params.paramsByArr(i)

  ///**
  //* Params Step
  //*  Description: Align data strand to 1KG reference. Also, update reference allele and variant ID to match 1KG
  //*  Requires: Plink1.9 and, at least, Genotype Harmonizer v1.4.18
  //*  Notes:
  //*     Could also add --variants and --mafAlign as pipeline options, but for now these are static
  //*     To save time, this will be run in parallel by chromosome number
  //*/
  //
  //uger {
  //  for {
  //    (chr, paramsChr) <- paramsArr.paramsByArrByChr
  //  } {
  //    cmd"""$binPlink --$dataType $dataPath --chr $chr --keep-allele-order --make-bed --output-chr MT --out ${paramsChr.rawChrName}"""
  //      .in(data)
  //      .out(paramsChr.rawChr)
  //    
  //    cmd"""$binGenotypeHarmonizer
  //    --input ${paramsChr.rawChrName}
  //    --inputType PLINK_BED
  //    --output ${paramsChr.harmKgChrName}
  //    --outputType PLINK_BED
  //    --ref ${paramsChr.kgVcfChr}
  //    --refType VCF
  //    --keep
  //    --update-id
  //    --variants 1000
  //    --mafAlign 0.1
  //    --update-id
  //    --update-reference-allele
  //    --debug"""
  //      .in(paramsChr.rawChr :+ paramsChr.kgVcfChr)
  //      .out(paramsChr.harmKgChr :+ paramsChr.harmKgChrVarIdUpdate :+ paramsChr.harmKgChrVarSnpLog)
  //
  //    cmd"""python $pyAlignNon1kgVariants
  //    --legend ${paramsChr.kgLegendChr}
  //    --bim ${paramsChr.harmKgChrName}.bim
  //    --ref ${paramsChr.humanReference}
  //    --out-remove ${paramsChr.harmKgChrRemove}
  //    --out-flip ${paramsChr.harmKgChrNonKgFlip}
  //    --out-force-a1 ${paramsChr.harmKgChrForceA1}"""
  //      .in(paramsChr.harmKgChr :+ paramsChr.kgLegendChr)
  //      .out(paramsChr.harmKgChrNonKgFlip, paramsChr.harmKgChrForceA1)
  //
  //    cmd"""$binPlink --bfile ${paramsChr.harmKgChrName} --exclude ${paramsChr.harmKgChrRemove} --flip ${paramsChr.harmKgChrNonKgFlip} --a1-allele ${paramsChr.harmKgChrForceA1} --make-bed --out ${paramsChr.harmKgHuRefChrName}"""
  //      .in(paramsChr.harmKgChr :+ paramsChr.harmKgChrRemove :+ paramsChr.harmKgChrNonKgFlip :+ paramsChr.harmKgChrForceA1)
  //      .out(paramsChr.harmKgHuRefChr)
  //
  //  }
  //
  //  val harmMergeLinesConcat: String = paramsArr.harmMergeLines
  //    .drop(1)
  //    .mkString("\n") // Exclude first chrom
  //  
  //  cmd"""echo "$harmMergeLinesConcat" > ${paramsArr.harmMergeList}"""
  //    .out(paramsArr.harmMergeList)
  //  
  //  cmd"""$binPlink --bfile ${paramsArr.paramsByArrByChrSorted.head.harmKgHuRefChrName} --merge-list ${paramsArr.harmMergeList} --make-bed --keep-allele-order --out ${paramsArr.harmName}"""
  //    .in(paramsArr.paramsByArrByChrSorted.flatMap(_.harmKgHuRefChr) :+ paramsArr.harmMergeList)
  //    .out(paramsArr.harm)
  //  
  //  cmd"""awk '{print $$2,$$5}' ${paramsArr.harmName}.bim > ${paramsArr.harmForceA2}"""
  //    .in(paramsArr.harm)
  //    .out(paramsArr.harmForceA2)
  //  
  //  cmd"""$binPlink --bfile ${paramsArr.harmName} --recode vcf-iid bgz --real-ref-alleles --a2-allele ${paramsArr.harmForceA2} --out ${paramsArr.harmRefName}"""
  //    .in(paramsArr.harm :+ paramsArr.harmForceA2)
  //    .out(paramsArr.harmRefVcf)
  //  
  //  cmd"""$binTabix -f -p vcf ${paramsArr.harmRefVcf}"""
  //    .in(paramsArr.harmRefVcf)
  //    .out(paramsArr.harmRefVcfTbi)
  //}
  //
  ///**
  // * Load Step
  // *  Description: Generate the Hail VDS from VCF file and a sample file containing population and sex information
  // *  Requires: Hail
  // */
  //
  //local {
  //  googleCopy(paramsArr.harmRefVcf, paramsArr.harmRefVcfCloud)
  //  googleCopy(paramsArr.harmRefVcfTbi, paramsArr.harmRefVcfTbiCloud)
  //}
  //
  //google {
  //  hail"""$pyHailLoad
  //    --vcf-in $projectId ${paramsArr.harmRefVcfCloud}
  //    --vds-out ${paramsArr.harmRefVdsCloud}"""
  //    .in(paramsArr.harmRefVcfCloud, paramsArr.harmRefVcfTbiCloud)
  //    .out(paramsArr.harmRefVdsCloud)
  //}
  //
  ///**
  // * Filter Step
  // *  Description: Generate filtered and filtered/pruned filesets for QC
  // *  Requires: Hail
  // */
  //
  //google {
  //  hail"""$pyHailFilter
  //    --vds-in ${paramsArr.harmRefVdsCloud}
  //    --regions-exclude ${Input.Google.regionsExclude}
  //    --variant-qc-out ${paramsArr.harmRefFiltVariantQcCloud}
  //    --variants-prunedin-out ${paramsArr.harmRefFiltVariantsPrunedInCloud}
  //    --filt-vds-out ${paramsArr.harmRefFiltVdsCloud}
  //    --filt-plink-out ${paramsArr.harmRefFiltNameCloud}
  //    --filt-pruned-vds-out ${paramsArr.harmRefFiltPrunedVdsCloud}
  //    --filt-pruned-plink-out ${paramsArr.harmRefFiltPrunedNameCloud}"""
  //    .in(paramsArr.harmRefVdsCloud, Input.Google.regionsExclude)
  //    .out(((paramsArr.harmRefFiltCloud :+ paramsArr.harmRefFiltVdsCloud) ++ (paramsArr.harmRefFiltPrunedCloud :+ paramsArr.harmRefFiltPrunedVdsCloud)) :+ paramsArr.harmRefFiltVariantQcCloud :+ paramsArr.harmRefFiltVariantsPrunedInCloud)
  //}
  //
  //local {
  //  googleCopy(paramsArr.harmRefFiltPrunedCloud, paramsArr.harmRefFiltPruned)
  //}
  //
  ///**
  // * Kinship Step
  // *  Description: Calculate kinship to identify duplicates and any samples exhibiting abnormal (excessive) sharing
  // *  Requires: King, R
  // *  Notes:
  // *     King is preferred to Plink or Hail based IBD calcs due to robust algorithm handling of population stratification. This step should be followed by a visual inspection for duplicates or excessive sharing
  // * King only writes the '.kin0' file if families are found, so a bash script is used to write an empty file in that case
  // */
  //
  //uger {
  //  cmd"""$shKing $binKing ${paramsArr.harmRefFiltPrunedName}.bed ${paramsArr.kinName} ${paramsArr.kinLog} ${paramsArr.kinKin0} ${paramsArr.kinKin0Related}"""
  //  .in(paramsArr.harmRefFiltPruned)
  //  .out(paramsArr.kinLog, paramsArr.kinKin, paramsArr.kinTmpDat, paramsArr.kinTmpPed, paramsArr.kinKin0, paramsArr.kinKin0Related)
  //
  //  cmd"""$binR --vanilla --args ${paramsArr.kinKin0Related} ${paramsArr.kinFamsizes} < ${rCalcKinshipFamSizes}"""
  //  .in(paramsArr.kinKin0Related)
  //  .out(paramsArr.kinFamsizes)
  //}
  //
  ///**
  //  * Ancestry PCA Step
  //  *  Description: Calculate PCs combined with 1KG Phase 3 Purcell 5k data
  //  *  Requires: Hail, R, $rPlotAncestryPca
  //  *  Notes:
  //  *     To perform ancestry inference and clustering with 1KG data, we must combine on common variants with reference data (clustering does not work when only using PCA loadings and projecting)
  //  */
  //
  //google {
  //  hail"""$pyHailAncestryPcaMerge1kg
  //    --vds-in ${paramsArr.harmRefVdsCloud}
  //    --kg-vcf-in ${Input.Google.kgPurcellVcf}
  //    --kg-sample ${Input.Google.kgSample}
  //    --plink-out ${paramsArr.harmRef1kgNameCloud}"""
  //    .in(paramsArr.harmRefVdsCloud, Input.Google.kgPurcellVcf, Input.Google.kgSample)
  //    .out(paramsArr.harmRef1kgCloud)
  //}
  //
  //local {
  //  googleCopy(paramsArr.harmRef1kgCloud, paramsArr.harmRef1kg)
  //}
  //
  //uger {
  //  cmd"""$binRscript --vanilla --verbose
  //    $rPcair
  //    --plink-in ${paramsArr.harmRef1kgName}
  //    --gds-out ${paramsArr.harmRef1kgGds}
  //    --scores ${paramsArr.ancestryPcaScores}
  //    --id $projectId
  //    --force-unrel $kgSampleId ${Input.Local.kgSample}
  //    --update-pop $kgSampleId $kgSamplePop ${Input.Local.kgSample}
  //    --update-group $kgSampleId $kgSampleGroup ${Input.Local.kgSample}
  //    > ${paramsArr.ancestryPcaLog}"""
  //    .in(paramsArr.harmRef1kg :+ Input.Local.kgSample)
  //    .out(paramsArr.harmRef1kgGds, paramsArr.ancestryPcaLog, paramsArr.ancestryPcaScores)
  //    .using("R-3.4")
  //
  //  cmd"""$binR --vanilla --args $projectId ${paramsArr.ancestryPcaScores} ${paramsArr.ancestryPcaScoresPlots} < $rPlotAncestryPca"""
  //  .in(paramsArr.ancestryPcaScores)
  //  .out(paramsArr.ancestryPcaScoresPlots)
  //}
  //
  ///**
  // * Ancestry Cluster Step
  // *  Description: Cluster with 1KG samples using Gaussian Mixture Modeling and infer ancestry
  // *  Requires: Hail, R
  // *  Notes:
  // *     *.ancestry.inferred.tsv contains the final inferred ancestry for each sample, including OUTLIERS
  // *     This file is array specific
  // */
  //
  //uger {
  //  cmd"""(echo 3; sed '1d' ${paramsArr.ancestryPcaScores} | cut -f4-6 | sed 's/\t/ /g') > ${paramsArr.ancestryClusterFet}"""
  //  .in(paramsArr.ancestryPcaScores)
  //  .out(paramsArr.ancestryClusterFet)
  //
  //  cmd"""$binKlustakwik ${paramsArr.ancestryClusterName} 1 -UseFeatures 111 -UseDistributional 0 > ${paramsArr.ancestryClusterLog}"""
  //  .in(paramsArr.ancestryClusterFet)
  //  .out(paramsArr.ancestryClusterClu, paramsArr.ancestryClusterKlg, paramsArr.ancestryClusterLog)
  //
  //  cmd"""$binR --vanilla --args ${paramsArr.ancestryPcaScores} ${paramsArr.ancestryClusterClu} ${Input.Local.pheno} $projectId $phenoId $phenoSrRace
  //    ${paramsArr.ancestryClusterPlots} ${paramsArr.ancestryClusterXtabs} ${paramsArr.ancestryClusterPlotsCenters}
  //    ${paramsArr.ancestryClusterGroups} ${paramsArr.ancestryInferred}
  //    ${paramsArr.ancestryClusterPlotsNo1kg} < $rPlotAncestryCluster"""
  //    .in(paramsArr.ancestryPcaScores, paramsArr.ancestryClusterClu, Input.Local.pheno)
  //    .out(paramsArr.ancestryClusterPlots, paramsArr.ancestryClusterXtabs, paramsArr.ancestryClusterPlotsCenters, paramsArr.ancestryClusterGroups, paramsArr.ancestryInferred, paramsArr.ancestryClusterPlotsNo1kg)
  //}

  paramsArr.ancestryInferred

}

def qc2(i: Int): Map[(String, String, String, String, String), Store[TXT]] = {

  val (_, paramsArr) = Params.paramsByArr(i)
  var resultsMap = Seq[Map[(String, String, String, String, String), Store[TXT]]]()

  ///**
  // * PCA Step
  // *  Description: Calculate PCs for all non-outlier samples combined (to be used for adjustment during sample outlier removal)
  // *  Requires: R
  // */
  //
  //uger {
  //
  //  cmd"""$binRscript --vanilla --verbose
  //    $rPcair
  //    --plink-in ${paramsArr.harmRefFiltPrunedName}
  //    --gds-out ${paramsArr.harmRefFiltPrunedPcaGds}
  //    --exclude ${ancestryInferredMergedOutliers}
  //    --ancestry ${ancestryInferredMerged}
  //    --id $projectId
  //    --scores ${paramsArr.pcaScores}
  //    > ${paramsArr.pcaLog}"""
  //    .in(paramsArr.harmRefFiltPruned :+ ancestryInferredMerged :+ ancestryInferredMergedOutliers)
  //    .out(paramsArr.harmRefFiltPrunedPcaGds, paramsArr.pcaLog, paramsArr.pcaScores)
  //    .using("R-3.4")
  //}
  //
  ///**
  // * Sample QC Stats Calculation Step
  // *  Description: Calculate sexcheck and sample by variant statistics for all samples
  // *  Requires: Hail, R
  // */
  //
  //local {
  //  googleCopy(ancestryInferredMerged, ancestryInferredMergedCloud)
  //  googleCopy(Input.Local.pheno, Input.Google.pheno)
  //}
  //
  //google {
  //  hail"""$pyHailSexcheck
  //    --vds-in ${paramsArr.harmRefVdsCloud}
  //    --regions-exclude ${Input.Google.regionsExclude}
  //    --pheno-in ${Input.Google.pheno}
  //    --id-col $phenoId
  //    --sex-col $phenoSrSex
  //    --sexcheck-out ${paramsArr.sampleqcSexcheckCloud}
  //    --sexcheck-problems-out ${paramsArr.sampleqcSexcheckProblemsCloud}"""
  //    .in(Input.Google.pheno, paramsArr.harmRefVdsCloud, Input.Google.regionsExclude)
  //    .out(paramsArr.sampleqcSexcheckCloud, paramsArr.sampleqcSexcheckProblemsCloud)
  //
  //  hail"""$pyHailSampleqc
  //    --vds-in ${paramsArr.harmRefFiltPrunedVdsCloud}
  //    --clusters-in ${ancestryInferredMergedCloud}
  //    --qc-out ${paramsArr.sampleqcStatsCloud}"""
  //    .in(paramsArr.harmRefFiltPrunedVdsCloud, ancestryInferredMergedCloud)
  //    .out(paramsArr.sampleqcStatsCloud)
  //}
  //
  //local {
  //  googleCopy(paramsArr.sampleqcStatsCloud, paramsArr.sampleqcStats)
  //}
  //
  //uger {
  //  cmd"""$binR --vanilla --args ${paramsArr.sampleqcStats} ${paramsArr.pcaScores} ${paramsArr.sampleqcStatsAdj} < $rCalcIstatsAdj"""
  //  .in(paramsArr.sampleqcStats, paramsArr.pcaScores)
  //  .out(paramsArr.sampleqcStatsAdj)
  //
  //  cmd"""$binR --vanilla --args ${paramsArr.sampleqcStatsAdj} ${paramsArr.sampleqcStatsAdjCorrPlots} ${paramsArr.sampleqcStatsAdjPcaLoadings} ${paramsArr.sampleqcStatsAdjPcaScoresPlots} ${paramsArr.sampleqcStatsAdjPcaScores} < $rIstatsAdjPca"""
  //  .in(paramsArr.sampleqcStatsAdj)
  //  .out(paramsArr.sampleqcStatsAdjCorrPlots, paramsArr.sampleqcStatsAdjPcaLoadings, paramsArr.sampleqcStatsAdjPcaScoresPlots, paramsArr.sampleqcStatsAdjPcaScores)
  //}
  //
  //local {
  //  googleCopy(paramsArr.sampleqcSexcheckCloud, paramsArr.sampleqcSexcheck)
  //  googleCopy(paramsArr.sampleqcSexcheckProblemsCloud, paramsArr.sampleqcSexcheckProblems)
  //}
  //
  ///**
  // * Sample QC PCA Clustering Step
  // *  Description: Cluster PCs of adjusted sample QC metrics
  // *  Requires: Klustakwik, R
  // */
  //
  //uger {
  //  cmd"""N=$$(head -1 ${paramsArr.sampleqcStatsAdjPcaScores} | wc | awk '{print $$2-1}');
  //    echo $$N > ${paramsArr.sampleqcStatsAdjClusterFet};
  //    sed '1d' ${paramsArr.sampleqcStatsAdjPcaScores} | cut -f2- | sed 's/\t/ /g' >> ${paramsArr.sampleqcStatsAdjClusterFet};
  //    FEATURES=1; for i in $$(seq 2 $$N); do FEATURES=$${FEATURES}1; done;
  //    $binKlustakwik ${paramsArr.sampleqcStatsAdjClusterName} 1 -UseFeatures $$FEATURES -UseDistributional 0 >
  //    ${paramsArr.sampleqcStatsAdjClusterKlustakwikLog}"""
  //    .in(paramsArr.sampleqcStatsAdjPcaScores)
  //    .out(paramsArr.sampleqcStatsAdjClusterFet, paramsArr.sampleqcStatsAdjClusterClu, paramsArr.sampleqcStatsAdjClusterKlg, paramsArr.sampleqcStatsAdjClusterKlustakwikLog)
  //
  //  cmd"""$binR --vanilla --args ${paramsArr.sampleqcStatsAdjPcaScores} ${paramsArr.sampleqcStatsAdjClusterClu}
  //    ${paramsArr.sampleqcStatsAdjClusterOutliers} ${paramsArr.sampleqcStatsAdjClusterPlots}
  //    ${paramsArr.sampleqcStatsAdjClusterXtabs} $projectId < $rIstatsPcsGmmClusterPlot"""
  //    .in(paramsArr.sampleqcStatsAdjPcaScores, paramsArr.sampleqcStatsAdjClusterClu)
  //    .out(paramsArr.sampleqcStatsAdjClusterOutliers, paramsArr.sampleqcStatsAdjClusterPlots, paramsArr.sampleqcStatsAdjClusterXtabs)
  //
  //}
  //
  ///**
  // * Sample QC Individual Stats Clustering Step
  // *  Description: Cluster PCs of adjusted sample QC metrics
  // *  Requires: Klustakwik, R
  // */
  //
  //for {
  //  (metric, paramsMetric) <- paramsArr.paramsByArrByMetric
  //} {
  //
  //  uger {
  //    cmd"""echo 1 > ${paramsMetric.sampleqcStatsAdjIndClusterFet};
  //      metricIdx=`head -1 ${paramsArr.sampleqcStatsAdj} | tr '\t' '\n' | awk '{print NR" "$$0}' | grep -w ${paramsMetric.sampleqcStatsAdjIndMetric} | awk '{print $$1}'`;
  //      sed '1d' ${paramsArr.sampleqcStatsAdj} | awk -v col=$${metricIdx} '{print $$col}' >> ${paramsMetric.sampleqcStatsAdjIndClusterFet}"""
  //      .in(paramsArr.sampleqcStatsAdj)
  //      .out(paramsMetric.sampleqcStatsAdjIndClusterFet)
  //
  //    cmd"""$binKlustakwik ${paramsMetric.sampleqcStatsAdjIndClusterName} 1 -UseFeatures 1 -UseDistributional 0 > ${paramsMetric.sampleqcStatsAdjIndClusterKlustakwikLog}"""
  //      .in(paramsMetric.sampleqcStatsAdjIndClusterFet)
  //      .out(paramsMetric.sampleqcStatsAdjIndClusterClu, paramsMetric.sampleqcStatsAdjIndClusterKlg, paramsMetric.sampleqcStatsAdjIndClusterKlustakwikLog)
  //  }
  //
  //}
  //
  //uger {
  //  cmd"""$binR --vanilla --args
  //    ${sampleQcMetrics.mkString(",")}
  //    ${paramsArr.sampleqcStats}
  //    ${paramsArr.sampleqcStatsAdj}
  //    ${paramsArr.sampleqcStatsAdjClusterOutliers}
  //    ${paramsArr.sampleqcStatsAdjIndBoxplots}
  //    ${paramsArr.sampleqcStatsAdjIndDiscreteness}
  //    ${paramsArr.sampleqcStatsAdjOutliersTable}
  //    ${paramsArr.sampleqcStatsAdjStripchart}
  //    ${ancestryInferredMerged}
  //    < $rIstatsAdjGmmPlotMetrics"""
  //    .in(paramsArr.paramsByArrByMetricSorted.map(_.sampleqcStatsAdjIndClusterClu) :+ paramsArr.sampleqcStats :+ paramsArr.sampleqcStatsAdj :+ ancestryInferredMerged :+ paramsArr.sampleqcStatsAdjClusterOutliers)
  //    .out(paramsArr.sampleqcStatsAdjIndBoxplots, paramsArr.sampleqcStatsAdjIndDiscreteness, paramsArr.sampleqcStatsAdjOutliersTable, paramsArr.sampleqcStatsAdjStripchart)
  //}
  //
  ///**
  // * Compile Sample Exclusions Step
  // * Requires: Python
  // */
  //
  //uger {
  //
  //  cmd"""python $pyCompileExclusions
  //    --ancestry-inferred ${ancestryInferredMerged}
  //    --kinship-related ${paramsArr.kinKin0Related}
  //    --kinship-famsizes ${paramsArr.kinFamsizes}
  //    --sampleqc-outliers ${paramsArr.sampleqcStatsAdjOutliersTable}
  //    --sexcheck-problems ${paramsArr.sampleqcSexcheckProblems}
  //    --ancestry-keep ${ancestryKeep.mkString(",")}
  //    --duplicates-keep ${duplicatesKeep.mkString(",")}
  //    --famsize-keep ${famsizeKeep.mkString(",")}
  //    --sampleqc-keep ${sampleqcKeep.mkString(",")}
  //    --sexcheck-keep ${sexcheckKeep.mkString(",")}
  //    --out ${paramsArr.finalSampleExclusions}"""
  //    .in(ancestryInferredMerged, paramsArr.kinKin0Related, paramsArr.kinFamsizes, paramsArr.sampleqcStatsAdjOutliersTable, paramsArr.sampleqcSexcheckProblems)
  //    .out(paramsArr.finalSampleExclusions)
  //}
  //
  ///**
  //* Filter Clean Step
  //* filter variants and generate final clean dataset
  //*/
  //
  //local {
  //  googleCopy(paramsArr.finalSampleExclusions, paramsArr.finalSampleExclusionsCloud)
  //}
  //
  //google {
  //  hail"""$pyHailFilterFinal
  //    --vds-in ${paramsArr.harmRefVdsCloud}
  //    --ancestry-in ${ancestryInferredMergedCloud}
  //    --sexcheck-in ${paramsArr.sampleqcSexcheckCloud}
  //    --pheno-in ${Input.Google.pheno}
  //    --iid-col $phenoId
  //    --case-ctrl-col $phenoStatus
  //    --samples-remove ${paramsArr.finalSampleExclusionsCloud}
  //    --variantqc-out ${paramsArr.variantqcStatsCloud}
  //    --variants-exclude-out ${paramsArr.finalVariantExclusionsCloud}
  //    --plink-out ${paramsArr.cleanNameCloud}
  //    --vcf-out ${paramsArr.cleanVcfCloud}
  //    --vds-out ${paramsArr.cleanVdsCloud}"""
  //    .in(paramsArr.harmRefVdsCloud, ancestryInferredMergedCloud, paramsArr.sampleqcSexcheckCloud, Input.Google.pheno, paramsArr.finalSampleExclusionsCloud)
  //    .out(paramsArr.cleanCloud :+ paramsArr.cleanVcfCloud :+ paramsArr.variantqcStatsCloud :+ paramsArr.finalVariantExclusionsCloud :+ paramsArr.cleanVdsCloud)
  //}
  //
  //local {
  //  googleCopy(paramsArr.cleanCloud, paramsArr.clean)
  //  googleCopy(paramsArr.cleanVcfCloud, paramsArr.cleanVcf)
  //  googleCopy(paramsArr.variantqcStatsCloud, paramsArr.variantqcStats)
  //  googleCopy(paramsArr.finalVariantExclusionsCloud, paramsArr.finalVariantExclusions)
  //}
  //
  //local {
  //  cmd"""$binTabix -f -p vcf ${paramsArr.cleanVcf}"""
  //    .in(paramsArr.cleanVcf)
  //    .out(paramsArr.cleanVcfTbi)
  //}

  /**
   * Association Step
   *  Description: Run association tests
   *  Requires: Hail
   */
  
  for {
    (assoc, paramsAssoc) <- paramsArr.paramsByArrByAssoc
  } {
  
    //google {
    //  hail"""$pyHailListSamples
    //    --vds-in ${paramsArr.cleanVdsCloud}
    //    --bim-in ${paramsArr.harmRefFiltPrunedNameCloud}.bim
    //    --pheno-in ${Input.Google.pheno}
    //    --iid-col $phenoId
    //    --pheno-col ${paramsAssoc.assocPheno}
    //    --test ${paramsAssoc.assocTest}
    //    --covars "${paramsAssoc.assocCovars}"
    //    --out-pheno-prelim ${paramsAssoc.assocPhenoPrelimFileCloud}
    //    --out-samples ${paramsAssoc.assocSamplesIncludeCloud}"""
    //  .in(paramsArr.harmRefFiltPrunedCloud :+ paramsArr.cleanVdsCloud :+ Input.Google.pheno)
    //  .out(paramsAssoc.assocPhenoPrelimFileCloud, paramsAssoc.assocSamplesIncludeCloud)
    //}
    //
    //local {
    //  googleCopy(paramsAssoc.assocPhenoPrelimFileCloud, paramsAssoc.assocPhenoPrelimFile)
    //  googleCopy(paramsAssoc.assocSamplesIncludeCloud, paramsAssoc.assocSamplesInclude)
    //}
    //
    //uger {
    //  cmd"""$binRscript --vanilla --verbose
    //    $rGeneratePheno
    //    --gds-in ${paramsArr.harmRefFiltPrunedPcaGds}
    //    --pheno-in ${Input.Local.pheno}
    //    --ancestry-in ${ancestryInferredMerged}
    //    --pheno-col ${paramsAssoc.assocPheno}
    //    --iid-col $phenoId
    //    --samples-include ${paramsAssoc.assocSamplesInclude}
    //    --variants-exclude ID ${paramsArr.finalVariantExclusions}
    //    --test ${paramsAssoc.assocTest}
    //    --trans "${paramsAssoc.assocTrans}"
    //    --covars "${paramsAssoc.assocCovars}"
    //    --out-pheno ${paramsAssoc.assocPhenoFile}
    //    --out-pcs ${paramsAssoc.assocPcsFile}
    //    > ${paramsAssoc.assocPhenoFileLog} 2>&1"""
    //    .in(paramsArr.harmRefFiltPrunedPcaGds, Input.Local.pheno, ancestryInferredMerged, paramsAssoc.assocSamplesInclude, paramsArr.finalVariantExclusions)
    //    .out(paramsAssoc.assocPhenoFile, paramsAssoc.assocPcsFile, paramsAssoc.assocPhenoFileLog)
    //    .using("R-3.4")
    //}
    //
    //local {
    //  googleCopy(paramsAssoc.assocPhenoFile, paramsAssoc.assocPhenoFileCloud)
    //  googleCopy(paramsAssoc.assocPcsFile, paramsAssoc.assocPcsFileCloud)
    //}
    //
    //google {
    //  hail"""$pyHailAssoc
    //    --vds-in ${paramsArr.cleanVdsCloud}
    //    --bim-in ${paramsArr.harmRefFiltPrunedNameCloud}.bim
    //    --pheno-in ${paramsAssoc.assocPhenoFileCloud}
    //    --iid-col $phenoId
    //    --pheno-col ${paramsAssoc.assocPheno}
    //    --pcs-include ${paramsAssoc.assocPcsFileCloud}
    //    --test ${paramsAssoc.assocTest}
    //    --trans "${paramsAssoc.assocTrans}"
    //    --covars "${paramsAssoc.assocCovars}"
    //    --out ${paramsAssoc.assocResultsCloud}"""
    //      .in(paramsArr.harmRefFiltPrunedCloud :+ paramsArr.cleanVdsCloud :+ Input.Google.pheno :+ paramsAssoc.assocPhenoFileCloud)
    //      .out(paramsAssoc.assocResultsCloud)
    //}
    //
    //local {
    //  googleCopy(paramsAssoc.assocResultsCloud, paramsAssoc.assocResults)
    //}
    //
    //local {
    //  cmd"""$binTabix -b 2 -e 2 ${paramsAssoc.assocResults}"""
    //    .in(paramsAssoc.assocResults)
    //    .out(paramsAssoc.assocResultsTbi)
    //}

    resultsMap = resultsMap :+ Map((paramsArr.arrayId, paramsAssoc.assocPheno, paramsAssoc.assocTest, paramsAssoc.assocCovars, paramsAssoc.assocTrans) -> paramsAssoc.assocResultsCloud)

  }

  return resultsMap.flatten.toMap

}

def finalizeResults(i: Int): Unit = {

  val (_, paramsResult) = Params.paramsByResult(i)
  
  ///**
  // * Merge Step
  // *  Description: Run association tests
  // *  Requires: Hail
  // */
  //
  //val modelResultsMap = resultsStoresMapsList.flatten.toMap.filterKeys({e => e._2 == paramsResult.resultPheno && e._3 == paramsResult.resultTest && e._4 == paramsResult.resultCovars && e._5 == paramsResult.resultTrans})
  //
  //val modelResultsString = modelResultsMap.map { case (key, value) => s"""${key._1}___${value.toString.split("@")(1)}""" }.mkString(",")
  //
  //google {
  //  hail"""$pyHailMerge
  //    --results "${modelResultsString}"
  //    --test ${paramsResult.resultTest}
  //    --out ${paramsResult.resultFinalCloud}
  //    """.in(modelResultsMap.values).out(paramsResult.resultFinalCloud)
  //}
  //
  //local {
  //  googleCopy(paramsResult.resultFinalCloud, paramsResult.resultFinal)
  //}
  //
  //local {
  //  cmd"""$binTabix -b 2 -e 2 ${paramsResult.resultFinal}"""
  //    .in(paramsResult.resultFinal)
  //    .out(paramsResult.resultFinalTbi)
  //}
  //
  ///**
  // * Plot Step
  // *  Description: Run association tests
  // *  Requires: Python
  // */
  //
  //uger {
  //  cmd"""python $pyQqPlot
  //    --results ${paramsResult.resultFinal}
  //    --p pval
  //    --out ${paramsResult.resultFinalQqPlot}
  //    """.in(paramsResult.resultFinal).out(paramsResult.resultFinalQqPlot)
  //  
  //  cmd"""python $pyMhtPlot
  //    --results ${paramsResult.resultFinal}
  //    --chr chr
  //    --pos pos
  //    --p pval
  //    --out ${paramsResult.resultFinalMhtPlot}
  //    """.in(paramsResult.resultFinal).out(paramsResult.resultFinalMhtPlot)
  //  
  //  cmd"""python $pyExtractTopRegions
  //    --results ${paramsResult.resultFinal}
  //    --chr chr
  //    --pos pos
  //    --p pval
  //    --out ${paramsResult.resultFinalSigRegions}
  //    """.in(paramsResult.resultFinal).out(paramsResult.resultFinalSigRegions)
  //}

  andThen {
    uger {
      val regions = Files.readFrom(paramsResult.resultFinalSigRegions.path).split(System.lineSeparator)

      for (region <- regions) {
        val regionChr = region.split("\t")(0)
        val regionStart = region.split("\t")(1)
        val regionEnd = region.split("\t")(2)
		val resultsFinalRegplotPdf = store[TXT].at(localOutDir / s"${paramsResult.resultFinalRegplotName}_chr${regionChr}_${regionStart}_${regionEnd}.pdf")
        val resultsFinalRegplotPng = store[TXT].at(localOutDir / s"${paramsResult.resultFinalRegplotName}_chr${regionChr}_${regionStart}_${regionEnd}.png")

        cmd"""pcol=`tabix -H tabix ${paramsResult.resultFinal} | tr "\t" "\n" | grep -n pval | awk -F':' '{print $$1}'`; 
          (echo -e "id\tpval"; tabix ${paramsResult.resultFinal} ${regionChr}:${regionStart}-${regionEnd} | awk -v pcol=$$pcol '{if(substr($$4 ,0, 2) != "rs") { print "chr"$$1":"$$2"\t"$$pcol } else print $$4"\t"$$pcol}') | $binLocuszoom --metal - --chr $regionChr --start $regionStart --end $regionEnd --markercol id --pvalcol pval --pop EUR --build hg19 --source 1000G_Nov2014 --plotonly --no-date --prefix ${paramsResult.resultFinalRegplotName} --cache None"""
          .in(paramsResult.resultFinal)
          .out(resultsFinalRegplotPdf)

        cmd"""convert -density 300 -depth 8 -quality 100 -flatten ${resultsFinalRegplotPdf}[0] $resultsFinalRegplotPng"""
          .in(resultsFinalRegplotPdf)
          .out(resultsFinalRegplotPng)

      }
    }
  }

}
