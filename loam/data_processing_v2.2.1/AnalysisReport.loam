/**
  * Analysis Report Step
  *  Description: Generate Analysis Report
  *  Requires: R-3.4, Python, convert, pdflatex
  */
import ProjectConfig._
import PipelineConfig._
import ArrayStores._
import AssocStores._
import ProjectStores._
import QcReportStores._
import AnalysisReportStores._
import ResultsSummaryStores._
import PhenotypeStores._

def AnalysisReportGlobal(configReport: ConfigReport): Unit = {

  drm {

	cmd"""$binPython $pyGenerateReportHeader
      --out ${analysisReportStores(configReport).globalData.header}"""
      .out(analysisReportStores(configReport).globalData.header)
      .tag(s"${analysisReportStores(configReport).globalData.header}".split("/").last)

    cmd"""$binPython $pyGenerateAnalysisReportIntro
      --id ${projectConfig.projectId}
      --name "${configReport.name}"
      --authors "${projectConfig.analysisReportAuthors.mkString(",")}"
      --out-tex ${analysisReportStores(configReport).globalData.intro}
      --out-input ${analysisReportStores(configReport).globalData.introInput}"""
      .in(arrayStores.map(e => e._2).flatMap(e => e.rawData.data))
      .out(analysisReportStores(configReport).globalData.intro, analysisReportStores(configReport).globalData.introInput)
      .tag(s"${analysisReportStores(configReport).globalData.intro}".split("/").last)

  }

  val arraysString = {

    for {
      array <- projectConfig.Arrays
    } yield {
      array.liftOver match {
        case Some(s) => Seq(array.id, array.filename.split("/").last, array.format, array.liftOver.get.split("/").last).mkString(",")
        case None => Seq(array.id, array.filename.split("/").last, array.format, "N/A").mkString(",")
      }
    }

  }

  val cohortsString = {
  
    for {
      cohort <- projectConfig.Cohorts
    } yield {
      Seq(cohort.id, cohort.array, cohort.ancestry.mkString("+"), if ( cohortsReport contains cohort ) { "YES" } else { "NO" }).mkString(",")
    }
  
  }
  
  val metasString = {
  
    for {
      meta <- metas
      cohort <- projectConfig.Cohorts.filter(e => meta.cohorts contains e.id)
    } yield {
      Seq(meta.id, cohort.id, s"${metaKinshipStores(meta).metaCohort(cohort).kinshipSamplesExclude.path}", if ( metasReport contains meta ) { "YES" } else { "NO" }).mkString(",")
    }
  
  }
  
  val mergesString = {
  
    for {
      merge <- merges
    } yield {
      Seq(merge.id, merge.cohorts_metas.mkString(">"), if ( merges contains merge ) { "YES" } else { "NO" }).mkString(",")
    }
  
  }

  drm {

    cmd"""$binPython $pyGenerateAnalysisReportData
      --samples-upset-diagram ${qcReportStores.figureData.samplesRemainingUpsetPlotPdf.path.toAbsolutePath()}
      --variants-upset-diagram ${qcReportStores.figureData.variantsRemainingUpsetPlotPdf.path.toAbsolutePath()}
      --arrays ${arraysString.mkString(" ")}
      --out-tex ${analysisReportStores(configReport).globalData.data}
      --out-input ${analysisReportStores(configReport).globalData.dataInput}"""
      .in(qcReportStores.figureData.samplesRemainingUpsetPlotPdf, qcReportStores.figureData.variantsRemainingUpsetPlotPdf)
      .out(analysisReportStores(configReport).globalData.data, analysisReportStores(configReport).globalData.dataInput)
      .tag(s"${analysisReportStores(configReport).globalData.data}".split("/").last)

    cmd"""$binPython $pyGenerateAnalysisReportStrategy
      --cohorts "${cohortsString.mkString("___")}"
      --metas "${metasString.mkString("___")}"
      --merges "${mergesString.mkString("___")}"
      --out-tex ${analysisReportStores(configReport).globalData.strategy}
      --out-input ${analysisReportStores(configReport).globalData.strategyInput}"""
      .in(metaKinshipStores.flatMap(e => e._2.metaCohort.map(e => e._2.kinshipSamplesExclude)).toSeq)
      .out(analysisReportStores(configReport).globalData.strategy, analysisReportStores(configReport).globalData.strategyInput)
      .tag(s"${analysisReportStores(configReport).globalData.strategy}".split("/").last)

  }

  val knownLociCitations = {

    for {
      known <- knowns
    } yield {
      Seq(known.id, known.citation).mkString("___")
    }

  }

  drm {

    cmd"""$binPython $pyGenerateAnalysisReportBibliography
      --names "${projectConfig.analysisReportAcknowledgements.mkString(",")}"
      --known-loci-citations "${knownLociCitations.mkString(",,,")}"
      --out-tex ${analysisReportStores(configReport).globalData.bibliography}
      --out-input ${analysisReportStores(configReport).globalData.bibliographyInput}"""
      .out(analysisReportStores(configReport).globalData.bibliography, analysisReportStores(configReport).globalData.bibliographyInput)
      .tag(s"${analysisReportStores(configReport).globalData.bibliography}".split("/").last)

  }

}

def AnalysisReportPheno(configReport: ConfigReport, configSection: ConfigSection, configPheno: ConfigPheno): Unit = {

  val distPlotStrings = {
    phenotypeStores.filter(e => e._1._1 == configPheno).filter(e => ! e._1._3.isDefined).map(e => ("", e._1._2.id, s"${e._2.figureData.distPlot.path.toAbsolutePath()}")) ++ phenotypeStores.filter(e => e._1._1 == configPheno).filter(e => e._1._3.isDefined).map(e => (e._1._3.get.id, e._1._2.id, s"${e._2.figureData.distPlot.path.toAbsolutePath()}"))
  }.toSeq.distinct.sortBy(e => (e._1, e._2)).map(e => e.productIterator.mkString(","))

  val distPlotFiles = {
    phenotypeStores.filter(e => e._1._1 == configPheno).filter(e => ! e._1._3.isDefined).map(e => e._2.figureData.distPlot) ++ 
    phenotypeStores.filter(e => e._1._1 == configPheno).filter(e => e._1._3.isDefined).map(e => e._2.figureData.distPlot)
  }.toSeq.distinct
  
  val modelFileStrings = {
    assocStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => ! e._1._3.isDefined).map(e => ("", e._1._2.id, e._1._2.array, e._1._2.ancestry.mkString("+"), if ( e._1._1.trans != "" ) { e._1._1.trans } else { "-" }, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.pcs.path}", s"${e._2.pheno.path}")) ++
    assocStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => (e._1._3.get.id, e._1._2.id, e._1._2.array, e._1._2.ancestry.mkString("+"), if ( e._1._1.trans != "" ) { e._1._1.trans } else { "-" }, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.pcs.path}", s"${e._2.pheno.path}"))
  }.toSeq.distinct.sortBy(e => (e._1, e._2, e._3, e._4, e._5)).map(e => e.productIterator.mkString(","))

  val pcFiles = {
    assocStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => ! e._1._3.isDefined).map(e => e._2.pcs) ++
    assocStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => e._2.pcs) 
  }.toSeq
  
  val phenoFiles = {
    assocStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => ! e._1._3.isDefined).map(e => e._2.pheno) ++
    assocStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => e._2.pheno) 
  }.toSeq
  
  drm {
  
    cmd"""$binPython $pyGenerateAnalysisReportPhenoSummary
      --dist-plot ${distPlotStrings.mkString(" ")}
      --pheno-master ${ProjectStores.phenoFile}
      --id-col ${projectConfig.phenoFileId}
      --sex-col ${projectConfig.phenoFileSrSex}
      --male-code ${projectConfig.phenoFileMaleCode}
      --female-code ${projectConfig.phenoFileFemaleCode}
      --model-files ${modelFileStrings.mkString(" ")}
      --pheno-name ${configPheno.id}
      --pheno-long-name "${configPheno.name}"
      --ancestry ${ProjectStores.ancestryInferred}
      --out-tex ${analysisReportStores(configReport).sectionData(configSection).summary}
      --out-input ${analysisReportStores(configReport).sectionData(configSection).summaryInput}"""
      .in(phenoFiles ++ pcFiles ++ distPlotFiles :+ ProjectStores.ancestryInferred :+ ProjectStores.phenoFile)
      .out(analysisReportStores(configReport).sectionData(configSection).summary, analysisReportStores(configReport).sectionData(configSection).summaryInput)
      .tag(s"${analysisReportStores(configReport).sectionData(configSection).summary}".split("/").last)
  
  }
  
  val qqPlotStrings = {
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => (e._1._2.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.qqPlotPng.path.toAbsolutePath()}")) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => (e._1._3.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.qqPlotPng.path.toAbsolutePath()}")) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => (e._1._4.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.qqPlotPng.path.toAbsolutePath()}"))
  }.toSeq.distinct.sortBy(e => (e._1, e._2, e._3)).map(e => e.productIterator.mkString(","))
  
  val qqPlotFiles = {
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => e._2.resultsSummaryData.qqPlotPng) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => e._2.resultsSummaryData.qqPlotPng) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => e._2.resultsSummaryData.qqPlotPng)
  }.toSeq
  
  val mhtPlotStrings = {
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => (e._1._2.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.mhtPlotPng.path.toAbsolutePath()}")) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => (e._1._3.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.mhtPlotPng.path.toAbsolutePath()}")) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => (e._1._4.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.mhtPlotPng.path.toAbsolutePath()}"))
  }.toSeq.distinct.sortBy(e => (e._1, e._2, e._3)).map(e => e.productIterator.mkString(","))
  
  val mhtPlotFiles = {
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => e._2.resultsSummaryData.mhtPlotPng) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => e._2.resultsSummaryData.mhtPlotPng) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => e._2.resultsSummaryData.mhtPlotPng)
  }.toSeq
  
  drm {
  
    cmd"""$binPython $pyGenerateAnalysisReportPhenoCalibration
      --qq-plots ${qqPlotStrings.mkString(" ")}
      --mht-plots ${mhtPlotStrings.mkString(" ")}
      --pheno-name ${configPheno.id}
      --pheno-long-name "${configPheno.name}"
      --out-tex ${analysisReportStores(configReport).sectionData(configSection).calibration}
      --out-input ${analysisReportStores(configReport).sectionData(configSection).calibrationInput}"""
      .in(qqPlotFiles ++ mhtPlotFiles)
      .out(analysisReportStores(configReport).sectionData(configSection).calibration, analysisReportStores(configReport).sectionData(configSection).calibrationInput)
      .tag(s"${analysisReportStores(configReport).sectionData(configSection).calibration}".split("/").last)
  
  }
  
  val top20AnnotAlignedRiskStrings = {
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => (e._1._2.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.top20AnnotAlignedRisk.path.toAbsolutePath()}")) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => (e._1._3.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.top20AnnotAlignedRisk.path.toAbsolutePath()}")) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => (e._1._4.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.top20AnnotAlignedRisk.path.toAbsolutePath()}"))
  }.toSeq.distinct.sortBy(e => (e._1, e._2, e._3)).map(e => e.productIterator.mkString(","))
  
  val top20AnnotAlignedRiskFiles = {
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => e._2.resultsSummaryData.top20AnnotAlignedRisk) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => e._2.resultsSummaryData.top20AnnotAlignedRisk) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => e._2.resultsSummaryData.top20AnnotAlignedRisk)
  }.toSeq
  
  val regplotsStrings = {
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => (e._1._2.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.sigRegions.path.toAbsolutePath()}", s"${e._2.resultsSummaryData.regPlotsPdf.path.toAbsolutePath()}")) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => (e._1._3.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.sigRegions.path.toAbsolutePath()}", s"${e._2.resultsSummaryData.regPlotsPdf.path.toAbsolutePath()}")) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => (e._1._4.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsSummaryData.sigRegions.path.toAbsolutePath()}", s"${e._2.resultsSummaryData.regPlotsPdf.path.toAbsolutePath()}"))
  }.toSeq.distinct.sortBy(e => (e._1, e._2, e._3)).map(e => e.productIterator.mkString(","))
  
  val sigRegionsFiles = {
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => e._2.resultsSummaryData.sigRegions) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => e._2.resultsSummaryData.sigRegions) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => e._2.resultsSummaryData.sigRegions)
  }.toSeq
  
  val regplotsFiles = {
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => e._2.resultsSummaryData.regPlotsPdf) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => e._2.resultsSummaryData.regPlotsPdf) ++
    resultsSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => e._2.resultsSummaryData.regPlotsPdf)
  }.toSeq
  
  drm {
    
    cmd"""$binPython $pyGenerateAnalysisReportPhenoTopLoci
      --top-results ${top20AnnotAlignedRiskStrings.mkString(" ")}
      --regionals ${regplotsStrings.mkString(" ")}
      --pheno-name ${configPheno.id}
      --pheno-long-name "${configPheno.name}"
      --out-tex ${analysisReportStores(configReport).sectionData(configSection).topLoci}
      --out-input ${analysisReportStores(configReport).sectionData(configSection).topLociInput}"""
      .in(top20AnnotAlignedRiskFiles ++ sigRegionsFiles ++ regplotsFiles)
      .out(analysisReportStores(configReport).sectionData(configSection).topLoci, analysisReportStores(configReport).sectionData(configSection).topLociInput)
      .tag(s"${analysisReportStores(configReport).sectionData(configSection).topLoci}".split("/").last)
  
  }
  
  val top50Strings = {
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => (e._1._2.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsKnownLociSummaryData.top50.path.toAbsolutePath()}")) ++
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => (e._1._3.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsKnownLociSummaryData.top50.path.toAbsolutePath()}")) ++
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => (e._1._4.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), s"${e._2.resultsKnownLociSummaryData.top50.path.toAbsolutePath()}"))
  }.toSeq.distinct.sortBy(e => (e._1, e._2, e._3)).map(e => e.productIterator.mkString(","))
  
  val top50Files = {
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => e._2.resultsKnownLociSummaryData.top50) ++
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => e._2.resultsKnownLociSummaryData.top50) ++
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => e._2.resultsKnownLociSummaryData.top50)
  }.toSeq
  
  val knownDescStrings = {
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => (e._1._2.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), e._1._5.desc)) ++
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => (e._1._3.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), e._1._5.desc)) ++
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => (e._1._4.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), e._1._5.desc))
  }.toSeq.distinct.sortBy(e => (e._1, e._2, e._3)).map(e => e.productIterator.mkString("___"))
  
  val knownIdStrings = {
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._2.isDefined).map(e => (e._1._2.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), e._1._5.id)) ++
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._3.isDefined).map(e => (e._1._3.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), e._1._5.id)) ++
    resultsKnownLociSummaryStores.filter(e => e._1._1.pheno == configPheno.id).filter(e => e._1._4.isDefined).map(e => (e._1._4.get.id, e._1._1.trans, e._1._1.covars.mkString("+").replace("[","").replace("]",""), e._1._5.id))
  }.toSeq.distinct.sortBy(e => (e._1, e._2, e._3)).map(e => e.productIterator.mkString(","))
  
  top50Strings.size match {
  
    case 0 => ()
  
    case _ =>
  
      drm {
        
        cmd"""$binPython $pyGenerateAnalysisReportPhenoKnownLoci
          --top-known-loci ${top50Strings.mkString(" ")}
          --pheno-name ${configPheno.id}
          --pheno-long-name "${configPheno.name}"
          --desc "${knownDescStrings.mkString(",,,")}"
          --tag ${knownIdStrings.mkString(" ")}
          --out-tex ${analysisReportStores(configReport).sectionData(configSection).knownLoci.get}
          --out-input ${analysisReportStores(configReport).sectionData(configSection).knownLociInput.get}"""
          .in(top50Files)
          .out(analysisReportStores(configReport).sectionData(configSection).knownLoci.get, analysisReportStores(configReport).sectionData(configSection).knownLociInput.get)
          .tag(s"${analysisReportStores(configReport).sectionData(configSection).knownLoci.get}".split("/").last)
      
      }
  
  }

}

def AnalysisReportCompile(configReport: ConfigReport): Unit = {

  val reportAnalysisResultsList = {
    analysisReportStores(configReport).sectionData.map(e => if ( e._2.knownLoci.isDefined ) { Seq(e._2.summary, e._2.calibration, e._2.topLoci, e._2.knownLoci.get) } else { Seq(e._2.summary, e._2.calibration, e._2.topLoci) } )
  }.flatten.toSeq

  val reportAnalysisResultsStringList = reportAnalysisResultsList.map(e => s"""${e.path}""")

  drm {

    cmd"""cat ${analysisReportStores(configReport).globalData.header} ${analysisReportStores(configReport).globalData.intro} ${analysisReportStores(configReport).globalData.data} ${analysisReportStores(configReport).globalData.strategy} ${reportAnalysisResultsStringList.mkString(" ")} ${analysisReportStores(configReport).globalData.bibliography} > ${analysisReportStores(configReport).globalData.tex}"""
      .in(reportAnalysisResultsList :+ analysisReportStores(configReport).globalData.header :+ analysisReportStores(configReport).globalData.intro :+ analysisReportStores(configReport).globalData.data :+ analysisReportStores(configReport).globalData.strategy :+ analysisReportStores(configReport).globalData.bibliography)
      .out(analysisReportStores(configReport).globalData.tex)
      .tag(s"${analysisReportStores(configReport).globalData.tex}".split("/").last)

  }

  val reportAnalysisResultsInputList = {
    analysisReportStores(configReport).sectionData.map(e => if ( e._2.knownLoci.isDefined ) { Seq(e._2.summaryInput, e._2.calibrationInput, e._2.topLociInput, e._2.knownLociInput.get) } else { Seq(e._2.summaryInput, e._2.calibrationInput, e._2.topLociInput) } )
  }.flatten.toSeq

  val reportAnalysisResultsInputStringList = reportAnalysisResultsInputList.map(e => s"""${e.path}""")

  drm {
    
    cmd"""cat ${analysisReportStores(configReport).globalData.introInput} ${analysisReportStores(configReport).globalData.dataInput} ${analysisReportStores(configReport).globalData.strategyInput} ${reportAnalysisResultsInputStringList.mkString(" ")} ${analysisReportStores(configReport).globalData.bibliographyInput} > ${analysisReportStores(configReport).globalData.input}"""
      .in(reportAnalysisResultsInputList :+ analysisReportStores(configReport).globalData.introInput :+ analysisReportStores(configReport).globalData.dataInput :+ analysisReportStores(configReport).globalData.strategyInput :+ analysisReportStores(configReport).globalData.bibliographyInput)
      .out(analysisReportStores(configReport).globalData.input)
      .tag(s"${analysisReportStores(configReport).globalData.input}".split("/").last)
    
    cmd"""$binPdflatex --output-directory=${localOutDir} ${analysisReportStores(configReport).globalData.tex}; sleep 5; $binPdflatex --output-directory=${localOutDir} ${analysisReportStores(configReport).globalData.tex}"""
      .in(analysisReportStores(configReport).globalData.tex)
      .out(analysisReportStores(configReport).globalData.pdf)
      .tag(s"${analysisReportStores(configReport).globalData.pdf}".split("/").last)

  }

}
