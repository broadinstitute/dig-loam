!title Analysis for MTA paper

lap_home=/home/unix/flannick/lap

#====================
#CLASSES

class project=Project with project_subset
minor class project_subset=Project Subset parent project
class mask=Mask parent project
class gene=Gene parent project
class special_gene_list=Special Gene List parent project
class simulation=Simulation parent project with simulation_batch
class simulation_batch=Simulation Batch parent simulation
class burden_test=Burden Test parent mask

#CLASSES
#====================

#====================
#DIRECTORIES
sortable mkdir path projects_dir=$unix_out_dir/projects
sortable mkdir path project_dir=$projects_dir/@project class_level project
sortable mkdir path project_subsets_dir=$project_dir/project_subsets class_level project
sortable mkdir path project_subset_dir=$project_subsets_dir/@project_subset class_level project_subset
sortable mkdir path masks_dir=$project_dir/masks class_level project
sortable mkdir path mask_dir=$masks_dir/@mask class_level mask
sortable mkdir path genes_dir=$project_dir/genes class_level project
sortable mkdir path gene_dir=$genes_dir/@gene class_level mask
sortable mkdir path simulations_dir=$project_dir/simulations class_level project
sortable mkdir path simulation_dir=$simulations_dir/@simulation class_level simulation
sortable mkdir path simulation_batches_dir=$simulation_dir/simulation_batches class_level simulation
sortable mkdir path simulation_batch_dir=$simulation_batches_dir class_level simulation
sortable mkdir path burden_tests_dir=$mask_dir/burden_tests class_level mask
sortable mkdir path burden_test_dir=$burden_tests_dir/@burden_test class_level burden_test

#DIRECTORIES
#====================


#====================
#CATEGORIES
cat cat_project_figure_data=null disp "Figures" class_level project
cat cat_project_annotation_data=null disp "Annotation data" class_level project
cat cat_project_mask_data=null disp "Mask data" class_level project
cat cat_project_simulation_data=null disp "Simulation data" class_level project

cat cat_project_subset_data=null disp "Project Subset Data" class_level project_subset

cat cat_mask_figure_data=null disp "Figures" class_level mask
cat cat_mask_data=null disp "Mask Data" class_level mask

cat cat_gene_figure_data=null disp "Figures" class_level gene
cat cat_gene_data=null disp "Gene Data" class_level gene

cat cat_special_gene_list_figure_data=null disp "Figures" class_level special_gene_list
cat cat_special_gene_list_data=null disp "Special Gene List Data" class_level special_gene_list

cat cat_simulation_data=null disp "Simulations Data" class_level simulation
cat cat_simulation_input_data=null disp "Input data" parent cat_simulation_data
cat cat_simulation_sim_data=null disp "Simulations" parent cat_simulation_data
cat cat_simulation_agg_sim_data=null disp "Aggregated" parent cat_simulation_data
cat cat_simulation_bar_data=null disp "Bar plot data" parent cat_simulation_data
cat cat_simulation_val_plot_data=null disp "Validation plots" parent cat_simulation_data
cat cat_simulation_bar_plot_data=null disp "Bar plots" parent cat_simulation_data
meta constant cat_n_samples=@n_samples disp "Npop" class_level simulation
meta constant cat_n_cases=@n_cases disp "Ncase" class_level simulation
meta constant cat_one_sided=@one_sided disp "One Sided" class_level simulation

cat cat_simulation_batch_data=null disp "Simulation Batch Data" class_level simulation_batch

cat cat_burden_test_data=null disp "Burden Test Data" class_level burden_test

#CATEGORIES
#====================

#====================
#UTILS

lap_trunk=$lap_home/trunk
lap_projects=$lap_home/projects
targeted_base_dir=/humgen/gsa-hpprojects/pfizer/projects/targeted/scratch/flannick
common_bin_dir=$lap_projects/common
targeted_bin_dir=$targeted_base_dir/bin
lib_dir=$targeted_base_dir/lib
bin_dir=$lap_projects/mta/bin

r_cmd=/broad/software/free/Linux/redhat_5_x86_64/pkgs/r_2.15.1/bin/R
r_script_cmd=$r_cmd -f @1 --slave --vanilla --args

draw_matrix_plot_cmd=$r_script_cmd($common_bin_dir/draw_matrix_plot.R)
draw_box_plot_cmd=$r_script_cmd($common_bin_dir/draw_box_plot.R)
draw_hist_plot_cmd=$r_script_cmd($common_bin_dir/draw_hist_plot.R)
draw_bar_plot_cmd=$r_script_cmd($common_bin_dir/draw_bar_plot.R)
draw_qq_plot_cmd=$r_script_cmd($common_bin_dir/draw_qq_plot.R)
draw_line_plot_cmd=$r_script_cmd($common_bin_dir/draw_line_plot.R)

!include $lap_trunk/config/common.cfg
pdflatex_cmd=/broad/software/free/Linux/redhat_5_x86_64/pkgs/texlive-20110510/bin/x86_64-linux/pdflatex

#vep_dir=$lib_dir/ensembl/variant_effect_predictor_new/ensembl-tools-release-76/scripts/variant_effect_predictor
vep_dir=$lib_dir/ensembl/variant_effect_predictor
vep_plugin_dir=$vep_dir/VEP_plugins
vep_condel_config_dir=$vep_plugin_dir/config/Condel/config
loftee_human_ancestor_path=$vep_plugin_dir/loftee-master/human_ancestor.fa.rz
ensembl_cache_dir=$lib_dir/ensembl/cache
ensembl_reference=$lib_dir/ensembl/reference/hg19/Homo_sapiens_assembly19.fasta 

vep_cmd=perl $vep_dir/variant_effect_predictor.pl

snpeff_dir=$lib_dir/snpEff/snpEff
snpeff_jar=$snpeff_dir/snpEff.jar
snpsift_dir=$lib_dir/snpEff/snpEff
snpsift_jar=$snpsift_dir/SnpSift.jar
snpeff_config=$snpeff_dir/snpEff.config
snpeff_heap=4g
snpeff_db_dir=$snpeff_dir/db
snpeff_genome=GRCh37.74
snpeff_dbsnp=$snpeff_db_dir/dbSnp.vcf
snpeff_dbnsfp=$snpeff_db_dir/dbNSFP2.4.txt.gz
dbnsfp_cols_start=9
dbnsfp_cols_ignore=SLR


vep_custom_tabix=$conservation_dir/29way.omega.v2.allchr.bed.gz $conservation_dir/gerp.allchr.bed.gz $conservation_dir/phyloP.allchr.bed.gz $conservation_dir/1kg.20101123.snps_indels_sv.sites.bed.gz
vep_custom_names=29_mammals_omega GERP_UCSC_RS PhyloP 1000G

vep_custom_tabix=$conservation_dir/29way.omega.v2.allchr.bed.gz $conservation_dir/gerp.allchr.bed.gz
vep_custom_names=29_mammals_omega GERP_UCSC_RS

tabix_dir=/broad/software/free/Linux/redhat_5_x86_64/pkgs/tabix/tabix_0.2.2/bin
tabix_cmd=$tabix_dir/tabix
bgzip_cmd=$tabix_dir/bgzip

pseq_dir=$lib_dir/pseq/pseq-0.08.2
pseq_cmd=$pseq_dir/client/pseq

conditional_exec_cmd=perl $common_bin_dir/conditional_exec.pl
smart_join_cmd=perl $common_bin_dir/smart_join.pl
smart_cut_cmd=perl $common_bin_dir/smart_cut.pl
bin_values_cmd=perl $common_bin_dir/bin_values.pl
add_function_cmd=perl $common_bin_dir/add_function.pl
add_header_cmd=perl $common_bin_dir/add_header.pl
transpose_cmd=perl $common_bin_dir/transpose.pl
table_to_beamer_cmd=perl $common_bin_dir/table_to_beamer.pl
text_to_beamer_cmd=perl $common_bin_dir/text_to_beamer.pl
format_columns_cmd=perl $common_bin_dir/format_columns.pl
vcf_utils_cmd=perl $targeted_bin_dir/vcf_utils.pl
sync_ref_alt_cmd=perl $targeted_bin_dir/sync_ref_alt.pl
tped_to_bed_cmd=perl $targeted_bin_dir/tped_to_bed.pl

table_sum_stats_cmd=perl $common_bin_dir/table_sum_stats.pl
transpose_cmd=perl $common_bin_dir/transpose.pl

transcript_fig_cmd=perl $bin_dir/make_transcript_fig.pl

#UTILS
#====================

#====================
#PARAMETERS

variant_group_mem=8000

#PARAMETERS
#====================

#====================
#CONSTANTS

vep_id_annot=Uploaded_variation
vep_trans_annot=Feature
vep_gene_annot=Gene
vep_ccds_annot=CCDS
vep_type_annot=Consequence
vep_loc_annot=Location
vep_canonical_annot=CANONICAL
vep_protein_change_annot=Protein_change
vep_codon_change_annot=Codons
vep_type_synonymous_annot=synonymous_variant
vep_type_missense_annot=missense_variant
vep_type_nonsense_annot=stop_gained
vep_type_readthrough_annot=stop_lost

synonymous_mask=$vep_type_annot,eq:$vep_type_synonymous_annot
missense_mask=$vep_type_annot,eq:$vep_type_missense_annot
nonsense_mask=$vep_type_annot,'eq:$vep_type_nonsense_annot eq:$vep_type_readthrough_annot'
noncoding_mask=$vep_protein_change_annot,eq:$vep_missing_field
coding_mask=$vep_protein_change_annot,ne:$vep_missing_field

vep_consequence_annot=Consequence
vep_consequence_rank=transcript_ablation splice_donor_variant splice_acceptor_variant stop_gained frameshift_variant stop_lost initiator_codon_variant inframe_insertion inframe_deletion missense_variant transcript_amplification splice_region_variant incomplete_terminal_codon_variant synonymous_variant stop_retained_variant coding_sequence_variant mature_miRNA_variant 5_prime_UTR_variant 3_prime_UTR_variant intron_variant NMD_transcript_variant non_coding_exon_variant nc_transcript_variant upstream_gene_variant downstream_gene_variant TFBS_ablation TFBS_amplification TF_binding_site_variant regulatory_region_variant regulatory_region_ablation regulatory_region_amplification feature_elongation feature_truncation intergenic_variant 

vep_id_col=1
vep_trans_col=5
vep_gene_col=4
vep_ccds_col=14

#CONSTANTS
#====================


#====================
#FILES

path file project_variant_vcf_file=@project.variant.vcf.gz dir project_dir disp ".variant.vcf.gz" parent cat_project_annotation_data class_level project comment "The VCF file containing the variants used for annotation as well as sample genotypes"

path file project_variant_vcf_index_file=@project.variant.vcf.gz.tbi dir project_dir disp ".variant.vcf.gz.tbi" parent cat_project_annotation_data class_level project comment "Tabix index file for this vcf file"

path file project_extended_variant_exclude_file=@project.extended.variant.exclude dir project_dir disp ".extended.variant.exclude" parent cat_project_annotation_data class_level project comment "Exclude file for burden tests"

path file project_extended_chrpos_exclude_file=@project.extended.chrpos.exclude dir project_dir disp ".extended.chrpos.exclude" parent cat_project_annotation_data class_level project comment "Exclude file for burden tests (chromosome:position format)"

path file project_variant_site_vcf_file=@project.variant.site.vcf dir project_dir disp ".variant.site.vcf" parent cat_project_annotation_data class_level project comment "The VCF file containing the variants used for annotation; sites only"

table path file project_intervals_file=@project.intervals dir project_dir disp ".intervals" parent cat_project_annotation_data class_level project comment "List of intervals, one for each subset"

meta_table path file project_subset_meta_file=@project.project_subset.meta dir project_dir disp ".project_subset.meta" parent cat_project_annotation_data class_level project comment "Meta file to load project subsets" meta_level project_subset

path file project_gencode_gtf_gz_file=@project.gencode.gtf.gz dir project_dir disp ".gencode.gtf.gz" parent cat_project_annotation_data class_level project comment "The raw GTF input file from GENCODE"

table path file project_gene_appris_file=@project.gene.appris.txt dir project_dir disp ".gene.appris.txt" parent cat_project_annotation_data class_level project comment "Appris information for all genes; external file"

table path file project_subset_vep_file=@project_subset.vep.tsv dir project_subset_dir disp ".vep.tsv" parent cat_project_subset_data class_level project_subset comment "The output of running the VEP on this subset of variants"

table path file project_subset_snpsift_file=@project_subset.snpsift dir project_subset_dir disp ".snpsift" parent cat_project_subset_data class_level project_subset comment "The output of running the SnpSIFT on this subset of variants"

#path file project_subset_vep_summary_file=@project_subset.vep.summary.html dir project_subset_dir disp ".vep.summary.html" parent cat_project_subset_data class_level project_subset comment "The summary file dumped by running the VEP on this subset of variants"

table path file project_vep_file=@project.vep.tsv dir project_dir disp ".vep.tsv" parent cat_project_annotation_data class_level project comment "The output of running the VEP on all variants"

table path file project_snpsift_file=@project.snpsift dir project_dir disp ".snpsift" parent cat_project_annotation_data class_level project comment "The output of running the SnpSIFT on all variants"

table path file project_maf_file=@project.maf.txt dir project_dir disp ".maf.txt" parent cat_project_annotation_data class_level project comment "The minor allele frequency for each variant"

table path file project_annot_file=@project.annot.txt dir project_dir disp ".annot.txt" parent cat_project_annotation_data class_level project comment "All annotations for each variant"

table path file project_gene_name_map_file=@project.gene.map dir project_dir disp ".gene.map" parent cat_project_annotation_data class_level project comment "A map from ENSEMBL gene ID to gene name"

table path file project_gene_canonical_file=@project.gene.canonical.txt dir project_dir disp ".gene.canonical.txt" parent cat_project_annotation_data class_level project comment "Map from gene to the canonical transcript, only includes genes with at least one variant in the canonical transcript"

!!expand:large:large:medium:small! \
table path file project_large_transcript_gene_file=@project.large.transcript.gene.txt dir project_dir disp ".large_transcript.gene.txt" parent cat_project_annotation_data class_level project comment "List of all transcripts to use, with parent gene name"

!!expand:large:large:medium:small! \
table path file project_large_annot_file=@project.large_annot.tsv dir project_dir disp ".large_annot.tsv" parent cat_project_annotation_data class_level project comment "List of annotations for large set of transcripts"

table path file project_num_gene_transcripts_text_file=@project.num.gene.transcripts.txt dir project_dir disp ".num.gene.transcripts.txt" parent cat_project_annotation_data class_level project comment "Number of transcripts per gene, dat file"

path file project_num_gene_transcripts_pdf_file=@project.num.gene.transcripts.pdf dir project_dir disp ".num.gene.transcripts.pdf" parent cat_project_figure_data class_level project comment "Number of transcripts per gene, pdf file"

table path file project_num_variant_transcripts_text_file=@project.num.variant.transcripts.txt dir project_dir disp ".num.variant.transcripts.txt" parent cat_project_mask_data class_level project comment "Number of transcripts per variant, dat file"

!!expand:large:large:medium:small! \
table path file project_num_variant_large_transcripts_text_file=@project.num.variant.large.transcripts.txt dir project_dir disp ".num.variant.large.transcripts.txt" parent cat_project_mask_data class_level project comment "Number of transcripts in large set per variant, dat file"

!!expand:common:common:lowfreq:rare! \
path file project_num_common_variant_transcripts_pdf_file=@project.num.common.variant.transcripts.pdf dir project_dir disp ".num.common.variant.transcripts.pdf" parent cat_project_figure_data class_level project comment "Number of transcripts per common variant, pdf file"

!!expand:large:large:medium:small! \
path file project_num_variant_maf_large_transcripts_pdf_file=@project.num.variant.maf.large.transcripts.pdf dir project_dir disp ".num.variant.maf.large.transcripts.pdf" parent cat_project_figure_data class_level project comment "Number of transcripts in large set per variant, stratified by frequency"

!!expand:large:large:medium:small! \
table path file mask_large_setid_file=@mask.large.setid dir mask_dir disp ".large.setid" parent cat_mask_data class_level mask comment "SetID file for this mask for large set of transcripts"

!!expand:large:large:medium:small! \
table path file mask_large_set_chrpos_file=@mask.large.set.chrpos dir mask_dir disp ".large.set.chrpos" parent cat_mask_data class_level mask comment "Chr:pos file for this mask for large set of transcripts; includes Non-pathogenic transcript"

!!expand:large:large:medium:small! \
table path file mask_num_variant_large_transcripts_text_file=@mask.num.variant.large.transcripts.txt dir mask_dir disp ".num.variant.large.transcripts.txt" parent cat_mask_data class_level mask comment "Number of transcripts in large set per variant, dat file"

!!expand:large:large:medium:small! \
table path file mask_num_any_all_variant_large_transcripts_text_file=@mask.num.any.all.large.txt dir mask_dir disp ".num.any.all.large.txt" parent cat_mask_data class_level mask comment "Aggregate number of variants in who change membership in mask based on transcript in large set"

!!expand:large:large:medium:small! \
table path file mask_gene_size_large_transcripts_text_file=@mask.gene.size.large.transcripts.txt dir mask_dir disp ".gene.size.large.transcripts.txt" parent cat_mask_data class_level mask comment "Number of variants in each transcript according to this mask"

!!expand:large:large:medium:small! \
table path file mask_gene_size_large_most_del_text_file=@mask.gene.size.large.most_del.txt dir mask_dir disp ".gene.size.large.most_del.txt" parent cat_mask_data class_level mask comment "Number of variants in mask according to most and least deleterious annotations"

!!expand:large:large:medium:small! \
table path file mask_gene_size_stats_large_transcripts_text_file=@mask.gene.size.stats.large.transcripts.txt dir mask_dir disp ".gene.size.stats.large.transcripts.txt" parent cat_mask_data class_level mask comment "Statistics on change in number of variants for different use of transcripts in large set according to this mask"

table path file mask_gene_size_stats_transcripts_text_file=@mask.gene.size.stats.transcripts.txt dir mask_dir disp ".gene.size.stats.transcripts.txt" parent cat_mask_data class_level mask comment "Statistics on change in number of variants for different use of transcripts in all sets according to this mask"

!!expand:common:common:lowfreq:rare! \
path file project_num_common_variant_transcripts_pdf_file=@project.num.common.variant.transcripts.pdf dir project_dir disp ".num.common.variant.transcripts.pdf" parent cat_project_figure_data class_level project comment "Number of transcripts per common variant, pdf file"


!!expand:common:all:common:lowfreq:rare! \
!!expand:large:large:medium:small! \
table path file project_num_any_all_common_variant_large_transcripts_text_file=@project.num.any.all.common.large.txt dir project_dir disp ".num.any.all.common.large.txt" parent cat_project_mask_data class_level project comment "Aggregate number of common variants who change membership in all masks based on transcript in large set"

!!expand:pdf:tex:pdf! \
path file project_num_any_all_all_variant_pdf_file=@project.num.any.all.all.pdf dir project_dir disp ".num.any.all.all.pdf" parent cat_project_figure_data trunk @project.num.any.all.all class_level project comment "Table of number of variants in each mask who change membership for each set of transcripts"

!!expand:large:large:medium:small! \
table path file project_gene_size_stats_large_transcripts_text_file=@project.gene.size.stats.large.transcripts.txt dir project_dir disp ".gene.size.stats.large.transcripts.txt" parent cat_project_mask_data class_level project comment "Statistics on change in number of variants for different use of transcripts in large set according to all masks"

#!!expand:,:canonical,Canonical:max,max vs. min:canonical,max vs. canonical:appris,max vs. appris:quantile,25th vs. 75th quantile:max_mean,max vs. mean:mean_min,mean vs. min:canonical_mean,canonical vs. mean:max_med,max vs. median:med_min,median vs. min:canonical_med,canonical vs. median! \

!!expand:,:canonical,Canonical:max_mean,max vs. mean:max_med,max vs. median! \
path file mask_gene_size_canonical_transcripts_pdf_file=@mask.gene.size.canonical.transcripts.pdf dir mask_dir disp ".gene.size.canonical.transcripts.pdf" parent cat_mask_figure_data class_level mask comment "Change in number of transcripts in this mask according to Canonical criteria"

#!!expand:,:canonical,Canonical:max,max vs. min:canonical,max vs. canonical:appris,max vs. appris:quantile,25th vs. 75th quantile:max_mean,max vs. mean:mean_min,mean vs. min:canonical_mean,canonical vs. mean:max_med,max vs. median:med_min,median vs. min:canonical_med,canonical vs. median! \

!!expand:,:canonical,Canonical:max_mean,max vs. mean:max_med,max vs. median! \
path file mask_gene_size_canonical_transcripts_scatter_pdf_file=@mask.gene.size.canonical.transcripts.scatter.pdf dir mask_dir disp ".gene.size.canonical.transcripts.scatter.pdf" parent cat_mask_figure_data class_level mask comment "Scatter plot of number of transcripts in this mask for Canonical transcripts"

!!expand:large:large:medium:small! \
table path file mask_gene_size_strat_large_transcripts_text_file=@mask.gene.size.strat.large.transcripts.txt dir mask_dir disp ".gene.size.strat.large.transcripts.txt" parent cat_mask_data class_level mask comment "Numbers of variants in each gene for different fold increases in large transcript set"

!!expand:large:large:medium:small! \
path file mask_gene_size_strat_large_transcripts_pdf_file=@mask.gene.size.strat.large.transcripts.pdf dir mask_dir disp ".gene.size.strat.large.transcripts.pdf" parent cat_mask_figure_data class_level mask comment "Box plots of the numbers of variants in each gene for different fold increases in large transcript set"

!!expand:,:small_,small.:,:small_,small.! \
!!expand:,:lambdav,freqv:.5,.001:4,.001:.5,.01:4,.01! \
path file mask_analytical_sample_size_lambdalambdav_freqfreqv_small_pdf_file=@mask.analytical.sample.size.lambdalambdav.freqfreqv.small.pdf dir mask_dir disp ".analytical.sample.size.lambdalambdav.freqfreqv.small.pdf" parent cat_mask_figure_data class_level mask comment "Plot of sample size lost based on analytical power calculations, lambda=lambdav, freq=freqv"

#!!expand:,:canonical,Canonical:max,max vs. min:canonical,max vs. canonical:appris,max vs. appris:quantile,25th vs. 75th quantile:max_mean,max vs. mean:mean_min,mean vs. min:canonical_mean,canonical vs. mean:max_med,max vs. median:med_min,median vs. min:canonical_med,canonical vs. median! \

!!expand:,:canonical,Canonical:max_mean,max vs. mean:max_med,max vs. median! \
!!expand:large:large:medium:small! \
path file project_gene_size_canonical_large_transcripts_pdf_file=@project.gene.size.canonical.large.transcripts.pdf dir project_dir disp ".gene.size.canonical.large.transcripts.pdf" parent cat_project_figure_data class_level project comment "Change in number of transcripts in all mask according to Canonical criteria applied across large transcript set"

!!expand:,:canonical,Canonical:max_mean,max vs. mean:max_med,max vs. median! \
!!expand:large:large:medium:small! \
path file project_gene_size_canonical_large_transcripts_sum_text_file=@project.gene.size.canonical.large.transcripts.sum.txt trunk @project.gene.size.canonical.large.transcripts.sum dir project_dir disp ".gene.size.canonical.large.transcripts.sum.txt" parent cat_project_mask_data class_level project comment "Change in number of transcripts in all mask according to Canonical criteria averaged across large transcript set"

!!expand:,:canonical,Canonical:max_mean,max vs. mean:max_med,max vs. median! \
!!expand:large:large:medium:small! \
!!expand:pdf:tex:pdf! \
path file project_gene_size_canonical_large_transcripts_sum_pdf_file=@project.gene.size.canonical.large.transcripts.sum.pdf trunk @project.gene.size.canonical.large.transcripts.sum dir project_dir disp ".gene.size.canonical.large.transcripts.sum.pdf" parent cat_project_figure_data class_level project comment "Change in number of transcripts in all mask according to Canonical criteria averaged across large transcript set"

!!expand:,:canonical,Canonical:max_mean,max vs. mean:max_med,max vs. median! \
!!expand:pdf:tex:pdf! \
path file project_gene_size_canonical_transcripts_sum_pdf_file=@project.gene.size.canonical.transcripts.sum.pdf trunk @project.gene.size.canonical.transcripts.sum dir project_dir disp ".gene.size.canonical.transcripts.sum.pdf" parent cat_project_figure_data class_level project comment "Change in number of transcripts in all mask according to Canonical criteria averaged across all transcript sets"

!!expand:large:large:medium:small! \
table path file special_gene_list_large_stats_txt_file=@special_gene_list.large.stats.txt dir project_dir disp ".large.stats.txt" parent cat_special_gene_list_data class_level special_gene_list comment "Statistics subset down to the list of special genes for large transcript list"

!!expand:large:large:medium:small! \
!!expand:pdf:tex:pdf! \
path file special_gene_list_large_stats_pdf_file=@special_gene_list.large.stats.pdf trunk @special_gene_list.large.stats dir project_dir disp ".large.stats.pdf" parent cat_special_gene_list_figure_data class_level special_gene_list comment "Statistics subset down to the list of special genes for large transcript list"

!!expand:large:large:medium:small! \
table path file gene_plot_large_transcript_file=@gene.plot.large.transcript.txt dir gene_dir disp ".plot.large.transcript.txt" parent cat_gene_data class_level gene comment "Transcript file to use for plotting the gene with large transcripts"

!!expand:large:large:medium:small! \
table path file gene_plot_large_variant_file=@gene.plot.large.variant.txt dir gene_dir disp ".plot.large.variant.txt" parent cat_gene_data class_level gene comment "Variant file to use for plotting the gene with large transcripts"

!!expand:large:large:medium:small! \
!!expand:pdf:tex:pdf! \
path file gene_large_transcripts_pdf_file=@gene.large.transcripts.pdf trunk @gene.large.transcripts dir gene_dir disp ".large.transcripts.pdf" parent cat_gene_figure_data class_level gene comment "Plot of large transcripts for the gene"

!!expand:large:large:medium:small! \
table path file project_large_transcript_exons_file=@project.large.transcript.exons dir project_dir disp ".large.transcript.exons" parent cat_project_annotation_data class_level project comment "List of exons for each transcript"

!!expand:large:large:medium:small! \
path file project_large_gene_exons_file=@project.large.gene.exons dir project_dir disp ".large.gene.exons" parent cat_project_simulation_data class_level project comment "Number of exons for each gene"

!!expand:transcripts_per_gene:transcripts_per_gene:exons_per_transcript:exons_per_gene:exon_length! \
!!expand:large:large:medium:small! \
path file project_large_transcripts_per_gene_dist_file=@project.large.transcripts_per_gene_dist.txt dir project_dir disp ".large.transcripts_per_gene_dist.txt" parent cat_project_simulation_data class_level project comment "Distribution of transcripts per gene for large set"

!!expand:large:large:medium:small! \
path file mask_large_variants_per_gene_dist_file=@mask.large.variants_per_gene_dist.txt dir mask_dir disp ".large.variants_per_gene_dist.txt" parent cat_mask_data class_level mask comment "Distribution of variants per gene for large set"

table path file simulation_maf_effect_size_file=@simulation.maf_effect_size.txt dir simulation_dir disp ".maf_effect_size.txt" parent cat_simulation_input_data class_level simulation comment "Specify file of maf/effect size samples"

table path file simulation_batch_intercept_data_file=@simulation_batch.intercept.data dir simulation_batch_dir disp ".intercept.data" parent cat_simulation_batch_data class_level simulation_batch comment "Data from running simulations to learn intercept for log(p) scaling"

!!expand:large:large:medium:small! \
table path file simulation_batch_large_null_data_file=@simulation_batch.large.null.data dir simulation_batch_dir disp ".large.null.data" parent cat_simulation_batch_data class_level simulation_batch comment "Data from running simulations to learn null distribution for large set of transcripts"

!!expand:large:large:medium:small! \
table path file simulation_batch_large_simulations_output_file=@simulation_batch.large.sim.out dir simulation_batch_dir disp ".large.sim.out" parent cat_simulation_batch_data class_level simulation_batch comment "Output of simulations for large set"

meta_table path file simulation_simulation_batch_meta_file=@simulation.simulation_batch.meta dir simulation_dir disp ".simulation_batch.meta" parent cat_simulation_input_data class_level simulation comment "Meta file for simulation batches" meta_level simulation_batch

table path file simulation_intercept_data_file=@simulation.intercept.data dir simulation_dir disp ".intercept.data" parent cat_simulation_sim_data class_level simulation comment "Data from running simulations to learn intercept for log(p) scaling"

!!expand:burden:burden:skat:skat_perm! \
!!expand:large:large:medium:small! \
table path file simulation_large_burden_null_data_file=@simulation.large.burden.null.data dir simulation_dir disp ".large.burden.null.data" parent cat_simulation_sim_data class_level simulation comment "Data from running simulations to learn null distribution for burden test"

path file simulation_intercept_pdf_file=@simulation.intercept.pdf dir simulation_dir disp ".intercept.pdf" parent cat_simulation_val_plot_data class_level simulation comment "Plot of intercept values for log(p) scaling"

path file simulation_intercept_file=@simulation.intercept dir simulation_dir disp ".intercept" parent cat_simulation_sim_data class_level simulation comment "Intercept for log(p) scaling"

!!expand:large:large:medium:small! \
table path file simulation_large_simulations_output_file=@simulation.large.sim.out dir simulation_dir disp ".large.sim.out" parent cat_simulation_sim_data class_level simulation comment "Output of simulations for large set, per simulation statistics"

path file simulation_num_gene_transcripts_pdf_file=@simulation.num.gene.transcripts.pdf dir simulation_dir disp ".num.gene.transcripts.pdf" parent cat_simulation_val_plot_data class_level simulation comment "Number of transcripts per gene"

path file simulation_gene_size_transcripts_pdf_file=@simulation.gene.size.transcripts.pdf dir simulation_dir disp ".gene.size.transcripts.pdf" parent cat_simulation_val_plot_data class_level simulation comment "Change in number of transcripts from this simulation between pathogenic and collapse criteria"

!!expand:large:large:medium:small! \
table path file simulation_large_simulations_aggregated_output_file=@simulation.large.sim.aggregated.out dir simulation_dir disp ".large.sim.aggregated.out" parent cat_simulation_agg_sim_data class_level simulation comment "Output of simulations for large set, aggregated statistics"

!!expand:,:varexp,varianceexplained:varexp,variance explained:fold_increase,fold increase:ntrans,number of transcripts:nvar,number of variants:percentile,percentiles:reduced_percentile,reduced percentiles:top_20,top 20%! \
!!expand:large:large:medium:small! \
table path file simulation_large_simulations_varexp_aggregated_output_file=@simulation.large.sim.varexp.aggregated.out dir simulation_dir disp ".large.sim.varexp.aggregated.out" parent cat_simulation_agg_sim_data class_level simulation comment "Output of simulations for large set, aggregated statistics over varianceexplained"

!!expand:large:large:medium:small! \
table path file simulation_large_rel_bar_dat_file=@simulation.large.rel.bar.dat dir simulation_dir disp ".large.rel.bar.dat" parent cat_simulation_bar_data class_level simulation comment "Relative change in sample size between different criteria for large set of transcripts"

!!expand:,:varexp,varianceexplained:varexp,variance explained:fold_increase,fold increase:ntrans,number of transcripts:nvar,number of variants:percentile,percentiles:reduced_percentile,reduced percentiles:top_20,top 20%! \
!!expand:large:large:medium:small! \
table path file simulation_large_varexp_rel_bar_dat_file=@simulation.large.varexp.rel.bar.dat dir simulation_dir disp ".large.varexp.rel.bar.dat" parent cat_simulation_bar_data class_level simulation comment "Relative change in sample size between different criteria for large set of transcripts, stratified by varianceexplained"

!!expand:,:path_collapse,path_and_collapse:path_collapse,pathogenic and collapse:all_burden,all possible burden:burden_skat,all burden and SKAT:bonf,bonferroni:skat,just SKAT:skat_perm,SKAT with permutations:rand_path,trade-off between random and pathogenic:rand_path_skat,trade-off between random and pathogenic SKAT! \
!!expand:large:large:medium:small! \
path file simulation_large_path_collapse_rel_bar_pdf_file=@simulation.large.path_collapse.rel.bar.pdf dir simulation_dir disp ".large.path_collapse.rel.bar.pdf" parent cat_simulation_bar_plot_data class_level simulation comment "Relative change in sample size between path_and_collapse criteria for large set of transcripts"

!!expand:,:no_ylab_,no.ylab.:,:no_ylab_,no.ylab.! \
!!expand:,:path_collapse,path_and_collapse:path_collapse,pathogenic and collapse:all_burden,all possible burden:burden_skat,all burden and SKAT:bonf,bonferroni:skat,just SKAT:skat_perm,SKAT with permutations:rand_path,trade-off between random and pathogenic:rand_path_skat,trade-off between random and pathogenic SKAT! \
path file simulation_path_collapse_no_ylab_rel_bar_pdf_file=@simulation.path_collapse.no.ylab.rel.bar.pdf dir simulation_dir disp ".path_collapse.no.ylab.rel.bar.pdf" parent cat_simulation_bar_plot_data class_level simulation comment "Relative change in sample size between path_and_collapse criteria for all sets of transcripts"

!!expand:,:path_collapse,path_and_collapse:rand_path,trade-off between random and pathogenic:rand_path_skat,trade-off between random and pathogenic SKAT! \
!!expand:large:large:medium:small! \
path file simulation_large_path_collapse_tradeoff_pdf_file=@simulation.large.path_collapse.tradeoff.pdf dir simulation_dir disp ".large.path_collapse.tradeoff.pdf" parent cat_simulation_bar_plot_data class_level simulation comment "Trade-off between path_and_collapse criteria for large set of transcripts"

!!expand:,:no_ylab_,no.ylab.:,:no_ylab_,no.ylab.! \
!!expand:,:path_collapse,path_and_collapse:rand_path,trade-off between random and pathogenic:rand_path_skat,trade-off between random and pathogenic SKAT! \
path file simulation_path_collapse_no_ylab_tradeoff_pdf_file=@simulation.path_collapse.no.ylab.tradeoff.pdf dir simulation_dir disp ".path_collapse.no.ylab.tradeoff.pdf" parent cat_simulation_bar_plot_data class_level simulation comment "Trade-off between path_and_collapse criteria for all sets of transcripts"

!!expand:,:varexp,varianceexplained:varexp,variance explained:fold_increase,fold increase:ntrans,number of transcripts:nvar,number of variants:percentile,percentiles:reduced_percentile,reduced percentiles:top_20,top 20%! \
!!expand:,:path_collapse,path_and_collapse:path_collapse,pathogenic and collapse:all_burden,all possible burden:burden_skat,all burden and SKAT:bonf,bonferroni:skat,just SKAT:skat_perm,SKAT with permutations:rand_path,random and pathogenic:rand_path_skat,random and pathogenic SKAT! \
!!expand:large:large:medium:small! \
path file simulation_large_varexp_path_collapse_rel_bar_pdf_file=@simulation.large.varexp.path_collapse.rel.bar.pdf dir simulation_dir disp ".large.varexp.path_collapse.rel.bar.pdf" parent cat_simulation_bar_plot_data class_level simulation comment "Relative change in sample size between path_and_collapse criteria for large set of transcripts, stratified by varianceexplained"

!!expand:,:no_ylab_,no.ylab.:,:no_ylab_,no.ylab.! \
!!expand:,:varexp,varianceexplained:varexp,variance explained:fold_increase,fold increase:ntrans,number of transcripts:nvar,number of variants:percentile,percentiles:reduced_percentile,reduced percentiles:top_20,top 20%! \
!!expand:,:path_collapse,path_and_collapse:path_collapse,pathogenic and collapse:all_burden,all possible burden:burden_skat,all burden and SKAT:bonf,bonferroni:skat,just SKAT:skat_perm,SKAT with permutations:rand_path,random and pathogenic:rand_path_skat,random and pathogenic SKAT! \
path file simulation_varexp_path_collapse_no_ylab_rel_bar_pdf_file=@simulation.varexp.path_collapse.no.ylab.rel.bar.pdf dir simulation_dir disp ".varexp.path_collapse.no.ylab.rel.bar.pdf" parent cat_simulation_bar_plot_data class_level simulation comment "Relative change in sample size between path_and_collapse criteria for all setts of transcripts, stratified by varianceexplained"

!!expand:,:varexp,varianceexplained:varexp,variance explained:fold_increase,fold increase:ntrans,number of transcripts:nvar,number of variants:percentile,percentiles:reduced_percentile,reduced percentiles:top_20,top 20%! \
!!expand:,:path_collapse,path_and_collapse:rand_path,random and pathogenic:rand_path_skat,random and pathogenic SKAT! \
!!expand:large:large:medium:small! \
path file simulation_large_varexp_path_collapse_tradeoff_pdf_file=@simulation.large.varexp.path_collapse.tradeoff.pdf dir simulation_dir disp ".large.varexp.path_collapse.tradeoff.pdf" parent cat_simulation_bar_plot_data class_level simulation comment "Trade-off in sample size between path_and_collapse criteria for large set of transcripts, stratified by varianceexplained"

path file burden_test_ped_file=@burden_test.ped dir project_dir disp ".ped" parent cat_burden_test_data class_level burden_test comment "EPACTS ped file format containing the phenotypes as well as any covariates"

nohead table path file burden_test_gene_path_trans_list_file=@burden_test.gene.path.trans.list dir burden_test_dir disp ".gene.path.trans.list" parent cat_burden_test_data class_level burden_test comment "A file with two columns, first is gene to test, second is pathogenic transcript"

!!expand:large:large:medium:small! \
nohead table path file burden_test_large_initial_set_chrpos_file=@burden_test.large.initial.set.chrpos dir burden_test_dir disp ".large.initial.set.chrpos" parent cat_burden_test_data class_level burden_test comment "Set chr/pos file consisting only of genes for this burden test"

!!expand:large:large:medium:small! \
nohead table path file burden_test_large_set_chrpos_file=@burden_test.large.set.chrpos dir burden_test_dir disp ".large.set.chrpos" parent cat_burden_test_data class_level burden_test comment "Set chr/pos file consisting only of genes for this burden test; includes Non-pathogenic transcript"

!!expand:large:large:medium:small! \
table path file burden_test_large_gassoc_file=@burden_test.large.gassoc dir burden_test_dir disp ".large.gassoc" parent cat_burden_test_data class_level burden_test comment "Output of running the burden test"

!!expand:large:large:medium:small! \
table path file burden_test_large_flat_gassoc_file=@burden_test.large.flat.gassoc dir burden_test_dir disp ".large.flat.gassoc" parent cat_burden_test_data class_level burden_test comment "Processed output of gassoc file to have separate columns for each test"

!!expand:large:large:medium:small! \
table path file burden_test_large_path_non_sign_comp_file=@burden_test.large.path.non.sign.comp.txt dir burden_test_dir disp ".large.path.non.sign.comp.txt" parent cat_burden_test_data class_level burden_test comment "Statistics on the number of variants in correct direction between pathogenic and non-pathogenic transcript for large transcript set"

#FILES
#====================


#====================
#COMMANDS

prop num_project_subsets=scalar

local cmd make_project_variant_vcf_index_file=$tabix_cmd -f -p vcf !{input,,project_variant_vcf_file} class_level project

cmd make_project_extended_chrpos_exclude_file=$smart_join_cmd --in-delim $tab !{input,--file,project_extended_variant_exclude_file} --exec "cat !{input,,project_large_annot_file} | awk -F\"\\t\" -v OFS=\"\\t\" 'NR == 1 {for(i=1;i<=NF;i++) {m[\\$i]=i}} NR > 1 {print \\$m[\"VAR\"],\\$m[\"Location\"]}' | sort -u" --extra 2 --fill 2 --fill-value NA | cut -f2 | awk '\$1 != "NA"' | sed 's/:/\t/' > !{output,,project_extended_chrpos_exclude_file} class_level project

local cmd make_project_variant_site_vcf_file=zcat !{input,,project_variant_vcf_file} | cut -f1-8 > !{output,,project_variant_site_vcf_file} class_level project

local cmd make_project_intervals_file=cat !{input,,project_variant_site_vcf_file} | perl -ne 'BEGIN {\$n=`cat !{input,,project_variant_site_vcf_file} | fgrep -v \\\# | wc -l`; \$num_per = int(\$n / !{prop,,project,num_project_subsets} + 0.5); \$l=0} unless (/^\\#/) {chomp; @f = split(/\t/); if (!defined \$chrom) {\$chrom = \$f[0]; \$pos = \$f[1]} \$l++; if (\$f[0] ne \$chrom) {print "\$chrom:\$pos "; \$chrom=\$f[0]; \$pos=\$f[1]} if (\$l % \$num_per == 0) {print "\$chrom:\${pos}-\$f[1]\n"; \$pos=\$f[1]+1;}} END { unless (\$l % \$num_per) {print "\$chrom:\${pos}-\$f[1]\n"} }' > !{output,,project_intervals_file} class_level project

prop subset_interval=scalar

local cmd make_project_subset_meta_file=cat !{input,,project_intervals_file} | awk '{n="!{prop,,project}_subset_"NR; print n,"class project_subset"; print n,"parent","!{prop,,project}"; print n,"sort",NR; print n,"subset_interval",\$0}' > !{output,,project_subset_meta_file} class_level project

#--all_refseq --merged !{output,--stats_file,project_subset_vep_summary_file}

subset_vcf_file=(zcat !{input,,project_variant_vcf_file} | $vcf_utils_cmd --print-header | cut -f1-8; $tabix_cmd !{input,,project_variant_vcf_file} !{prop,,project_subset,subset_interval} | cut -f1-8)

short cmd make_project_subset_vep_file=$subset_vcf_file | $vep_cmd --offline -o STDOUT --dir $ensembl_cache_dir  --polyphen b --sift b --ccds --canonical --regulatory --domains flags --fields Uploaded_variation,Location,Allele,Gene,Feature,Feature_type,Consequence,cDNA_position,CDS_position,Protein_position,Amino_acids,Codons,Existing_variation,SOURCE,CCDS,CANONICAL,HGNC,ENSP,DOMAINS,MOTIF_NAME,MOTIF_POS,HIGH_INF_POS,MOTIF_SCORE_CHANGE,SIFT,PolyPhen > !{output,,project_subset_vep_file} class_level project_subset

snpsift_exe_helper=java -Xmx$snpeff_heap -jar $snpsift_jar 

short cmd make_project_subset_snpsift_file=cols=`zcat $snpeff_dbnsfp | head -n1 | cut -f${dbnsfp_cols_start}- | sed 's/\t/\n/g' | egrep -v '$dbnsfp_cols_ignore' | tr '\n' ' '`; \
  $subset_vcf_file | cut -f1-8 \
  | $snpsift_exe_helper dbnsfp -v $snpeff_dbnsfp -f `echo \$cols | sed 's/\s\s*/,/g'` - \
  | $vcf_utils_cmd --print-annots | $smart_cut_cmd --tab-delim --select-col 0,1,ID --select-col 0,1,"\$cols" \ 
  > !{output,,project_subset_snpsift_file} class_level project_subset


#1. Include all transcripts that have a CCDS tag.
#2. Include transcripts labeled "protein_coding" and where either 'mRNA_start_NF' or 'mRNA_end_NF' are not included. 

local cmd make_project_vep_file=(fgrep \\# !{input,,project_subset_vep_file,limit=1} && cat !{input,,project_subset_vep_file} | fgrep -v \\#) > !{output,,project_vep_file} class_level project

local cmd make_project_snpsift_file=(head -n1 !{input,,project_subset_snpsift_file,limit=1} && tail -qn+2 !{input,,project_subset_snpsift_file}) > !{output,,project_snpsift_file} class_level project

cmd make_project_maf_file=$pseq_cmd !{input,,project_variant_vcf_file} v-freq --show-id | cut -d: -f3- | cut -f1,10 | awk -F"\t" -v OFS="\t" '\$2 > .5 {\$2 = 1 - \$2} {print \$1,\$2}' > !{output,,project_maf_file} class_level project

cmd make_project_annot_file=$smart_join_cmd --in-delim $tab !{input,--file,project_maf_file} --exec "sed 's/^\\\#//g' !{input,,project_vep_file} | fgrep -v \\\#" --exec "awk '!m[\\$1] {print} {m[\\$1]=1}' !{input,,project_snpsift_file}" --header 1 --multiple 2 --extra 1 --ignore-status 141 > !{output,,project_annot_file} class_level project

short cmd make_project_gene_name_map_file=zcat !{input,,project_gencode_gtf_gz_file} | fgrep -v \\#\\# | cut -d\; -f1,5 | sed 's/.\*gene_id\s\s*//' | awk -v OFS="\t" '{print \$1,\$3}' | sed 's/"//g' | sed 's/\.[0-9][0-9]*;*//g' | sort -u > !{output,,project_gene_name_map_file} class_level project

!!expand:,:large,filter:large,:medium,| egrep -v '(mRNA_start_NF|mRNA_end_NF)':small,| fgrep 'tag "CCDS"'! \
short cmd make_project_large_transcript_gene_file=zcat !{input,,project_gencode_gtf_gz_file} | fgrep -v \\\#\\\# | egrep '(transcript_type "protein_coding"|tag "CCDS")' filter | cut -d\; -f1,2 | sed 's/.\*gene_id\s\s*//' | awk -v OFS="\t" '{print \$1,\$3}' | sed 's/"//g' | sed 's/\.[0-9][0-9]*;*//g' | sort -u | $smart_cut_cmd --in-delim $tab --select-col 0,'2 1' | awk -F"\t" '\$1 != \$2' > !{output,,project_large_transcript_gene_file} class_level project

canonical_header=Canonical

short cmd make_project_gene_canonical_file=$smart_cut_cmd --in-delim $tab !{input,--file,project_annot_file} --select-col 1,1,'$vep_gene_annot $vep_trans_annot' --exact --require-col-match --select-row 1,1,$vep_canonical_annot,YES --exclude-row 1,1 | sort -u | sed '1 s/^/Gene\t$canonical_header\n/' > !{output,,project_gene_canonical_file} class_level project

!!expand:large:large:medium:small! \
short cmd make_project_large_annot_file=$smart_join_cmd --in-delim $tab --exec "$smart_cut_cmd --in-delim $tab !{input,--file,project_annot_file} --select-col 1,1,'$vep_trans_annot $vep_gene_annot' --exact | tail -n+2 | sort -u | cat - !{input,,project_large_transcript_gene_file} | cut -f1,2 | sort | uniq -d | sed '1 s/^/$vep_trans_annot\t$vep_gene_annot\n/'" !{input,--file,project_annot_file} --col 1,1 --col 1,2 --col 2,$(($vep_trans_col+1)) --col 2,$(($vep_gene_col+1)) --extra 2 --multiple 2 --header 1 > !{output,,project_large_annot_file} class_level project

compute_num_transcripts=tail -n+@4 !{input,,@1} | $smart_cut_cmd --tab-delim --select-col 0,'@2' | sed 's/$/\t1/' | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --col @6 --group-col 1 @8 --totals --print-header | cut -f1,@7 | sed '1 s/.*/@5\t@3/'

large_disp=All GENCODE
medium_disp=Confirmed GENCODE
small_disp=CCDS

short cmd make_project_num_gene_transcripts_text_file=$smart_join_cmd --in-delim $tab --fill 1 --extra 1 --fill 2 --extra 2 --fill-value 0 --header 1 --exec "$compute_num_transcripts(project_small_transcript_gene_file,2,$small_disp,1,GENE,2,3,)" --exec "$compute_num_transcripts(project_medium_transcript_gene_file,2,$medium_disp,1,GENE,2,3,)" --exec "$compute_num_transcripts(project_large_transcript_gene_file,2,$large_disp,1,GENE,2,3,)" > !{output,,project_num_gene_transcripts_text_file} class_level project

!!expand:large:large:medium:small! \
cmd make_project_num_variant_large_transcripts_text_file=$compute_num_transcripts(project_large_annot_file,2 3,$large_disp,2,GENE\tVARIANT,3,2-3,--group-col 2) > !{output,,project_num_variant_large_transcripts_text_file} class_level project rusage_mod $variant_group_mem

cmd make_project_num_variant_transcripts_text_file=$smart_join_cmd --in-delim $tab --header 1 --exec "$smart_join_cmd --in-delim $tab --col 1 --col 2 --fill 1 --extra 1 --fill 2 --extra 2 --fill-value 0 --header 1 !{input,--file,project_num_variant_small_transcripts_text_file} !{input,--file,project_num_variant_medium_transcripts_text_file} !{input,--file,project_num_variant_large_transcripts_text_file}" !{input,--file,project_maf_file} --multiple 1 --extra 2 --col 1,2 | awk -F"\t" -v OFS="\t" '{t=\$1; \$1=\$2; \$2=t} {print}'  > !{output,,project_num_variant_transcripts_text_file} class_level project

prop max_num_transcripts=scalar default 15
prop num_gene_transcript_breaks=scalar default 60
prop num_variant_transcript_breaks=scalar default 120

small_color=red
medium_color=blue
large_color=gray

local cmd make_project_num_gene_transcripts_pdf_file=$draw_hist_plot_cmd !{input,,project_num_gene_transcripts_text_file} !{output,,project_num_gene_transcripts_pdf_file} 2,3,4 '' 'Number of transcripts per gene' colors='$small_color,$medium_color,$large_color' sep=$tab alpha=.4 x.max=!{prop,,project,max_num_transcripts} breaks=!{prop,,project,num_gene_transcript_breaks} overlay.density=T cex=1.1 class_level project

rare_maf=0.001
common_maf=0.01

rare_disp=rare
lowfreq_disp=low frequency
common_disp=common
all_disp=all

Rare_disp=Rare
Lowfreq_disp=Low frequency
Common_disp=Common
All_disp=All

awk_rare_filter=\$@1 > 0 && \$@1 <= $rare_maf
awk_lowfreq_filter=\$@1 > $rare_maf && \$@1 <= $common_maf
awk_common_filter=\$@1 > $common_maf


!!expand:,:common,Common:common,$common_disp:lowfreq,$lowfreq_disp:rare,$rare_disp! \
cmd make_project_num_common_variant_transcripts_pdf_file=awk -F"\t" 'NR == 1 || ($awk_common_filter(6))' !{input,,project_num_variant_transcripts_text_file} | $draw_hist_plot_cmd /dev/stdin !{output,,project_num_common_variant_transcripts_pdf_file} 3,4,5 '' 'Number of transcripts per Common variant' colors='$small_color,$medium_color,$large_color' sep=$tab alpha=.4 x.max=!{prop,,project,max_num_transcripts} breaks=!{prop,,project,num_variant_transcript_breaks} overlay.density=T cex=1.1 class_level project

common_color=cyan
lowfreq_color=cornflowerblue
rare_color=darkblue

!!expand:,:large,column:large,5:medium,4:small,3! \
short cmd make_project_num_variant_maf_large_transcripts_pdf_file=awk -F"\t" -v OFS="\t" 'NR == 1 {\$7="$Common_disp"; \$8="$Lowfreq_disp"; \$9="$Rare_disp"} NR > 1 { \$7=\$8=\$9="NA"; if ($awk_common_filter(6)) {\$7=\$column} else if ($awk_lowfreq_filter(6)) {\$8=\$column} else if ($awk_rare_filter(6)) {\$9=\$column}} {print}' !{input,,project_num_variant_transcripts_text_file} | $draw_hist_plot_cmd /dev/stdin !{output,,project_num_variant_maf_large_transcripts_pdf_file} 7,8,9 '' 'Number of transcripts per variant' colors='$common_color,$lowfreq_color,$rare_color' sep=$tab alpha=.4 x.max=!{prop,,project,max_num_transcripts} breaks=!{prop,,project,num_variant_transcript_breaks} overlay.cumulative=T legend.pos=right height.scale=.75 cex=1.1 class_level project

prop mask_filter_condition=scalar

!!expand:large:large:medium:small! \
large_setid_helper=cat !{input,,project_large_annot_file} | awk -F"\t" -v OFS="\t" 'NR == 1 {for(i=1;i<=NF;i++) {m[\$i]=i}} NR == 1 || (!{prop,,mask,mask_filter_condition}) {print \$m["$vep_gene_annot"],\$m["$vep_trans_annot"],\$m["@1"]}' | tail -n+2 | sort -u | sed '1 s/^/$vep_gene_annot\t$vep_trans_annot\tVAR\n/'

!!expand:large:large:medium:small! \
short cmd make_mask_large_setid_file=$large_setid_helper(VAR) > !{output,,mask_large_setid_file} class_level mask

!!expand:large:large:medium:small! \
short cmd make_mask_large_set_chrpos_file=$large_setid_helper(Location) | sed '1 s/VAR/Chr\tPos/' | sed '1! s/:\([0-9][0-9]*\)/\t\1/' > !{output,,mask_large_set_chrpos_file} class_level mask

!!expand:,:large,title:large,${large_disp}:medium,${medium_disp}:small,${small_disp}! \
short cmd make_mask_num_variant_large_transcripts_text_file=$smart_join_cmd --in-delim $tab --exec "$smart_join_cmd --in-delim $tab --fill 1 --extra 1 --fill-value 0 --header 1 --exec \"$compute_num_transcripts(mask_large_setid_file,1 3,title_!{prop;;mask},2,GENE\tVARIANT,3,2-3,--group-col 2)\" --exec \"sed '1 s/\(\t[^\t][^\t]*\)/\1_with_annot/g' !{input,,project_num_variant_large_transcripts_text_file}\" --col 1 --col 2" --exec "$smart_cut_cmd --in-delim $tab !{input,--file,project_num_gene_transcripts_text_file} --select-col 1,1 --select-col 1,1,'$large_disp' --vec-delim : | sed '1 s/\(\t[^\t][^\t]*\)/\1_total_for_gene/g'" --header 1 --extra 2 --fill 2 --fill-value 0 --multiple 1 | awk -F"\t" -v OFS="\t" 'NR == 1 {print \$0,"!{prop,,mask}_any","!{prop,,mask}_all"} NR > 1 {any=(\$3>0); all=(\$3==\$5); print \$0,any,all }' > !{output,,mask_num_variant_large_transcripts_text_file} class_level mask rusage_mod $variant_group_mem

!!expand:large:large:medium:small! \
short cmd make_mask_num_any_all_variant_large_transcripts_text_file=$smart_join_cmd !{input,--file,project_maf_file} --in-delim $tab !{input,--file,mask_num_variant_large_transcripts_text_file} --header 1 --extra 1 --col 2,2 --multiple 2 | awk -F"\t" -v OFS="\t" 'NR == 1 {print} NR > 1 && \$2 > 0 { f=\$2; \$2="$all_disp"; print; \$2=f; if ($awk_rare_filter(2)) { \$2="$rare_disp" } else if ($awk_lowfreq_filter(2)) { \$2="$lowfreq_disp" } else if ($awk_common_filter(2)) { \$2="$common_disp" } {print}}' | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --col !{prop,,mask}_any --col !{prop,,mask}_all --totals --summaries --print-header --has-header --group-col MAF | $smart_cut_cmd --in-delim $tab --select-col 0,1,MAF --select-col 0,1,!{prop,,mask}_all_tot --select-col 0,1,!{prop,,mask}_all_mean --select-col 0,1,!{prop,,mask}_any_tot --select-col 0,1,!{prop,,mask}_any_mean --require-col-match -x | $add_function_cmd --in-delim $tab --header 1 --val-header !{prop,,mask}_fraction_constant --col1 !{prop,,mask}_all_tot --col2 !{prop,,mask}_any_tot --type divide | $add_function_cmd --in-delim $tab --header 1 --val-header !{prop,,mask}_fraction_which_change --val1 1 --col2 !{prop,,mask}_fraction_constant --type subtract > !{output,,mask_num_any_all_variant_large_transcripts_text_file} class_level mask

num_variants_header=NUM_VARIANTS

compute_num_transcripts=tail -n+@4 !{input,,@1} | $smart_cut_cmd --tab-delim --select-col 0,'@2' | sed 's/$/\t1/' | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --col @6 --group-col 1 @8 --totals --print-header | cut -f1,@7 | sed '1 s/.*/@5\t@3/'

most_del_disp=MOST_DEL
least_del_disp=LEAST_DEL

!!expand:large:large:medium:small! \
cmd make_mask_gene_size_large_most_del_text_file=$smart_cut_cmd !{input,--file,mask_num_variant_large_transcripts_text_file} --tab-delim --select-col 1,1,'GENE !{prop,,mask}_any !{prop,,mask}_all' | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --has-header --col !{prop,,mask}_any --col !{prop,,mask}_all  --group-col GENE --totals --print-header | $smart_cut_cmd --in-delim $tab --select-col 0,1,'GENE !{prop,,mask}_any_tot !{prop,,mask}_all_tot' | sed '1 s/.*/GENE\t$most_del_disp\t$least_del_disp/' > !{output,,mask_gene_size_large_most_del_text_file} class_level mask

!!expand:large:large:medium:small! \
cmd make_mask_gene_size_large_transcripts_text_file=$smart_join_cmd --header 1 --in-delim $tab --exec "$compute_num_transcripts(mask_large_setid_file,1 2,$num_variants_header,2,GENE\tTRANSCRIPT,3,2-3,--group-col 2)" --exec "$smart_cut_cmd --in-delim $tab !{input,--file,project_large_transcript_gene_file} --select-col 1,'2 1' | sed '1 s/^/GENE\tTRANSCRIPT\n/' | sed 's/$/\t0/'" --merge --col 1 --col 2 > !{output,,mask_gene_size_large_transcripts_text_file} class_level mask

low_quantile=.25
med_quantile=.50
high_quantile=.75

appris_header=APPRIS

!!expand:large:large:medium:small! \
cmd make_mask_gene_size_stats_large_transcripts_text_file=$smart_join_cmd --exec "$smart_join_cmd --in-delim $tab !{input,--file,mask_gene_size_large_transcripts_text_file} !{input,--file,project_gene_canonical_file} !{input,--file,mask_gene_size_large_most_del_text_file} --header 1 --multiple 1 --extra 2 --fill 2 --extra 3 --fill 3 --fill-value 0" --exec "cut -f2,3 !{input,,project_gene_appris_file} | sed '1 s/^/Gene\tTranscript\t$appris_header\n/' | sed '1! s/$/\t0/'" --col 1 --col 2 --extra 2 --fill 2 --fill-value NA --header 1 | awk -F"\t" -v OFS="\t" 'NR > 1 {if (\$4 == \$2) {\$4 = \$3} else {\$4 = 0} if (\$7 == 0) {\$7 = \$3} else {\$7 = "NA"}} {print}'  | $smart_cut_cmd --in-delim $tab --exclude-row 0,1,$num_variants_header,eq:0 | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --has-header --print-header --group-col GENE --col $num_variants_header --col $canonical_header --col $appris_header --col $most_del_disp --col $least_del_disp --quantile $med_quantile --quantile $low_quantile --quantile $high_quantile --quantile 0 --quantile 1 --totals --summaries | $smart_cut_cmd --in-delim $tab --select-col 0,1,'GENE ${num_variants_header}_mean ${num_variants_header}_quant_$med_quantile ${num_variants_header}_quant_$low_quantile ${num_variants_header}_quant_$high_quantile ${least_del_disp}_quant_0 ${most_del_disp}_quant_0 ${canonical_header}_tot ${appris_header}_mean' --exact --require-col-match | awk -F"\t" -v OFS="\t" 'NR == 1 {\$2="Mean"; \$3="50pct"; \$4="25pct"; \$5="75pct"; \$6="LEAST_DEL"; \$7="MOST_DEL"; \$8="CANONICAL"; \$9="APPRIS"; print \$0,"MOST_LEAST_CHANGE","MOST_CANONICAL_CHANGE","MOST_APPRIS_CHANGE","FOLD_CHANGE","MOST_MEAN_CHANGE","MEAN_LEAST_CHANGE","CANONICAL_MEAN_CHANGE","MOST_MEDIAN_CHANGE","MEDIAN_LEAST_CHANGE","CANONICAL_MEDIAN_CHANGE"; for (i=1;i<=NF;i++) {m[\$i]=i}} NR > 1 {if (\$m["CANONICAL"] != "NA" && \$m["CANONICAL"] > 0) {most_canonical=\$m["MOST_DEL"]/\$m["CANONICAL"]} else {most_canonical="NA"} if (\$m["APPRIS"] != "NA" && \$m["APPRIS"] > 0) {most_appris=\$m["MOST_DEL"]/\$m["APPRIS"]} else {most_appris="NA"} if (\$m["LEAST_DEL"] != "NA" && \$m["LEAST_DEL"] > 0) {most_least=\$m["MOST_DEL"]/\$m["LEAST_DEL"]; mean_least=\$m["Mean"]/\$m["LEAST_DEL"]; median_least=\$m["50pct"]/\$m["LEAST_DEL"]} else {most_least="NA"; mean_least="NA"; median_least="NA"} if (\$m["Mean"] != "NA" && \$m["Mean"] > 0) {most_mean=\$m["MOST_DEL"]/\$m["Mean"]; canonical_mean=\$m["CANONICAL"]/\$m["Mean"]} else {most_mean="NA"; canonical_mean="NA"} if (\$m["50pct"] != "NA" && \$m["50pct"] > 0) {most_median=\$m["MOST_DEL"]/\$m["50pct"]; canonical_median=\$m["CANONICAL"]/\$m["50pct"]} else {most_median="NA"; canonical_median="NA"} print \$0,most_least,most_canonical,most_appris,\$m["75pct"]/\$m["25pct"],most_mean,mean_least,canonical_mean,most_median,median_least,canonical_median}' > !{output,,mask_gene_size_stats_large_transcripts_text_file} class_level mask

short cmd make_mask_gene_size_stats_transcripts_text_file=$smart_join_cmd --in-delim $tab --exec "tail -qn+2 !{input,,mask_gene_size_stats_large_transcripts_text_file} !{input,,mask_gene_size_stats_medium_transcripts_text_file} !{input,,mask_gene_size_stats_small_transcripts_text_file} | cut -f1 | sort -u | sed '1 s/^/Gene\n/'" --exec "sed '1 s/\(\S\S*\)/${small_disp}_\1/g' !{input,,mask_gene_size_stats_small_transcripts_text_file}" --exec "sed '1 s/\(\S\S*\)/${medium_disp}_\1/g' !{input,,mask_gene_size_stats_medium_transcripts_text_file}" --exec "sed '1 s/\(\S\S*\)/${large_disp}_\1/g' !{input,,mask_gene_size_stats_large_transcripts_text_file}" --header 1 --rest-extra 1 --fill 2 --fill 3 --fill 4 > !{output,,mask_gene_size_stats_transcripts_text_file} class_level mask

!!expand:common:all:common:lowfreq:rare! \
!!expand:large:large:medium:small! \
local cmd make_project_num_any_all_common_variant_large_transcripts_text_file=$smart_cut_cmd --tab-delim --exec "sed '1 s/!{prop,,mask,limit=1}_//g' !{input,,mask_num_any_all_variant_large_transcripts_text_file,limit=1} | sed '1 s/MAF/Mask/'" --select-row 1,1 | $smart_cut_cmd --tab-delim !{raw;;mask;--exec "$smart_cut_cmd --tab-delim --file *mask_num_any_all_variant_large_transcripts_text_file --select-row 1,1,MAF,$common_disp | sed 's/^\S\S*/@disp/'"} !{input,mask_num_any_all_variant_large_transcripts_text_file} --stdin-first > !{output,,project_num_any_all_common_variant_large_transcripts_text_file} class_level project

Annotated=\# annotated
Annotation_changes=\% variable

local cmd make_project_num_any_all_all_variant_tex_file=$smart_cut_cmd --in-delim $tab --exclude-col 2-3,1 --paste --exec "$smart_cut_cmd !{input,--file,project_num_any_all_all_variant_small_transcripts_text_file} --in-delim $tab -x --require-col-match --select-col 1,1 --select-col 1,1,'any_tot any_mean fraction_which_change' | sed '1 s/\(.*\)/\1\n\1/' | sed '1 s/\t\S\S*/\t$small_disp/g'" --exec "$smart_cut_cmd !{input,--file,project_num_any_all_all_variant_medium_transcripts_text_file} --in-delim $tab -x --require-col-match --select-col 1,1 --select-col 1,1,'any_tot any_mean fraction_which_change' | sed '1 s/\(.*\)/\1\n\1/' | sed '1 s/\t\S\S*/\t$medium_disp/g'" --exec "$smart_cut_cmd !{input,--file,project_num_any_all_all_variant_large_transcripts_text_file} --in-delim $tab -x --require-col-match --select-col 1,1 --select-col 1,1,'any_tot any_mean fraction_which_change' | sed '1 s/\(.*\)/\1\n\1/' | sed '1 s/\t\S\S*/\t$large_disp/g'" | $format_columns_cmd --in-delim $tab --header 2 --commify 2 --commify 5 --commify 8 --number-format '3 4 6 7 9 10',%.1f --percentage '3 4 6 7 9 10' | sed '2 s/\tany_tot\tany_mean\tfraction_which_change/\t$Annotated\t$Annotated\t$Annotation_changes/g' | awk -F"\t" -v OFS="\t" 'NR > 2 {for (i=3;i<=NF;i+=3) {\$i="("\$i")"}} {print}' | sed 's/\(strict\|broad\)/\$_{\\text{\1}}$/' | $table_to_beamer_cmd --in-delim $tab --header-cols 1 --header-rows 2 --auto-dim --multi-col 1-2 --multi-row 1 --left-align 1 `for i in 2 5 8; do echo --right-align \$i --right-align \$((i+1)) --right-align \$((i+2)); done` > !{output,,project_num_any_all_all_variant_tex_file} class_level project

local cmd make_project_num_any_all_all_variant_pdf_file=$run_latex_cmd(project_num_any_all_all_variant_tex_file,project_num_any_all_all_variant_pdf_file) class_level project

!!expand:large:large:medium:small! \
local cmd make_project_gene_size_stats_large_transcripts_text_file=$smart_join_cmd --in-delim $tab --exec "tail -qn+2 !{input,,mask_gene_size_stats_large_transcripts_text_file} | cut -f1 | sort -u | sed '1 s/^/GENE\n/'" !{raw,,mask,--exec "sed '1 s/\(\S\S*\)/@{disp}_\1/g' *mask_gene_size_stats_large_transcripts_text_file"} !{input,mask_gene_size_stats_large_transcripts_text_file} --header 1 --rest-extra 1 `i=2; for f in !{prop,,mask}; do echo --fill \$i; i=$((i+1)); done` --fill-value NA > !{output,,project_gene_size_stats_large_transcripts_text_file} class_level project

prop max_fold_increase=scalar default 3
prop num_fold_breaks=scalar

#!!expand:,:canonical,Max,Min,cols:max,most deleterious,least deleterious,10:canonical,most deleterious,canonical transcript,11:appris,most deleterious,appris transcript,12:quantile,75th percentile,25th percentile,13:max_mean,most deleterious,mean,14:mean_min,mean,least deleterious,15:canonical_mean,canonical,mean,16:max_med,most deleterious,median,17:med_min,median,least deleterious,18:canonical_med,canonical,median,19! \

prop r_disp=scalar

#CHANGE BACK TO LOCAL

!!expand:,:canonical,Max,Min,cols:max_mean,"most deleterious",mean,14:max_med,most deleterious,median,17! \
short cmd make_mask_gene_size_canonical_transcripts_pdf_file=sed '1 s/\($small_disp\|$medium_disp\|$large_disp\)_\S\S*/\1/g' !{input,,mask_gene_size_stats_transcripts_text_file} | $draw_hist_plot_cmd /dev/stdin !{output,,mask_gene_size_canonical_transcripts_pdf_file} cols,$((cols+18)),$((cols+36)) '' 'Fold-increase in variants between Max and Min transcript' colors='$small_color,$medium_color,$large_color' sep=$tab alpha=.4 x.max=!{prop,,project,max_fold_increase} !{prop,breaks=,project,num_fold_breaks,if_prop=num_fold_breaks,allow_empty=1} overlay.density=T overlay.cumulative=T legend.pos=topright log=y inset=0,0.2 title.shift=-2 cex=1.1 class_level mask

#!!expand:;:canonical;Min;Max;col1;col2:max;Least deleterious;Most deleterious;LEAST_DEL;MOST_DEL:canonical;Canonical transcript;Most deleterious;CANONICAL;MOST_DEL:appris;APPRIS transcript;Most deleterious;APPRIS;MOST_DEL:quantile;25th percentile;75th percentile;25pct;75pct:max_mean;Mean number of variants;Most deleterious;Mean;MOST_DEL:mean_min;Least deleterious;Mean number of variants;LEAST_DEL;Mean:canonical_mean;Mean number of variants;Canonical transcript;Mean;CANONICAL:max_med;Median number of variants;Most deleterious;50pct;MOST_DEL:med_min;Least deleterious;Median number of variants;LEAST_DEL;50pct:canonical_med;Median number of variants;Canonical transcript;50pct;CANONICAL! \

!!expand:;:canonical;Min;Max;col1;col2:max_mean;Mean number of variants;Most deleterious;Mean;MOST_DEL:max_med;Median number of variants;Most deleterious;50pct;MOST_DEL! \
local cmd make_mask_gene_size_canonical_transcripts_scatter_pdf_file=$smart_cut_cmd --tab-delim --exec "sed 's/$/\t$small_disp\t$small_color\t3/g' !{input,,mask_gene_size_stats_transcripts_text_file}" --exec "sed 's/$/\t$medium_disp\t$medium_color\t2/g' !{input,,mask_gene_size_stats_transcripts_text_file}" --exec "sed 's/$/\t$large_disp\t$large_color\t1/g' !{input,,mask_gene_size_stats_transcripts_text_file}" --vec-delim : --select-col 1-3,1 --exclude-row 1-3,1 --select-col 1,1,'${small_disp}_col1:${small_disp}_col2:${small_disp}:$small_color:3' --select-col 2,1,'${medium_disp}_col1:${medium_disp}_col2:${medium_disp}:$medium_color:2' --select-col 3,1,'${large_disp}_col1:${large_disp}_col2:${large_disp}:$large_color:1' --exact --require-col-match | sed '1 s/^/Gene\tMin\tMax\tTranscripts\tColor\tOrder\n/' | $draw_matrix_plot_cmd /dev/stdin !{output,,mask_gene_size_canonical_transcripts_scatter_pdf_file} 'Number of variants in each gene' 'Min,Max' sep=$tab fill.col=Color order.col=Order fill.label=Transcripts alpha=.2 rev.legend=TRUE class_level mask


min_fold_bin=1
max_fold_bin=3
bin_width=.2

!!expand:large:large:medium:small! \
local cmd make_mask_gene_size_strat_large_transcripts_text_file=$smart_cut_cmd --in-delim $tab !{input,--file,mask_gene_size_stats_large_transcripts_text_file} --exact --require-col-match --select-col 1,1,'GENE FOLD_CHANGE 50pct' | awk -F"\t" -v OFS="\t" 'NR > 1 {\$2 = int(\$2 / $bin_width) * $bin_width} NR == 1 || (\$2 >= $min_fold_bin && \$2 <= $max_fold_bin) {print}' > !{output,,mask_gene_size_strat_large_transcripts_text_file} class_level mask

!!expand:large:large:medium:small! \
local cmd make_mask_gene_size_strat_large_transcripts_pdf_file=sed '1 s/50pct/Size of genes by fold increase/' !{input,,mask_gene_size_strat_large_transcripts_text_file} | $draw_box_plot_cmd /dev/stdin !{output,,mask_gene_size_strat_large_transcripts_pdf_file} '' 'Fold increase' 'Median number of variants' 'Size of genes by fold increase' header=TRUE label=FOLD_CHANGE order=FOLD_CHANGE sep=$tab show.p=FALSE class_level mask

!!expand:,:plotsmall_,plotheight,plotcex:,.8,1.1:small_,.7,1.3! \
!!expand:,:lambdav,freqv:.5,.001:4,.001:.5,.01:4,.01! \
local cmd make_mask_analytical_sample_size_lambdalambdav_freqfreqv_plotsmall_pdf_file=sed '1 s/\($small_disp\|$medium_disp\|$large_disp\)_\S\S*/\1/g' !{input,,mask_gene_size_stats_transcripts_text_file} | cut -f14,$((14+18)),$((14+36)) | awk -v OFS="\t" -F"\t" 'function rel_n(lambda, f) { return (1 / ((1 + lambda) * f * log(1 + lambda) + (1 - (1 + lambda) * f) * log((1 - (1 + lambda) * f)/(1 - f)))) } NR > 1 {for (i=1;i<=NF;i++) {if (\$i != "NA") {\$i=rel_n(lambdav, freqv)/rel_n(lambdav/\$i, freqv*\$i)}}} {print \$0}' | $draw_hist_plot_cmd /dev/stdin !{output,,mask_analytical_sample_size_lambdalambdav_freqfreqv_plotsmall_pdf_file} 1,2,3 '' 'Relative sample size of "most deleterious"' colors='$small_color,$medium_color,$large_color' sep=$tab alpha=.4 x.min=.5 x.max=1 rev.x=T !{prop,breaks=,project,num_fold_breaks,if_prop=num_fold_breaks,allow_empty=1} overlay.cumulative=T legend.pos=bottomright log=y title.shift=-2 ylab="Number of genes" height.scale=plotheight cex=plotcex class_level mask 

prop gene_list=list
prop transcript_list=list

!!expand:large:large:medium:small! \
local cmd make_special_gene_list_large_stats_txt_file=$smart_join_cmd --header 1 --in-delim $tab --extra 1 --exec "sed '1 s/^/Gene\tGene\n/' !{input,,project_gene_name_map_file}" --exec "$smart_join_cmd --in-delim $tab --header 1 !{input,mask_gene_size_stats_transcripts_text_file} --exec \"tail -qn+2  !{input,,mask_gene_size_stats_transcripts_text_file} | cut -f1 | sort -u | sed '1 s/^/Gene\n/'\" !{raw;;mask;--exec \"$smart_cut_cmd --in-delim $tab --file *mask_gene_size_stats_transcripts_text_file --exact --require-col-match --vec-delim : --select-col 1,1,'Gene:${large_disp}_MOST_DEL' | sed '1 s/\t\(\S\S*\)/\t@{disp}_\1/g'\"} --rest-extra 1 --fill-all --fill-value 0 | $smart_cut_cmd --in-delim $tab --select-row 0,1 --select-row 0,1,Gene,'!{prop;;special_gene_list;gene_list;sep=|}' --exact --require-col-match" --exec "$smart_join_cmd --in-delim $tab --header 1 !{input,mask_gene_size_large_transcripts_text_file} --exec \"tail -qn+2  !{input,,mask_gene_size_large_transcripts_text_file} | cut -f1-2 | sort -u | sed '1 s/^/Gene\tTRANSCRIPT\n/'\" !{raw,,mask,--exec \"sed '1 s/\(\S\S*\)$/@{disp}_TRANSCRIPT/' *mask_gene_size_large_transcripts_text_file\"} --col 1 --col 2 --rest-extra 1 --fill-all --fill-value 0 | $smart_cut_cmd --in-delim $tab --vec-delim : --select-row 0,1 --select-row 0,1,TRANSCRIPT,'!{prop;;special_gene_list;transcript_list;sep=|}' --exclude-col 0,1,TRANSCRIPT --exact --require-col-match" !{raw;;mask;| $add_function_cmd --in-delim $tab --header 1 --val-header '@{disp}_MOST_DEL_TRANSCRIPT_FOLD_CHANGE' --col1 '@{disp}_${large_disp}_MOST_DEL' --col2 '@{disp}_TRANSCRIPT' --type divide} | cut -f2- | sed '1 s/${large_disp}_//g' > !{output,,special_gene_list_large_stats_txt_file} class_level special_gene_list

!!expand:large:large:medium:small! \
local cmd make_special_gene_list_large_stats_tex_file=cat !{input,,special_gene_list_large_stats_txt_file} | $smart_cut_cmd --in-delim $tab --select-col 0,1,Gene --vec-delim : !{raw;;mask;--select-col 0,1,'@{disp}_TRANSCRIPT:@{disp}_MOST_DEL:@{disp}_MOST_DEL_TRANSCRIPT_FOLD_CHANGE'} --no-regex --require-col-match | sed '1 s/\(.*\)/\1\n\1/' | sed '1 s/_\(MOST_DEL\|TRANSCRIPT\|FOLD_CHANGE\)//g' | sed '2 s/\(!{prop,,mask,disp,sep=\|}\)_//g' | sed '2 s/MOST_DEL_TRANSCRIPT_FOLD_CHANGE/Fold change/g' | sed '2 s/MOST_DEL/Most del./g' | sed '2 s/TRANSCRIPT/Transcript/g' | $format_columns_cmd --in-delim $tab --header 2 --number-format '4 7 10 13',%.2f | $table_to_beamer_cmd --in-delim $tab --header-cols 1 --header-rows 2 --auto-dim --multi-col 1-2 --multi-row 1 --left-align 1 `i=2; for m in !{prop,,mask}; do for g in 0 1 2; do echo --right-align $((i+g)); done; i=$((i+3)); done` > !{output,,special_gene_list_large_stats_tex_file} class_level special_gene_list

!!expand:large:large:medium:small! \
local cmd make_special_gene_list_large_stats_pdf_file=$run_latex_cmd(special_gene_list_large_stats_tex_file,special_gene_list_large_stats_pdf_file) class_level special_gene_list

prop color=scalar

#!!expand:,:canonical,Max,Min,cols:max,most deleterious,least deleterious,MOST_LEAST_CHANGE:canonical,most deleterious,canonical transcript,CANONICAL:appris,most deleterious,appris transcript,APPRIS:quantile,75th percentile,25th percentile,FOLD_CHANGE:max_mean,most deleterious,mean,MOST_MEAN_CHANGE:mean_min,mean,least deleterious,MEAN_LEAST_CHANGE:canonical_mean,canonical,mean,CANONICAL_MEAN_CHANGE:max_med,most deleterious,median,MOST_MEDIAN_CHANGE:med_min,median,least deleterious,MEDIAN_LEAST_CHANGE:canonical_med,canonical,median,CANONICAL_MEDIAN_CHANGE! \

!!expand:,:canonical,Max,Min,cols:max_mean,most deleterious,mean,MOST_MEAN_CHANGE:max_med,most deleterious,median,MOST_MEDIAN_CHANGE! \
!!expand:large:large:medium:small! \
local cmd make_project_gene_size_canonical_large_transcripts_pdf_file=$smart_cut_cmd --in-delim $tab !{input,--file,project_gene_size_stats_large_transcripts_text_file} --select-col 1,1 --select-col 1,1,'cols' --vec-delim : | sed 's/_cols//g' | $draw_hist_plot_cmd /dev/stdin !{output,,project_gene_size_canonical_large_transcripts_pdf_file} '!{prop::mask:disp:sep=,}' '' 'Fold-increase in variants between Max and Min transcript' colors='!{prop::mask:color:sep=,}' sep=$tab alpha=.4 x.max=!{prop,,project,max_fold_increase} !{prop,breaks=,project,num_fold_breaks,if_prop=num_fold_breaks,allow_empty=1} overlay.density=T overlay.cumulative=T legend.pos=topright log=y inset=0,0.2 cex=1.1 class_level project

!!expand:,:canonical,Max,Min,intcols,Cols:max_mean,most deleterious,mean,Mean MOST_DEL MOST_MEAN_CHANGE,Mean\tMost del.\tFold change:max_med,most deleterious,median,50pct MOST_DEL MOST_MEDIAN_CHANGE,Median transcript\tMost del.\tFold change! \
!!expand:large:large:medium:small! \
local cmd make_project_gene_size_canonical_large_transcripts_sum_text_file=$smart_cut_cmd --in-delim $tab --exclude-row .,1 !{input,mask_gene_size_stats_large_transcripts_text_file} !{raw::mask:--exec "$smart_cut_cmd --in-delim $tab --file *mask_gene_size_stats_large_transcripts_text_file --select-col 1,1 --select-col 1,1,'intcols' | $table_sum_stats_cmd --has-header --print-header \`for f in intcols; do echo --col \\$f; done\` --summaries --in-delim $tab --out-delim $tab | $smart_cut_cmd --in-delim $tab --select-col 0,1,mean | sed 's/_mean//g' | sed 's/^/@disp\t/'"} | sed '1 s/^/Mask\tCols\n/' | $format_columns_cmd --in-delim $tab --header 1 --number-format '2 3 4',%.2f > !{output,,project_gene_size_canonical_large_transcripts_sum_text_file} class_level project

!!expand:,:canonical,Max,Min,intcols,Cols:max_mean,most deleterious,mean,Mean MOST_DEL MOST_MEAN_CHANGE,Mean\tMost del.\tFold change:max_med,most deleterious,median,50pct MOST_DEL MOST_MEDIAN_CHANGE,Median transcript\tMost del.\tFold change! \
!!expand:large:large:medium:small! \
local cmd make_project_gene_size_canonical_large_transcripts_sum_tex_file=cat !{input,,project_gene_size_canonical_large_transcripts_sum_text_file} | $table_to_beamer_cmd --in-delim $tab --header-cols 1 --header-rows 1 --auto-dim --left-align 1 > !{output,,project_gene_size_canonical_large_transcripts_sum_tex_file} class_level project

!!expand:,:canonical:max_mean:max_med! \
!!expand:large:large:medium:small! \
local cmd make_project_gene_size_canonical_large_transcripts_sum_pdf_file=$run_latex_cmd(project_gene_size_canonical_large_transcripts_sum_tex_file,project_gene_size_canonical_large_transcripts_sum_pdf_file) class_level project

!!expand:,:canonical,Max,Min,intcols,Cols:max_mean,most deleterious,mean,Mean MOST_DEL MOST_MEAN_CHANGE,Mean\tMost del.\tFold change:max_med,most deleterious,median,50pct MOST_DEL MOST_MEDIAN_CHANGE,Median transcript\tMost del.\tFold change! \
local cmd make_project_gene_size_canonical_transcripts_sum_tex_file=$smart_cut_cmd --in-delim $tab --exec "cat !{input,,project_gene_size_canonical_small_transcripts_sum_text_file} | sed '1 s/\(.*\)/\1\n\1/' | sed '1 s/\t[^\t][^\t]*/\t$small_disp/g'" --exec "cat !{input,,project_gene_size_canonical_medium_transcripts_sum_text_file} | sed '1 s/\(.*\)/\1\n\1/' | sed '1 s/\t[^\t][^\t]*/\t$medium_disp/g'" --exec "cat !{input,,project_gene_size_canonical_large_transcripts_sum_text_file} | sed '1 s/\(.*\)/\1\n\1/' | sed '1 s/\t[^\t][^\t]*/\t$large_disp/g'" --paste --exclude-col 2-3,1 | $table_to_beamer_cmd --in-delim $tab --header-cols 1 --header-rows 2 --multi-row 1 --multi-col 1 --auto-dim --left-align 1 > !{output,,project_gene_size_canonical_transcripts_sum_tex_file} class_level project

!!expand:,:canonical:max_mean:max_med! \
local cmd make_project_gene_size_canonical_transcripts_sum_pdf_file=$run_latex_cmd(project_gene_size_canonical_transcripts_sum_tex_file,project_gene_size_canonical_transcripts_sum_pdf_file) class_level project

prop ensembl_id=scalar

adjust_exons=awk -F\"\\t\" -v OFS=\"\\t\" 'BEGIN {g=\"\"; cs=@2; ce=@3} g == \"\" || g != \\$2 {s=@1; e=@1} \\$1 == \"UTR\" {g=\\$2; if (\\$cs > e) {s = \\$cs} if (\\$ce > e) {e = \\$ce}} \\$1 == \"exon\" && \\$2 == g {if (\\$cs < e) {\\$cs = e} if (\\$ce < e) {\\$ce = e}} {print}'
invert_exons=awk -F\"\\t\" -v OFS=\"\\t\" 'BEGIN {cs=@1; ce=@2} {\\$cs=-\\$cs; \\$ce=-\\$ce} {print}'

clean_exons=$adjust_exons(0,4,5) | $invert_exons(4,5) | $smart_cut_cmd --in-delim $tab --select-col 0,'1 2 3 5 4' | sort -k2,2 -k3,3 -k4,4g | $adjust_exons(-3e9,4,5) | $invert_exons(4,5) | $smart_cut_cmd --in-delim $tab --select-col 0,'1 2 3 5 4'

!!expand:large:large:medium:small! \
parse_large_transcripts_helper=$smart_join_cmd --in-delim $tab --exec "$smart_cut_cmd !{input,--file,project_large_transcript_gene_file} --select-col 1,@3 @1 | sort -u" --exec "zcat !{input,,project_gencode_gtf_gz_file} | fgrep -v \\\#\\\# | cut -f1,3,4,5,9 | cut -d\; -f1,2 | awk -v OFS=\"\\t\" '\\$2 == \"exon\" || \\$2 == \"UTR\" {print \\$2,\\$6,\\$@4,\\$1,\\$3,\\$4}' | sed 's/\(\"\|;\)//g' | sed 's/\.[0-9]*//g' | $smart_cut_cmd --in-delim $tab --select-col 0,'1 3-6' @2 | sort -u | sort -k2,2 -k3,3 -k4,4g | $clean_exons | $smart_cut_cmd --in-delim $tab --select-row 0,1,exon --select-col 0,2-5 | sort -k1,1 -k2,2 -k3,3 | awk -F\"\\t\" '\\$3 != \\$4'" --extra 2 --multiple 2

!!expand:large:large:medium:small! \
short cmd make_gene_plot_large_transcript_file=$parse_large_transcripts_helper(--select-row 1\,2\,!{prop::gene:ensembl_id},--select-row 0\,2\,!{prop::gene:ensembl_id},1,8) | cut -f1,3- > !{output,,gene_plot_large_transcript_file} class_level gene

!!expand:large:large:medium:small! \
short cmd make_gene_plot_large_variant_file=id="!{prop,,gene,ensembl_id}"; $smart_join_cmd --exec "fgrep -v \\\# !{input,,project_variant_site_vcf_file} | cut -f2-3" --col 1,2 --extra 1 --multiple 2 --exec "$smart_join_cmd !{raw;--exec;mask;\"$smart_cut_cmd --in-delim $tab --file *mask_large_setid_file --select-row 1,1,Gene,\$id --exact --require-col-match --select-col 1,1,'VAR Feature' | sed 's/$/\t@color\t@sort/'\"} --merge --col 1 --col 2" !{input,mask_large_setid_file} | cut -f2- | sort -nrk4 | cut -f1-3 | perl -ne '@f = split("\t"); push(@f,ucfirst(pop(@f))); print join("\t", @f)' > !{output,,gene_plot_large_variant_file} class_level gene

!!expand:large:large:medium:small! \
local cmd make_gene_large_transcripts_tex_file=$transcript_fig_cmd !{input,,gene_plot_large_transcript_file} !{input,,gene_plot_large_variant_file} > !{output,,gene_large_transcripts_tex_file} class_level gene

!!expand:large:large:medium:small! \
local cmd make_gene_large_transcripts_pdf_file=$run_latex_cmd(gene_large_transcripts_tex_file,gene_large_transcripts_pdf_file) class_level gene

count_to_list_helper=awk '{print \$1,1}' | $table_sum_stats_cmd --group-col 1 --totals --col 2 --out-delim $tab --print-header |  $smart_cut_cmd --in-delim $tab --select-col 0,1 --select-col 0,1,'num' --exact --exclude-row 0,1 | sort -gk1 | awk -F"\t" -v OFS="\t" 'BEGIN {n=0} {for (i=n+1;i<\$1;i++) {print i,0} n=\$1; if (n > 0) {print}}' | cut -f2 | $transpose_cmd --in-delim $tab --out-delim , | sed 's/^/[/' | sed 's/$/]/'

item_to_list_helper=sort | uniq -c | sort | $count_to_list_helper

!!expand:large:large:medium:small! \
short cmd make_project_large_transcripts_per_gene_dist_file=cut -f2 !{input,,project_large_transcript_gene_file} | $item_to_list_helper > !{output,,project_large_transcripts_per_gene_dist_file} class_level project

!!expand:large:large:medium:small! \
short cmd make_project_large_transcript_exons_file=$parse_large_transcripts_helper(,,1,8) > !{output,,project_large_transcript_exons_file} class_level project

!!expand:large:large:medium:small! \
short cmd make_project_large_exons_per_transcript_dist_file=$smart_join_cmd --exec "cat !{input,,project_large_transcript_exons_file} | cut -f1 | sort | uniq -c" --exec "$smart_join_cmd !{input,--file,project_large_transcript_gene_file} --exec \"cat !{input,,project_large_gene_exons_file} | cut -f1 | sort | uniq -c\" --col 2 --multiple 1" --col 2 | awk -F"\t" -v OFS="\t" '{print \$3,\$2/\$4}' | $table_sum_stats_cmd --group-col 1 --summaries --col 2 --out-delim $tab --print-header | $smart_cut_cmd --in-delim $tab --exclude-row 0,1 --select-col 0,1,mean | awk '{print int(100 * \$1 + .5)}' | $count_to_list_helper > !{output,,project_large_exons_per_transcript_dist_file} class_level project

!!expand:large:large:medium:small! \
short cmd make_project_large_gene_exons_file=$smart_cut_cmd --in-delim $tab --exec "$smart_join_cmd --in-delim $tab !{input,--file,project_large_transcript_gene_file} !{input,--file,project_large_transcript_exons_file} --extra 2 --multiple 2 | cut -f2- | sed 's/^/exon\t/' | $clean_exons" | cut -f2- | sort -u > !{output,,project_large_gene_exons_file} class_level project

!!expand:large:large:medium:small! \
short cmd make_project_large_exons_per_gene_dist_file=cat !{input,,project_large_gene_exons_file} | cut -f1 | $item_to_list_helper > !{output,,project_large_exons_per_gene_dist_file} class_level project

!!expand:large:large:medium:small! \
short cmd make_project_large_exon_length_dist_file=cut -f2-4 !{input,,project_large_transcript_exons_file} | sort -u | awk '{print \$3-\$2}' | $count_to_list_helper > !{output,,project_large_exon_length_dist_file} class_level project

!!expand:large:large:medium:small! \
short cmd make_mask_large_variants_per_gene_dist_file=cut -f2 !{input,,mask_gene_size_large_most_del_text_file} | tail -n+2 | $count_to_list_helper > !{output,,mask_large_variants_per_gene_dist_file} class_level mask


prop n_samples=scalar
prop n_cases=scalar
prop one_sided=scalar
prop path_frac=scalar

prop environ_var=scalar

prop effect_size_frac=scalar

prop pval=scalar default 1e-4
prop min_var_exp=scalar default 0.0005
prop max_var_exp=scalar default 0.1
prop max_var_var_exp=scalar default 0.001
prop var_exp_bins=list default "0.001 0.002 0.005 0.01"


prop min_skat_perms=scalar default 100
prop max_skat_perms=scalar default 1000

prop variants_per_gene_dist_mask=scalar

prop num_sims=scalar default 1000
prop num_per_batch=scalar default 5

local cmd make_simulation_simulation_batch_meta_file=num_batches=`perl -e 'print int(!{prop,,simulation,num_sims}/!{prop,,simulation,num_per_batch}+.5)'` && (echo "simulation_batch_{1..\$num_batches} class simulation_batch" && echo "!select:!{prop,,project} simulation_batch_{1..\$num_batches} parent !{prop,,simulation}") > !{output,,simulation_simulation_batch_meta_file} class_level simulation

!!expand:large:large:medium:small! \
large_ve_sim_params=!{prop,-pval,simulation,pval} !{prop,-environVar,simulation,environ_var,if_prop=environ_var,allow_empty=1} !{prop,-maxVarExp,simulation,max_var_exp,if_prop=max_var_exp,allow_empty=1} !{prop,-minVarExp,simulation,min_var_exp,allow_empty=1} !{prop,-maxVarVarExp,simulation,max_var_var_exp,if_prop=max_var_var_exp,allow_empty=1} !{raw,-oneSided,simulation,,if_prop=one_sided,allow_empty=1} -effectSizeVar 1 $large_ve_sim_dist_params !{input,-mafEffectSizeFile,simulation_maf_effect_size_file,if_prop=simulation_maf_effect_size_file,allow_empty=1} !{raw,,simulation,-effectSizeConst 1,if_prop=effect_size_frac,allow_empty=1} !{prop,-effectSizeFrac,simulation,effect_size_frac,if_prop=effect_size_frac,allow_empty=1} !{prop,-pathFrac,simulation,path_frac,if_prop=path_frac,allow_empty=1} !{raw,,simulation,-varExpBins '[,if_prop=var_exp_bins,allow_empty=1}!{prop;;simulation;var_exp_bins;sep=,;allow_empty=1}!{raw,,simulation,]',if_prop=var_exp_bins,allow_empty=1} !{input,-variants_per_gene_dist_file,mask_large_variants_per_gene_dist_file,if_prop=mask:eq:@variants_per_gene_dist_mask,allow_empty=1}

!!expand:large:large:medium:small! \
large_ve_sim_dist_params=!{input,-transcripts_per_gene_dist_file,project_large_transcripts_per_gene_dist_file} !{input,-exons_per_transcript_dist_file,project_large_exons_per_transcript_dist_file} !{input,-exons_per_gene_dist_file,project_large_exons_per_gene_dist_file} !{input,-exon_length_dist_file,project_large_exon_length_dist_file}

simulation_intercept_mem=2000

short cmd make_simulation_batch_intercept_data_file=python $bin_dir/veSim2.py -nSamples $((!{prop,,simulation,n_samples}\*2)) !{raw,,simulation,-nCases $((@n_cases\*2)),if_prop=n_cases,allow_empty=1} !{prop,-nRuns,simulation,num_per_batch} $large_ve_sim_params -onlyPath -downSample .1 -downSample .2 -downSample .3 -downSample .4 -downSample .5 -downSample .75 > !{output,,simulation_batch_intercept_data_file} class_level simulation_batch rusage_mod $simulation_intercept_mem

prop num_per_null_batch=scalar default 10

!!expand:large:large:medium:small! \
short cmd make_simulation_batch_large_null_data_file=python $bin_dir/veSim2.py !{prop,-nSamples,simulation,n_samples} !{prop,-nRuns,simulation,num_per_null_batch} !{prop,-nCases,simulation,n_cases,if_prop=n_cases,allow_empty=1} $large_ve_sim_dist_params -nullDist -environVar 1 !{prop,-minSkatPermute,simulation,min_skat_perms,if_prop=min_skat_perms} !{prop,-maxSkatPermute,simulation,max_skat_perms,if_prop=max_skat_perms} > !{output,,simulation_batch_large_null_data_file} class_level simulation_batch

process_aggregated_rows=awk 'FNR == 1 {p=0} p {print} \$1 == "\#N" {p=1}' !{input,,@1} | sed 's/^\\#//'

local cmd make_simulation_intercept_data_file=$process_aggregated_rows(simulation_batch_intercept_data_file) | awk -v OFS="\t" '\$2 == "Pathogenic" {print \$1,\$4}' | $table_sum_stats_cmd --out-delim $tab --col 2 --group-col 1 --summaries --print-header | $smart_cut_cmd --exclude-row 0,1 --select-col 0,1 --select-col 0,1,mean | sed '1 s/^/N\tlogP\n/' > !{output,,simulation_intercept_data_file} class_level simulation

local cmd make_simulation_intercept_files=$r_script_cmd($bin_dir/fit_logp_intercept.R) !{input,,simulation_intercept_data_file} !{output,,simulation_intercept_pdf_file} cex=1.1 height.scale=.8 | tail -n1 > !{output,,simulation_intercept_file} class_level simulation

prop exclude_tails=scalar default .01

!!expand:,:burden,Min_pval,Collapse_pval:burden,Min_pval,Collapse_pval:skat,Min_SKAT_pval,Collapse_SKAT_pval:skat_perm,Min_SKAT_perm_pval,Collapse_SKAT_perm_pval! \
!!expand:large:large:medium:small! \
local cmd make_simulation_large_burden_null_data_file=$process_simulation_batches(simulation_batch_large_null_data_file) | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --has-header --col Min_pval --col Collapse_pval --col NumTranscripts --threshold 0.05 --threshold 0.01 --totals --print-header | $smart_cut_cmd --tab-delim --exact --require-col-match --select-col 0,1,Min_pval_num --select-col 0,1,NumTranscripts_tot --select-col 0,1,Min_pval_frac_lte_0.05 --select-col 0,1,Collapse_pval_frac_lte_0.05 --select-col 0,1,Min_pval_frac_lte_0.01 --select-col 0,1,Collapse_pval_frac_lte_0.01 | $add_function_cmd --in-delim $tab --header 1 --col1 Min_pval_frac_lte_0.05 --col2 Collapse_pval_frac_lte_0.05 --type divide --val-header 0.05_ratio | $add_function_cmd --in-delim $tab --header 1 --col1 Min_pval_frac_lte_0.01 --col2 Collapse_pval_frac_lte_0.01 --type divide --val-header 0.01_ratio | $add_function_cmd --in-delim $tab --header 1 --col1 NumTranscripts_tot --col2 Min_pval_num --type divide --val-header NumTranscripts_ratio > !{output,,simulation_large_burden_null_data_file} class_level simulation

#$process_aggregated_rows(simulation_batch_intercept_data_file) | awk -v OFS="\t" '\$2 == "Pathogenic" {print \$1,\$4}' | $table_sum_stats_cmd --out-delim $tab --col 2 --group-col 1 --summaries --print-header | $smart_cut_cmd --exclude-row 0,1 --select-col 0,1 --select-col 0,1,mean | sed '1 s/^/N\tlogP\n/' > !{output,,simulation_intercept_data_file} class_level simulation

!!expand:large:large:medium:small! \
short cmd make_simulation_batch_large_simulations_output_file=python $bin_dir/veSim2.py !{prop,-nSamples,simulation,n_samples} !{prop,-nRuns,simulation,num_per_batch} !{prop,-nCases,simulation,n_cases,if_prop=n_cases,allow_empty=1} -adjustLogP `cat !{input,,simulation_intercept_file}` $large_ve_sim_params !{prop,-minSkatPermute,simulation,min_skat_perms,if_prop=min_skat_perms} !{prop,-maxSkatPermute,simulation,max_skat_perms,if_prop=max_skat_perms} > !{output,,simulation_batch_large_simulations_output_file} class_level simulation_batch

process_simulation_batches=(fgrep -v \\# !{input,,@1,limit=1} | head -n1; awk 'FNR == 1 {p=0} \$1 ~ "Error" {p=-1} p > 0 && NF > 1 {print} \$1 !~ "^\#" {p++}' !{input,,@1} | fgrep -v \\# | awk -v OFS="\t" 'NF > 0 {print \$14/\$12,\$0}' | sort -gk1 | cut -f2-) 

!!expand:large:large:medium:small! \
local cmd make_simulation_large_simulations_output_file=$process_simulation_batches(simulation_batch_large_simulations_output_file) > !{output,,simulation_large_simulations_output_file} class_level simulation

log_p_transform=$add_function_cmd --in-delim $tab --header 1 --col1 @{1}_pval --type minus_log --val-header TEMP_LOG | $add_function_cmd --in-delim $tab --header 1 --col1 TEMP_LOG --val2 `cat !{input,,simulation_intercept_file}` --type subtract --val-header @{1}_NCP | $smart_cut_cmd --in-delim $tab --exclude-col 0,1,'@{1}_pval TEMP_LOG' --exact

#relative_n_mean_transform=$add_function_cmd --in-delim $tab --header 1 --col1 @{1}_NCP_mean --col2 Pathogenic_NCP_mean --type divide --val-header @{1}_mean_relative_N | $add_function_cmd --in-delim $tab --header 1 --col1 @{1}_relative_N_num --type sqrt --val-header @{1}_relative_N_sqrt_num | $add_function_cmd --in-delim $tab --header 1 --col1 @{1}_relative_N_stddev --col2 @{1}_relative_N_sqrt_num --type divide --val-header @{1}_relative_N_stderr --add-at @{1}_relative_N_stddev | $smart_cut_cmd --in-delim $tab --exclude-col 0,1,@{1}_relative_N_sqrt_num | awk -F"\t" -v OFS="\t" 'NR == 1 {for (i=1;i<=NF;i++) {m[\$i]=i} print \$0,"@{1}_relative_N_jacknife","@{1}_relative_N_jacknife_stderr"} NR > 1 {g = \$m["@{1}_relative_N_num"]; mean = g * \$m["@{1}_mean_relative_N"] - (g - 1) * \$m["@{1}_relative_N_mean"]; var = 1} NR > 1 {print \$0,mean,var}'

#aggregate_sims_helper=$log_p_transform(MTA) | $log_p_transform(Bonf) | $log_p_transform(Collapse) | $log_p_transform(Pathogenic) | $log_p_transform(Random_Transcript) | $log_p_transform(Collapse_SKAT) | $log_p_transform(Pathogenic_SKAT) | $log_p_transform(Bonf_SKAT) | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --has-header --group-col N @1 --col 'MTA_NCP' --col 'Bonf_NCP' --col 'Collapse_NCP' --col 'Pathogenic_NCP' --col 'Random_Transcript_NCP' --col 'Collapse_SKAT_NCP' --col 'Pathogenic_SKAT_NCP' --col 'Bonf_SKAT_NCP'  --summaries --totals --print-header | $smart_cut_cmd --in-delim $tab --exclude-col 0,1,'min max tot' | $relative_n_transform(MTA) | $relative_n_transform(Bonf) | $relative_n_transform(Collapse) | $relative_n_transform(Pathogenic) | $relative_n_transform(Random_Transcript) | $relative_n_transform(Collapse_SKAT) | $relative_n_transform(Pathogenic_SKAT) | $relative_n_transform(Bonf_SKAT)

#first_agg_number=40

#aggregate_sims_helper=$log_p_transform(MTA) | $log_p_transform(Bonf) | $log_p_transform(Collapse) | $log_p_transform(Pathogenic) | $log_p_transform(Random_Transcript) | $log_p_transform(Collapse_SKAT) | $log_p_transform(Pathogenic_SKAT) | $log_p_transform(Bonf_SKAT) | awk -F"\t" -v OFS="\t" 'NR == 1 {print "Row",\$0} NR > 1 {print NR % int(!{prop,,simulation,num_sims}/$first_agg_number),\$0;}' | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --has-header --group-col N @1 --group-col Row --col 'MTA_NCP' --col 'Bonf_NCP' --col 'Collapse_NCP' --col 'Pathogenic_NCP' --col 'Random_Transcript_NCP' --col 'Collapse_SKAT_NCP' --col 'Pathogenic_SKAT_NCP' --col 'Bonf_SKAT_NCP' --summaries --print-header | $smart_cut_cmd --in-delim $tab --exclude-col 0,1,'Row stddev' | sed '1 s/_mean//g' | $relative_n_transform(MTA) | $relative_n_transform(Bonf) | $relative_n_transform(Collapse) | $relative_n_transform(Pathogenic) | $relative_n_transform(Random_Transcript) | $relative_n_transform(Collapse_SKAT) | $relative_n_transform(Pathogenic_SKAT) | $relative_n_transform(Bonf_SKAT) | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --has-header --group-col N @1 --col 'MTA_NCP' --col 'Bonf_NCP' --col 'Collapse_NCP' --col 'Pathogenic_NCP' --col 'Random_Transcript_NCP' --col 'Collapse_SKAT_NCP' --col 'Pathogenic_SKAT_NCP' --col 'Bonf_SKAT_NCP' --col 'MTA_relative_N' --col 'Bonf_relative_N' --col 'Collapse_relative_N' --col 'Pathogenic_relative_N' --col 'Random_Transcript_relative_N' --col 'Collapse_SKAT_relative_N' --col 'Pathogenic_SKAT_relative_N' --col 'Bonf_SKAT_relative_N'  --summaries --totals --print-header | $smart_cut_cmd --in-delim $tab --exclude-col 0,1,'min max tot' | $relative_n_mean_transform(MTA) | $relative_n_mean_transform(Bonf) | $relative_n_mean_transform(Collapse) | $relative_n_mean_transform(Pathogenic) | $relative_n_mean_transform(Random_Transcript) | $relative_n_mean_transform(Collapse_SKAT) | $relative_n_mean_transform(Pathogenic_SKAT) | $relative_n_mean_transform(Bonf_SKAT)

#relative_n_mean_transform=$add_function_cmd --in-delim $tab --header 1 --col1 @{1}_NCP_mean --col2 Pathogenic_NCP_mean --type divide --val-header @{1}_mean_relative_N | $add_function_cmd --in-delim $tab --header 1 --col1 @{1}_relative_N_num --type sqrt --val-header @{1}_relative_N_sqrt_num | $add_function_cmd --in-delim $tab --header 1 --col1 @{1}_relative_N_stddev --col2 @{1}_relative_N_sqrt_num --type divide --val-header @{1}_relative_N_stderr --add-at @{1}_relative_N_stddev | $smart_cut_cmd --in-delim $tab --exclude-col 0,1,@{1}_relative_N_sqrt_num | awk -F"\t" -v OFS="\t" 'NR == 1 {for (i=1;i<=NF;i++) {m[\$i]=i} print \$0,"@{1}_relative_N_jacknife","@{1}_relative_N_jacknife_stderr"} NR > 1 {g = \$m["@{1}_relative_N_num"]; mean = g * \$m["@{1}_mean_relative_N"] - (g - 1) * \$m["@{1}_relative_N_mean"]; var = 1} NR > 1 {print \$0,mean,var}'

relative_n_transform=$add_function_cmd --in-delim $tab --header 1 --col1 @{1}_NCP_mean --col2 @{2}_NCP_mean --type divide --val-header @{1}_relative_N_@{2} | awk -F"\t" -v OFS="\t" 'NR == 1 {for (i=1;i<=NF;i++) {m[\$i]=i} print \$0,"@{1}_relative_N_@{2}_corr","@{1}_relative_N_@{2}_stderr"} NR > 1 {r = \$m["@{1}_relative_N_@2"]; n = \$m["@{1}_NCP_num"]; s_x = \$m["@{1}_NCP_stddev"]; s_y = \$m["@{2}_NCP_stddev"]; m_x = \$m["@{1}_NCP_mean"]; m_y = \$m["@{2}_NCP_mean"]; s_xy = \$m["@{1}_NCP_covariance_@{2}_NCP"]; r_corr = r + (1/n) * ((r * s_x * s_x - s_xy) / (m_x * m_x)); var = (1 / n) * ((s_y * s_y)/(m_x * m_x) + (m_y * m_y * s_x * s_x)/(m_x ** 4) - (2 * m_y * s_xy)/(m_x ** 3)); if (var < 0) {var = 0}} NR > 1 {print \$0,r_corr,sqrt(var)}'

aggregate_sims_helper=$log_p_transform(MTA) | $log_p_transform(Bonf) | $log_p_transform(Collapse) | $log_p_transform(Pathogenic) | $log_p_transform(Random_Transcript) | $log_p_transform(Collapse_SKAT) | $log_p_transform(Pathogenic_SKAT) | $log_p_transform(Bonf_SKAT) | $log_p_transform(Random_Transcript_SKAT) | $log_p_transform(Collapse_SKAT_perm) | $log_p_transform(Pathogenic_SKAT_perm) | $log_p_transform(Bonf_SKAT_perm) | $log_p_transform(MTA_SKAT_perm) | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --has-header --group-col N @1 --col 'MTA_NCP' --col 'Bonf_NCP' --col 'Collapse_NCP' --col 'Pathogenic_NCP' --col 'Random_Transcript_NCP' --col 'Collapse_SKAT_NCP' --col 'Pathogenic_SKAT_NCP' --col 'Bonf_SKAT_NCP' --col 'Random_Transcript_SKAT_NCP' --col 'Collapse_SKAT_perm_NCP' --col 'Pathogenic_SKAT_perm_NCP' --col 'Bonf_SKAT_perm_NCP' --col 'MTA_SKAT_perm_NCP' --summaries --totals --covariance 'Pathogenic_NCP' --covariance 'Pathogenic_SKAT_NCP' --covariance 'Pathogenic_SKAT_perm_NCP' --print-header | $smart_cut_cmd --in-delim $tab --exclude-col 0,1,'tot min max' | $relative_n_transform(MTA,Pathogenic) | $relative_n_transform(Bonf,Pathogenic) | $relative_n_transform(Collapse,Pathogenic) | $relative_n_transform(Pathogenic,Pathogenic) | $relative_n_transform(Random_Transcript,Pathogenic) | $relative_n_transform(Collapse_SKAT,Pathogenic) | $relative_n_transform(Pathogenic_SKAT,Pathogenic) | $relative_n_transform(Bonf_SKAT,Pathogenic) | $relative_n_transform(Collapse_SKAT,Pathogenic_SKAT) | $relative_n_transform(Pathogenic_SKAT,Pathogenic_SKAT) | $relative_n_transform(Bonf_SKAT,Pathogenic_SKAT) | $relative_n_transform(Random_Transcript_SKAT,Pathogenic_SKAT) | $relative_n_transform(Collapse_SKAT_perm,Pathogenic_SKAT_perm) | $relative_n_transform(Pathogenic_SKAT_perm,Pathogenic_SKAT_perm) | $relative_n_transform(Bonf_SKAT_perm,Pathogenic_SKAT_perm) | $relative_n_transform(MTA_SKAT_perm,Pathogenic_SKAT_perm) | sed '1 s/Random_Transcript/Random/g'

#aggregate_sims_helper=$log_p_transform(Pathogenic) | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --has-header --group-col N @1 --col 'Pathogenic_NCP' --summaries --totals --covariance 'Pathogenic_NCP' --print-header | $smart_cut_cmd --in-delim $tab --exclude-col 0,1,'tot min max' | $relative_n_transform(Pathogenic,Pathogenic)

!!expand:large:large:medium:small! \
truncate_simulation_large_simulations_output_file=cat !{input,,simulation_large_simulations_output_file} | awk 'NR <= 1 + (1 - !{prop,,simulation,exclude_tails}) * (!{prop,,simulation,num_sims})'


!!expand:large:large:medium:small! \
short cmd make_simulation_large_simulations_aggregated_output_file=$truncate_simulation_large_simulations_output_file | $aggregate_sims_helper() > !{output,,simulation_large_simulations_aggregated_output_file} class_level simulation

!!expand:large:large:medium:small! \
short cmd make_simulation_large_simulations_varexp_aggregated_output_file=$truncate_simulation_large_simulations_output_file | awk -F"\t" -v OFS="\t" '{p = 1} NR > 1 {if (\$2 > 0.002) {\$2="3:>0.002"} else if (\$2 > 0.001) {\$2="2:0.001-0.002"} else if (\$2 > 0) {\$2="1:<0.001"} else {p=0}} p {print}' | $aggregate_sims_helper(--group-col VarianceExplained) > !{output,,simulation_large_simulations_varexp_aggregated_output_file} class_level simulation

!!expand:large:large:medium:small! \
short cmd make_simulation_large_simulations_fold_increase_aggregated_output_file=$truncate_simulation_large_simulations_output_file | awk -F"\t" -v OFS="\t" 'NR == 1 {print \$0,"FoldIncrease"} NR > 1 {p=1; f = \$5/\$4} NR > 1 {if (f > 2.5) {f = ">2.5"} else if (f > 2) {f="2-2.5"} else if (f > 1.5) {f="1.5-2"} else if (f > 1) {f="1-1.5"} else if (f == 1) {p=0} if (p) {print \$0,f}}' | $aggregate_sims_helper(--group-col FoldIncrease) > !{output,,simulation_large_simulations_fold_increase_aggregated_output_file} class_level simulation

!!expand:large:large:medium:small! \
short cmd make_simulation_large_simulations_ntrans_aggregated_output_file=$truncate_simulation_large_simulations_output_file | awk -F"\t" -v OFS="\t" 'NR == 1 {print \$0,"NumTranscripts"} NR > 1 {p=1; f = \$3} NR > 1 {if (f > 5) {f = ">5"} else if (f > 3) {f="4-5"} else if (f > 2) {f="3"} else if (f > 1) {f="2"} else if (f == 1) {p=0} if (p) {print \$0,f}}' | $aggregate_sims_helper(--group-col NumTranscripts) > !{output,,simulation_large_simulations_ntrans_aggregated_output_file} class_level simulation

!!expand:large:large:medium:small! \
short cmd make_simulation_large_simulations_nvar_aggregated_output_file=$truncate_simulation_large_simulations_output_file | awk -F"\t" -v OFS="\t" 'NR == 1 {print \$0,"NumVariants"} NR > 1 {p=1; f = \$4} NR > 1 {if (f > 40) {f = "3:>40"} else if (f > 10) {f="2:10-40"} else if (f > 0) {f="1:<10"} if (p) {print \$0,f}}' | $aggregate_sims_helper(--group-col NumVariants) > !{output,,simulation_large_simulations_nvar_aggregated_output_file} class_level simulation

!!expand:large:large:medium:small! \
short cmd make_simulation_large_simulations_percentile_aggregated_output_file=$truncate_simulation_large_simulations_output_file | awk -F"\t" -v OFS="\t" 'NR == 1 {print -1,\$0} NR > 1 {if (\$13 == 1) {if (\$14 == 1) {r=1} else {r=100000}} else {r= -log(\$14)/-log(\$13)} print r,\$0}' | sort -k1,1g | cut -f2- | awk -F"\t" -v OFS="\t" -v nsim=`$truncate_simulation_large_simulations_output_file | wc -l` 'NR == 1 {print \$0,"Percentile"} NR > 1 {p=1; f = 1 - (NR / (nsim - 1))} NR > 1 {if (f <= .05) {f = "5:<5%"} else if (f <= .1) {f="4:10%-5%"} else if (f <= .2) {f="3:20%-10%"} else if (f <= .3) {f="2:30%-20%"} else if (f <= .5) {f="1:50%-30%"} else {p=0} if (p) {print \$0,f}}' | $aggregate_sims_helper(--group-col Percentile) > !{output,,simulation_large_simulations_percentile_aggregated_output_file} class_level simulation

!!expand:large:large:medium:small! \
short cmd make_simulation_large_simulations_reduced_percentile_aggregated_output_file=$truncate_simulation_large_simulations_output_file | awk -F"\t" -v OFS="\t" 'NR == 1 {print -1,\$0} NR > 1 {if (\$13 == 1) {if (\$14 == 1) {r=1} else {r=100000}} else {r= -log(\$14)/-log(\$13)} print r,\$0}' | sort -k1,1g | cut -f2- | awk -F"\t" -v OFS="\t" -v nsim=`$truncate_simulation_large_simulations_output_file | wc -l` 'NR == 1 {print \$0,"Percentile"} NR > 1 {p=1; f = 1 - (NR / (nsim - 1))} NR > 1 {if (f <= .1) {f = "3:<10%"} else if (f <= .25) {f="2:25%-10%"} else if (f <= .5) {f="1:50%-25%"} else {p=0} if (p) {print \$0,f}}' | $aggregate_sims_helper(--group-col Percentile) > !{output,,simulation_large_simulations_reduced_percentile_aggregated_output_file} class_level simulation

!!expand:large:large:medium:small! \
short cmd make_simulation_large_simulations_top_20_aggregated_output_file=$truncate_simulation_large_simulations_output_file | awk -F"\t" -v OFS="\t" 'NR == 1 {print -1,\$0} NR > 1 {if (\$13 == 1) {if (\$14 == 1) {r=1} else {r=100000}} else {r= -log(\$14)/-log(\$13)} print r,\$0}' | sort -k1,1g | cut -f2- | awk -F"\t" -v OFS="\t" -v nsim=`$truncate_simulation_large_simulations_output_file | wc -l` 'NR == 1 {print \$0,"Percentile"} NR > 1 {p=1; f = 1 - (NR / (nsim - 1))} NR > 1 {if (f <= .2) {f = "20%"} else {p=0} if (p) {print \$0,f}}' | $aggregate_sims_helper(--group-col Percentile) > !{output,,simulation_large_simulations_top_20_aggregated_output_file} class_level simulation

!!expand:large:large:medium:small! \
large_sim_gene_size_helper="$add_function_cmd --in-delim $tab --header 1 --col1 NumCollapseVariants --col2 NumPathVariants --type divide --val-header '$large_disp' --add-at 1 !{input,,simulation_large_simulations_output_file} | cut -f1 | awk -F\"\\t\" -v OFS=\"\\t\" '{print NR-1,\\$1}'"

local cmd make_simulation_gene_size_transcripts_pdf_file=$smart_join_cmd --header 1 --in-delim $tab --exec "awk 'FNR > 1 {print FNR-1}' !{input,,simulation_small_simulations_output_file} !{input,,simulation_medium_simulations_output_file} !{input,,simulation_large_simulations_output_file} | sort -nu | sed '1 s/^/Num\n/'" --exec $small_sim_gene_size_helper --exec $medium_sim_gene_size_helper --exec $large_sim_gene_size_helper --extra 2 --extra 3 --extra 4 --fill 2 --fill 3 --fill 4 | $draw_hist_plot_cmd /dev/stdin !{output,,simulation_gene_size_transcripts_pdf_file} 2,3,4 '' 'Fold-increase in variants between "most deleterious" and pathogenic' colors='$small_color,$medium_color,$large_color' sep=$tab alpha=.4 x.max=!{prop,,project,max_fold_increase} !{prop,breaks=,project,num_fold_breaks,if_prop=num_fold_breaks,allow_empty=1} overlay.density=T overlay.cumulative=T legend.pos=topright log=y inset=0,0.2 cex=1.1 height.scale=.8 class_level simulation

min_sims=5

rel_bar_dat_helper=names="Pathogenic Collapse Bonf MTA Random Pathogenic_SKAT Collapse_SKAT Bonf_SKAT Random_SKAT Pathogenic_SKAT_perm Collapse_SKAT_perm Bonf_SKAT_perm MTA_SKAT_perm"; eval $smart_cut_cmd --tab-delim --select-col .,1 --select-col .,2 @2 --exact --exclude-row .,1 `for f in \$names; do for g in Pathogenic Pathogenic_SKAT Pathogenic_SKAT_perm; do echo --exec "\"$smart_cut_cmd !{input,--file,@1} --tab-delim --exclude-row 1,1,MTA_NCP_num,le:$min_sims | sed 's/^/\$f\\\\\t\$g\\\\\t/'\""; done; done` `i=1; for f in \$names; do for g in Pathogenic Pathogenic_SKAT Pathogenic_SKAT_perm; do echo --select-col \$i,1,"'\${f}_relative_N_\${g} \${f}_relative_N_\${g}_stderr'"; i=$((\$i+1)); done; done` @3 | awk -F"\t" 'NF >= 4' | sed '1 s/^/Criteria\tRelative_to\tRelative_sample_size\tStd_Err\n/' | sed 's/Bonf/Bonferroni/g' | sed '1! s/_/ /g' | awk -F"\t" -v OFS="\t" '{se_col=NF; n_col=NF-1} NR > 1 {if (\$n_col < 0) (\$n_col = 0)} {print}'

!!expand:large:large:medium:small! \
local cmd make_simulation_large_rel_bar_dat_file=$rel_bar_dat_helper(simulation_large_simulations_aggregated_output_file,,) > !{output,,simulation_large_rel_bar_dat_file} class_level simulation

!!expand:,:varexp,VarianceExplained,Variance_Explained,addprocess:varexp,VarianceExplained,Variance_Explained,:fold_increase,FoldIncrease,Fold_Increase,:ntrans,NumTranscripts,Number_of_Transcripts,:nvar,NumVariants,Number_of_Variants,:percentile,Percentile,Percentile,:reduced_percentile,Percentile,Percentile,:top_20,Percentile,Percentile,! \
!!expand:large:large:medium:small! \
local cmd make_simulation_large_varexp_rel_bar_dat_file=$rel_bar_dat_helper(simulation_large_simulations_varexp_aggregated_output_file,--select-col .\,1\,VarianceExplained, | sort -k3\,3 -s) addprocess | sed 's/\t\([0-9]:\)/\t/' | sed '1 s/Relative_to/Relative_to\tVariance_Explained/' > !{output,,simulation_large_varexp_rel_bar_dat_file} class_level simulation

rel_bar_pdf_helper=$smart_cut_cmd --in-delim $tab !{input,--file,@1} --select-row 1,1 --select-row 1,1,"(`echo @3 | sed 's/:/|/g'`)" --select-row 1,2,'@4' --vec-delim : --and-row-all --exact | sed 's/Collapse/Most del./g' | sed 's/\s\s\*perm//' | $draw_bar_plot_cmd /dev/stdin !{output,,@2} "" "Relative sample size" Relative_sample_size Criteria se.col=Std_Err sep=$tab no.legend=T se.cap=T

!!expand:large:large:medium:small! \
!!expand;@;path_collapse@toselect@tocompare@runif;path_collapse@Pathogenic:Collapse@Pathogenic@;all_burden@Pathogenic:Collapse:Bonferroni:MTA@Pathogenic@;burden_skat@Pathogenic:Collapse:Pathogenic SKAT:Collapse SKAT@Pathogenic@;bonf@Pathogenic:Collapse:Bonferroni@Pathogenic@;skat@Pathogenic SKAT perm:Collapse SKAT perm:Bonferroni SKAT perm@Pathogenic SKAT perm@;skat_perm@Pathogenic SKAT perm:Collapse SKAT perm:Bonferroni SKAT perm:MTA SKAT perm@Pathogenic SKAT perm@run_if or,min_skat_perms,max_skat_perms;rand_path@Random:Collapse:Pathogenic@Pathogenic@;rand_path_skat@Random SKAT:Collapse SKAT:Pathogenic SKAT@Pathogenic SKAT@! \
local cmd make_simulation_large_path_collapse_rel_bar_pdf_file=$rel_bar_pdf_helper(simulation_large_rel_bar_dat_file,simulation_large_path_collapse_rel_bar_pdf_file,toselect,tocompare) colors=$large_color width.scale=.75 height.scale=.85 class_level simulation runif

all_rel_bar_pdf_exec_helper=$smart_cut_cmd --in-delim $tab !{input,--file,@1} --select-row 1,1 --select-row 1,1,\"(`echo @2 | sed 's/:/|/g'`)\" --select-row 1,2,'@3' --vec-delim : --and-row-all --exact | sed '1 s/Relative_sample_size/@4/' | sed '1 s/Std_Err/Std_Err_@4/'

#else if ( NR > 1 && new[\$m["Relative_to"]@5] {rel=\$m["Relative_to"]@5; \$m["\$large_disp"] *= (new[rel] / old_large[rel]); \$m["\$medium_disp"] *= (new[rel] / old_medium[rel]); \$m["\$small_disp"] *= (new[rel] / old_small[rel]); } {print}' 

all_rel_bar_join_helper=$smart_join_cmd --col 1 --col 2 @4 --in-delim $tab --header 1 --extra 1 --extra 2 --fill 1 --fill 2 --exec "$all_rel_bar_pdf_exec_helper(simulation_small_@{1}rel_bar_dat_file,@2,@3,$small_disp)" --exec "$all_rel_bar_pdf_exec_helper(simulation_medium_@{1}rel_bar_dat_file,@2,@3,$medium_disp)" --exec "$all_rel_bar_pdf_exec_helper(simulation_large_@{1}rel_bar_dat_file,@2,@3,$large_disp) | awk -v OFS=\"\\t\" '{print \\$0,NR}'" | awk -F"\t" -v OFS="\t" '{print \$NF,\$0}' | sort -k1,1n | cut -f2- | rev | cut -f2- | rev | awk -F"\t" -v OFS="\t" 'NR == 1 {for (i=1;i<=NF;i++) {m[\$i]=i}} {if (NR > 1 && \$m["Relative_to"] == "Pathogenic" && (\$m["Criteria"] == "Pathogenic SKAT" || \$m["Criteria"] == "Pathogenic SKAT perm")) {t=\$m["Criteria"]@5; mean=(\$m["$large_disp"]+\$m["$medium_disp"]+\$m["$small_disp"])/3; old_large[t]=\$m["$large_disp"]; old_medium[t]=\$m["$medium_disp"]; old_small[t]=\$m["$small_disp"]; \$m["$large_disp"]=\$m["$medium_disp"]=\$m["$small_disp"]=new[t]=mean} else if ( NR > 1 && (\$m["Criteria"] ~ "SKAT" || \$m["Criteria"] ~ "SKAT perm")) {if (\$m["Criteria"] ~ "SKAT perm") { rel="Pathogenic SKAT perm"@5 } else { rel="Pathogenic SKAT"@5 } if (new[rel]) {\$m["$large_disp"] *= (new[rel] / old_large[rel]); \$m["$medium_disp"] *= (new[rel] / old_medium[rel]); \$m["$small_disp"] *= (new[rel] / old_small[rel]); }}} {print}' | sed 's/Collapse/Most del./g' | sed 's/\s\s\*perm//' | awk -F"\t" -v OFS="\t" 'NR == 1 {for (i=1;i<=NF;i++) {m[\$i]=i}} NR > 1 {if (\$m["$small_disp"] != "NA" && \$m["$large_disp"] != "NA") {\$m["$small_disp"]-=\$m["$large_disp"]} if (\$m["$medium_disp"] != "NA" && \$m["$large_disp"] != "NA") {\$m["$medium_disp"]-=\$m["$large_disp"]} if (\$m["$small_disp"] != "NA" && \$m["$medium_disp"] != "NA") {\$m["$small_disp"]-=\$m["$medium_disp"]}} {print}' 


all_rel_bar_pdf_helper=$all_rel_bar_join_helper(@1,@2,@3,@4,@6) | $draw_bar_plot_cmd /dev/stdin !{output,,simulation_@{1}@{5}_rel_bar_pdf_file} "" "@7" "$small_disp,$medium_disp,$large_disp" Criteria sep=$tab colors="$large_color","$medium_color","$small_color" no.legend=T se.col="Std_Err_$small_disp,Std_Err_$medium_disp,Std_Err_$large_disp" se.cap=T no.bar=T pt.cex=1.5

!!expand:,:_no_ylab,ylabel:,Relative sample size:_no_ylab,! \
!!expand;@;path_collapse@toselect@tocompare@runif@widthscale@heightscale;path_collapse@Pathogenic:Collapse@Pathogenic@@.75@.85;all_burden@Pathogenic:Collapse:Bonferroni:MTA@Pathogenic@@.75@.85;burden_skat@Pathogenic:Collapse:Pathogenic SKAT:Collapse SKAT@Pathogenic@@.75@.96;bonf@Pathogenic:Collapse:Bonferroni@Pathogenic@@.75@.85;skat@Pathogenic SKAT perm:Collapse SKAT perm:Bonferroni SKAT perm@Pathogenic SKAT perm@@.75@.96;skat_perm@Pathogenic SKAT perm:Collapse SKAT perm:Bonferroni SKAT perm:MTA SKAT perm@Pathogenic SKAT perm@run_if or,min_skat_perms,max_skat_perms@.75@.96;rand_path@Random:Collapse:Pathogenic@Pathogenic@@.75@.85;rand_path_skat@Random SKAT:Collapse SKAT:Pathogenic SKAT@Pathogenic SKAT@@.75@.96! \
local cmd make_simulation_path_collapse_no_ylab_rel_bar_pdf_file=$all_rel_bar_pdf_helper(,toselect,tocompare,,path_collapse_no_ylab,,ylabel) width.scale=widthscale height.scale=heightscale class_level simulation runif

draw_tradeoff_pdf=$draw_matrix_plot_cmd /dev/stdin !{output,,@1} "" Accuracy,Relative_sample_size x.label="Accuracy of prediction of pathogenic transcript" y.label="@2" header=T text.label.col=Criteria sep=$tab no.legend=T color.col=Color order.col=Color connect.col=Line cex=1.4 axis.cex=1.25 height.scale=.8

!!expand:large:large:medium:small! \
large_tradeoff_pdf_helper=$smart_cut_cmd --in-delim $tab --select-row 0,1 --select-row 0,1,"(`echo @2 | sed 's/:/|/g'`)" --select-row 0,2,'@3' @4 --vec-delim : --and-row-all --exact | awk -F"\t" -v OFS="\t" 'NR == 1 {print "Line","Color","Accuracy",\$0} NR > 1 { if (\$1 ~ "Most del.") {print 0,1,.5,\$0} else {n=\$1; \$1="\"\""; if (n ~ "Pathogenic") {print "$large_color",1,1,\$0} else {print "$large_color",1,0,\$0}}}' | $draw_tradeoff_pdf(@1,Relative sample size) custom.color=$large_color 

!!expand:large:large:medium:small! \
!!expand;@;path_collapse@toselect@tocompare@runif;rand_path@Random:Collapse:Pathogenic@Pathogenic@;rand_path_skat@Random SKAT:Collapse SKAT:Pathogenic SKAT@Pathogenic SKAT@! \
local cmd make_simulation_large_path_collapse_tradeoff_pdf_file=cat !{input,,simulation_large_rel_bar_dat_file} | $large_tradeoff_pdf_helper(simulation_large_path_collapse_tradeoff_pdf_file,toselect,tocompare,)  class_level simulation runif

#@4 becomes an argument, replaces Pathogenic in column 2
#Pathogenic gets
#Pass in tocompare

all_tradeoff_pdf_exec_helper=$smart_cut_cmd --in-delim $tab !{input,--file,@1} --select-row 1,1 --select-row 1,1,\"(`echo @2 | sed 's/:/|/g'`)\" --select-row 1,2,'@3' @4 --vec-delim : --and-row-all --exact | awk -v OFS=\"\\t\" -F\"\\t\" 'NR == 1 {print -1,\\$0} NR > 1 {v=10; if (\\$1 ~ \"Pathogenic\") {v=1} else if (\\$1 ~ \"Random\") {v=2} else if (\\$1 ~ \"Collapse\") {v=3} print v,\\$0}' | sort -gk1 | cut -f2- | awk -v OFS=\"\\t\" -F\"\\t\" 'NR == 1 {p=0; r=0; print \"Accuracy\",\\$0} NR > 1 {v=0; if (\\$1 ~ \"Pathogenic\") {p=\\$3; v=1} else if (\\$1 ~ \"Random\") {r=\\$3; v=0} else if (\\$1 ~ \"Collapse\" && p > 0 && r > 0) {if (\\$3 > r) {v=(\\$3 - r)/(p - r)} else {v=0; \\$3=r}} print v,\\$0}' | sed '1 s/^/Line\tColor\t/' | sed '1! s/^/@6\t@5\t/'

all_tradeoff_pdf_helper=$smart_cut_cmd --in-delim $tab --exec "$all_tradeoff_pdf_exec_helper(simulation_small_@{2}rel_bar_dat_file,@3,@4,@5,1,$small_color)" --exec "$all_tradeoff_pdf_exec_helper(simulation_medium_@{2}rel_bar_dat_file,@3,@4,@5,2,$medium_color)" --exec "$all_tradeoff_pdf_exec_helper(simulation_large_@{2}rel_bar_dat_file,@3,@4,@5,3,$large_color)" --exclude-row 2-3,1 | sed 's/Collapse/Most del./g' | sed 's/\s\s\*perm//' | awk -F"\t" -v OFS="\t" 'NR == 1 {print} NR > 1 { if (\$4 ~ "Most del.") {\$1=\$1"no"; print \$0} else {n=\$4; \$4="\"\""; if (n ~ "Pathogenic") {print \$0} else {print \$0}}}' | $draw_tradeoff_pdf(@1,@6) custom.color=$small_color custom.color=$medium_color custom.color=$large_color

!!expand:,:_no_ylab,ylabel:,Relative sample size:_no_ylab, ! \
!!expand;@;path_collapse@toselect@tocompare@runif;rand_path@Random:Collapse:Pathogenic@Pathogenic@;rand_path_skat@Random SKAT:Collapse SKAT:Pathogenic SKAT@Pathogenic SKAT@;rand_path_skat@Random SKAT:Collapse SKAT:Pathogenic SKAT@Pathogenic SKAT@! \
local cmd make_simulation_path_collapse_no_ylab_tradeoff_pdf_file=$all_tradeoff_pdf_helper(simulation_path_collapse_no_ylab_tradeoff_pdf_file,,toselect,tocompare,,ylabel) class_level simulation runif

!!expand:,:varexp,VarianceExplained,Variance_Explained:varexp,VarianceExplained,Variance_Explained:fold_increase,FoldIncrease,Fold_Increase:ntrans,NumTranscripts,Number_of_Transcripts:nvar,NumVariants,Number_of_Variants:percentile,Percentile,Percentile:reduced_percentile,Percentile,Percentile:top_20,Percentile,Percentile! \
!!expand:large:large:medium:small! \
!!expand;@;path_collapse@toselect@tocompare@runif;path_collapse@Pathogenic:Collapse@Pathogenic@;all_burden@Pathogenic:Collapse:Bonferroni:MTA@Pathogenic@;burden_skat@Pathogenic:Collapse:Pathogenic SKAT:Collapse SKAT@Pathogenic@;bonf@Pathogenic:Collapse:Bonferroni@Pathogenic@;skat@Pathogenic SKAT perm:Collapse SKAT perm:Bonferroni SKAT perm@Pathogenic SKAT perm@;skat_perm@Pathogenic SKAT perm:Collapse SKAT perm:Bonferroni SKAT perm:MTA SKAT perm@Pathogenic SKAT perm@run_if or,min_skat_perms,max_skat_perms;rand_path@Random:Collapse:Pathogenic@Pathogenic@;rand_path_skat@Random SKAT:Collapse SKAT:Pathogenic SKAT@Pathogenic SKAT@! \
local cmd make_simulation_large_varexp_path_collapse_rel_bar_pdf_file=$rel_bar_pdf_helper(simulation_large_varexp_rel_bar_dat_file,simulation_large_varexp_path_collapse_rel_bar_pdf_file,toselect,tocompare) group.col='Variance_Explained' colors=$large_color class_level simulation runif

!!expand:,:_no_ylab,ylabel:,Relative sample size:_no_ylab,! \
!!expand:,:varexp,VarianceExplained,Variance_Explained,widthscale:varexp,VarianceExplained,Variance_Explained,.8:fold_increase,FoldIncrease,Fold_Increase,.9:ntrans,NumTranscripts,Number_of_Transcripts,.8:nvar,NumVariants,Number_of_Variants,.8:percentile,Percentile,Percentile,1.22:reduced_percentile,Percentile,Percentile,.8:top_20,Percentile,Percentile,.75! \
!!expand;@;path_collapse@toselect@tocompare@runif@heightscale;path_collapse@Pathogenic:Collapse@Pathogenic@@.85;all_burden@Pathogenic:Collapse:Bonferroni:MTA@Pathogenic@@.85;burden_skat@Pathogenic:Collapse:Pathogenic SKAT:Collapse SKAT@Pathogenic@@.96;bonf@Pathogenic:Collapse:Bonferroni@Pathogenic@@.85;skat@Pathogenic SKAT perm:Collapse SKAT perm:Bonferroni SKAT perm@Pathogenic SKAT perm@@.96;skat_perm@Pathogenic SKAT perm:Collapse SKAT perm:Bonferroni SKAT perm:MTA SKAT perm@Pathogenic SKAT perm@run_if or,min_skat_perms,max_skat_perms@.96;rand_path@Random:Collapse:Pathogenic@Pathogenic@@.85;rand_path_skat@Random SKAT:Collapse SKAT:Pathogenic SKAT@Pathogenic SKAT@@.96! \
local cmd make_simulation_varexp_path_collapse_no_ylab_rel_bar_pdf_file=$all_rel_bar_pdf_helper(varexp_,toselect,tocompare,--col 3,path_collapse_no_ylab,\\":\\"\$m["VarianceExplained"],ylabel) group.col='Variance_Explained' width.scale=widthscale height.scale=heightscale class_level simulation runif

!!expand@;@varexp;VarianceExplained;Variance_Explained;widthscale;addselect@varexp;VarianceExplained;Variance_Explained;2;@fold_increase;FoldIncrease;Fold_Increase;1;--exclude-row 0\,1\,Fold_Increase\,eq:1@ntrans;NumTranscripts;Number_of_Transcripts;1;--exclude-row 0\,1\,Number_of_Transcripts\,eq:1@nvar;NumVariants;Number_of_Variants;1;@percentile;Percentile;Percentile;1;@reduced_percentile;Percentile;Percentile;1;@top_20;Percentile;Percentile;1;! \
!!expand:large:large:medium:small! \
!!expand;@;path_collapse@toselect@tocompare@runif;rand_path@Random:Collapse:Pathogenic@Pathogenic@;rand_path_skat@Random SKAT:Collapse SKAT:Pathogenic SKAT@Pathogenic SKAT@! \
local cmd make_simulation_large_varexp_path_collapse_tradeoff_pdf_file=cat !{input,,simulation_large_varexp_rel_bar_dat_file} | $large_tradeoff_pdf_helper(simulation_large_varexp_path_collapse_tradeoff_pdf_file,toselect,tocompare,addselect) group.col='Variance_Explained' class_level simulation runif

!!expand:large:large:medium:small! \
large_sim_num_transcripts_helper="$smart_cut_cmd --in-delim $tab !{input,--file,simulation_large_simulations_output_file} --select-col 1,1,NumTranscripts | sed '1 s/^/$large_disp\n/' | awk -F\"\\t\" -v OFS=\"\\t\" '{print NR-1,\\$1}'"

local cmd make_simulation_num_gene_transcripts_pdf_file=$smart_join_cmd --header 1 --in-delim $tab --exec "awk 'FNR > 1 {print FNR-1}' !{input,,simulation_small_simulations_output_file} !{input,,simulation_medium_simulations_output_file} !{input,,simulation_large_simulations_output_file} | sort -nu | sed '1 s/\S\S*/Num/'" --exec $small_sim_num_transcripts_helper --exec $medium_sim_num_transcripts_helper --exec $large_sim_num_transcripts_helper --extra 2 --extra 3 --extra 4 --fill 2 --fill 3 --fill 4 | $draw_hist_plot_cmd /dev/stdin !{output,,simulation_num_gene_transcripts_pdf_file} 2,3,4 '' 'Number of transcripts per gene' colors='$small_color,$medium_color,$large_color' sep=$tab alpha=.4 x.max=!{prop,,project,max_num_transcripts} breaks=25 overlay.density=T cex=1.1 height.scale=.8 class_level simulation

!!expand:large:large:medium:small! \
short cmd make_burden_test_large_initial_set_chrpos_file=$smart_join_cmd --in-delim $tab --exec "cut -f1 !{input,,burden_test_gene_path_trans_list_file}" --exec "$smart_join_cmd --in-delim $tab !{input,--file,project_gene_name_map_file} --exec \"tail -n+2 !{input,,mask_large_set_chrpos_file}\" --extra 1 --multiple 2 | cut -f2- | $smart_cut_cmd --in-delim $tab !{input,--file,mask_large_set_chrpos_file} --exclude-row 1,1" --extra 2 --multiple 2 --fill 2 | awk -F"\t" '\$2 != "NA"' | $smart_cut_cmd --in-delim $tab !{input,--file,project_extended_chrpos_exclude_file} | awk -F"\t" 'NF == 2 {m[\$1":"\$2]=1} NF > 2 && !m[\$3":"\$4] {print}' > !{output,,burden_test_large_initial_set_chrpos_file} class_level burden_test

!!expand:large:large:medium:small! \
local cmd make_burden_test_large_set_chrpos_file=cat !{input,,burden_test_large_initial_set_chrpos_file} | $smart_cut_cmd --in-delim $tab --exec "$smart_join_cmd --in-delim $tab --exec \"cut -f2 !{input,,burden_test_gene_path_trans_list_file} | sort -u\" !{input,--file,burden_test_large_initial_set_chrpos_file} --col 2,2 --extra 2 --fill 2 --multiple 2 | cut -f2,3-4 | cat - !{input,,burden_test_large_initial_set_chrpos_file} | awk -v OFS=\"\\t\" -F\"\\t\" 'NF == 3 {m[\\$1\":\"\\$2\":\"\\$3]=1} NF == 4 && m[\\$1\":\"\\$3\":\"\\$4] != 1 {m[\\$1\":\"\\$3\":\"\\$4] = 1; print \\$1,\"Non-Pathogenic\",\\$3,\\$4}'" > !{output,,burden_test_large_set_chrpos_file} class_level burden_test

gassoc_sig=1e-6

prop dichotomous=scalar

!!expand:large:large:medium:small! \
short cmd make_burden_test_large_gassoc_file=python $bin_dir/mta.py !{input,-vcf,project_variant_vcf_file} !{input,-w,burden_test_large_set_chrpos_file} !{input,-c,burden_test_ped_file} `for i in 1 2 3 4 5 6 7 8 9 10; do echo -cNames C\$i; done` !{input,-p,burden_test_ped_file} -pCol 7 -s $gassoc_sig !{raw,-l,burden_test,Logistic,if_prop=dichotomous,allow_empty=1} -pr 0.01 > !{output,,burden_test_large_gassoc_file} class_level burden_test

adjust_flat_gassoc_header=sed '1 s/AsymP/P/' | sed '1 s/BetaMax/BETA/' | sed '1 s/\t\(\S\S*\)/\t@{1}_\1/g'

!!expand:large:large:medium:small! \
filter_large_gassoc_file_helper=$smart_cut_cmd --in-delim $tab --exec \"sed 's/Bonferonni/Bonferroni/' !{input,,burden_test_large_gassoc_file}\" --select-col 1,1,'Gene AsymP BetaMax' --select-row 1,1 --select-row 1,1,Test,@1 | $adjust_flat_gassoc_header(@1)

!!expand:large:large:medium:small! \
local cmd make_burden_test_large_flat_gassoc_file=$smart_join_cmd --in-delim $tab --exec "$smart_join_cmd --in-delim $tab --exec \"cat !{input,,burden_test_gene_path_trans_list_file} | sed 's/\t/\tTranscript_/' | sed '1 s/^/Gene\tTranscript\tExpDir\tSource\n/'\" !{input,--file,burden_test_large_gassoc_file} --col 1 --col 2 --header 1 --extra 2 --fill 2 | $smart_cut_cmd --in-delim $tab --select-col 0,1,'Gene ExpDir Source AsymP BetaMax' | $adjust_flat_gassoc_header(Pathogenic)" --exec "$filter_large_gassoc_file_helper(Transcript_Non-Pathogenic) | sed '1 s/Transcript_//g'" --exec "$filter_large_gassoc_file_helper(Collapse)" --exec "$filter_large_gassoc_file_helper(Bonferroni)" --exec "$filter_large_gassoc_file_helper(MTA)" --header 1 --extra 2 --extra 3 --extra 4 --extra 5 --fill 2 --fill 3 --fill 4 --fill 5 > !{output,,burden_test_large_flat_gassoc_file} class_level burden_test

binom_test_helper=$smart_cut_cmd !{input,--file,burden_test_large_flat_gassoc_file} --in-delim $tab --select-col 1,1,'Pathogenic_ExpDir Pathogenic_BETA Non-Pathogenic_BETA' @1 | sed 's/nan/NA/g' | awk -F\"\\t\" -v OFS=\"\\t\" 'NR > 1 {for (i=2; i<=3; i++) {if (\\$i != \"NA\") { if (\\$1 == \"-\") {\\$i *= -1;} \\$i /= (\\$i > 0 ? \\$i : -\\$i)}}} {print \\$2,\\$3}' | $table_sum_stats_cmd --in-delim $tab --out-delim $tab --col Pathogenic_BETA --col Non-Pathogenic_BETA --threshold 0 --totals --print-header --has-header | $smart_cut_cmd --in-delim $tab --exact --require-col-match --select-col 0,1,'Pathogenic_BETA_num_above_0 Pathogenic_BETA_num_lte_0 Pathogenic_BETA_num Non-Pathogenic_BETA_num_above_0 Non-Pathogenic_BETA_num_lte_0 Non-Pathogenic_BETA_num' | $add_function_cmd --in-delim $tab --header 1 --col1 Pathogenic_BETA_num_above_0 --col2 Pathogenic_BETA_num --type binom_test --val-header Pathogenic_p_value --add-at Non-Pathogenic_BETA_num_above_0 | $add_function_cmd --in-delim $tab --header 1 --col1 Non-Pathogenic_BETA_num_above_0 --col2 Non-Pathogenic_BETA_num --type binom_test --val-header Non-Pathogenic_p_value | $smart_cut_cmd --in-delim $tab --select-col 0,1,'Pathogenic_BETA_num_above_0 Pathogenic_BETA_num_lte_0 Pathogenic_p_value Non-Pathogenic_BETA_num_above_0 Non-Pathogenic_BETA_num_lte_0 Non-Pathogenic_p_value' --exact --require-col-match | $format_columns_cmd --in-delim $tab --header 1 --number-format 'Pathogenic_p_value Non-Pathogenic_p_value','%.3f'

!!expand:large:large:medium:small! \
local cmd make_burden_test_large_path_non_sign_comp_file=$smart_cut_cmd --in-delim $tab --exec "$binom_test_helper() | sed '1 s/^/Genes\t/' | sed '1! s/^/All\t/'" --exec "$binom_test_helper(--select-row 1\,1 --select-row 1\,1\,Pathogenic_BETA\,gt:0) | tail -n+2 | sed 's/^/Pathogenic_BETA_gt_0\t/'" > !{output,,burden_test_large_path_non_sign_comp_file} class_level burden_test


#COMMANDS
#====================
